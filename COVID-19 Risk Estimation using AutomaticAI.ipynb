{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xai\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix, precision_score, recall_score, roc_curve, auc, accuracy_score\n",
    "\n",
    "from AutoAIAlgorithm.ParticleSwarmOptimization import PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/covid-19.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_delete = ['Patient ID', 'Patient addmited to semi-intensive unit (1=yes, 0=no)',\n",
    "                     'Patient addmited to intensive care unit (1=yes, 0=no)',\n",
    "                     'Patient addmited to regular ward (1=yes, 0=no)', \n",
    "                     'Metapneumovirus', 'Respiratory Syncytial Virus', 'Influenza A', \n",
    "                     'Influenza B', 'Parainfluenza 1', 'CoronavirusNL63', 'Rhinovirus/Enterovirus', \n",
    "                     'Mycoplasma pneumoniae', 'Coronavirus HKU1', 'Parainfluenza 3', 'Chlamydophila pneumoniae', \n",
    "                     'Adenovirus', 'Parainfluenza 4', 'Coronavirus229E', 'CoronavirusOC43', 'Inf A H1N1 2009',\n",
    "                     'Bordetella pertussis', 'Metapneumovirus', 'Parainfluenza 2', 'Influenza B, rapid test',\n",
    "                     'Influenza A, rapid test', 'Strepto A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns_to_delete, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_no_nan = df.dropna(subset=['Hematocrit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_no_nan.loc[:, df_no_nan.isnull().mean() < 0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient age quantile</th>\n",
       "      <th>SARS-Cov-2 exam result</th>\n",
       "      <th>Hematocrit</th>\n",
       "      <th>Hemoglobin</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Mean platelet volume</th>\n",
       "      <th>Red blood Cells</th>\n",
       "      <th>Lymphocytes</th>\n",
       "      <th>Mean corpuscular hemoglobin concentrationÂ (MCHC)</th>\n",
       "      <th>Leukocytes</th>\n",
       "      <th>...</th>\n",
       "      <th>Urea</th>\n",
       "      <th>C-reactive protein mg/dL</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>Potassium</th>\n",
       "      <th>Sodium</th>\n",
       "      <th>Alanine transaminase</th>\n",
       "      <th>Aspartate transaminase</th>\n",
       "      <th>Total Bilirubin</th>\n",
       "      <th>Direct Bilirubin</th>\n",
       "      <th>Indirect Bilirubin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.236515</td>\n",
       "      <td>-0.022340</td>\n",
       "      <td>-0.517413</td>\n",
       "      <td>0.010677</td>\n",
       "      <td>0.102004</td>\n",
       "      <td>0.318366</td>\n",
       "      <td>-0.950790</td>\n",
       "      <td>-0.094610</td>\n",
       "      <td>...</td>\n",
       "      <td>1.198059</td>\n",
       "      <td>-0.147895</td>\n",
       "      <td>2.089928</td>\n",
       "      <td>-0.305787</td>\n",
       "      <td>0.862512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1.571682</td>\n",
       "      <td>-0.774212</td>\n",
       "      <td>1.429667</td>\n",
       "      <td>-1.672222</td>\n",
       "      <td>-0.850035</td>\n",
       "      <td>-0.005738</td>\n",
       "      <td>3.331071</td>\n",
       "      <td>0.364550</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067309</td>\n",
       "      <td>-0.286986</td>\n",
       "      <td>-1.838623</td>\n",
       "      <td>0.930020</td>\n",
       "      <td>0.503132</td>\n",
       "      <td>-0.586821</td>\n",
       "      <td>-0.162200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.747693</td>\n",
       "      <td>-0.586244</td>\n",
       "      <td>-0.429480</td>\n",
       "      <td>-0.213711</td>\n",
       "      <td>-1.361315</td>\n",
       "      <td>-1.114514</td>\n",
       "      <td>0.542882</td>\n",
       "      <td>-0.884923</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.811643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.908177</td>\n",
       "      <td>0.435697</td>\n",
       "      <td>-0.215628</td>\n",
       "      <td>-0.559257</td>\n",
       "      <td>-0.549287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.991838</td>\n",
       "      <td>0.792188</td>\n",
       "      <td>0.072992</td>\n",
       "      <td>-0.550290</td>\n",
       "      <td>0.542763</td>\n",
       "      <td>0.045436</td>\n",
       "      <td>-0.452899</td>\n",
       "      <td>-0.211488</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.487674</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.190738</td>\n",
       "      <td>-0.147652</td>\n",
       "      <td>-0.668155</td>\n",
       "      <td>1.020415</td>\n",
       "      <td>-0.127191</td>\n",
       "      <td>0.002791</td>\n",
       "      <td>-1.249524</td>\n",
       "      <td>-1.132592</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.332677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.908177</td>\n",
       "      <td>-0.552949</td>\n",
       "      <td>-0.575008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.014726</td>\n",
       "      <td>0.854844</td>\n",
       "      <td>-0.178244</td>\n",
       "      <td>0.796029</td>\n",
       "      <td>0.489872</td>\n",
       "      <td>-0.730707</td>\n",
       "      <td>-0.353319</td>\n",
       "      <td>-0.075131</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.737209</td>\n",
       "      <td>-0.434025</td>\n",
       "      <td>-0.701411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>14</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.740064</td>\n",
       "      <td>0.854844</td>\n",
       "      <td>0.361914</td>\n",
       "      <td>-0.550290</td>\n",
       "      <td>0.436981</td>\n",
       "      <td>-0.227493</td>\n",
       "      <td>0.642463</td>\n",
       "      <td>0.105751</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.141742</td>\n",
       "      <td>-0.529401</td>\n",
       "      <td>0.332418</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>9</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.679027</td>\n",
       "      <td>-0.711556</td>\n",
       "      <td>0.952319</td>\n",
       "      <td>-0.886869</td>\n",
       "      <td>-0.321124</td>\n",
       "      <td>-0.875701</td>\n",
       "      <td>-0.253742</td>\n",
       "      <td>-0.286623</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.439476</td>\n",
       "      <td>0.545572</td>\n",
       "      <td>1.021638</td>\n",
       "      <td>0.435697</td>\n",
       "      <td>-1.653147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.236515</td>\n",
       "      <td>0.040316</td>\n",
       "      <td>0.072992</td>\n",
       "      <td>0.571643</td>\n",
       "      <td>0.066744</td>\n",
       "      <td>1.239503</td>\n",
       "      <td>-0.652057</td>\n",
       "      <td>-0.545423</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.513909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.391262</td>\n",
       "      <td>0.930020</td>\n",
       "      <td>0.143752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>17</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.808730</td>\n",
       "      <td>1.042812</td>\n",
       "      <td>-0.278739</td>\n",
       "      <td>1.581381</td>\n",
       "      <td>0.701437</td>\n",
       "      <td>-0.261609</td>\n",
       "      <td>1.040773</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.360505</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>14</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.106813</td>\n",
       "      <td>-0.335620</td>\n",
       "      <td>1.429667</td>\n",
       "      <td>-0.213711</td>\n",
       "      <td>-0.603210</td>\n",
       "      <td>0.326895</td>\n",
       "      <td>-0.950790</td>\n",
       "      <td>0.726313</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.519466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>16</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.426721</td>\n",
       "      <td>1.230779</td>\n",
       "      <td>0.600588</td>\n",
       "      <td>-1.111256</td>\n",
       "      <td>1.265607</td>\n",
       "      <td>0.506005</td>\n",
       "      <td>-0.353319</td>\n",
       "      <td>-0.022258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453725</td>\n",
       "      <td>-0.414154</td>\n",
       "      <td>-0.563567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>15</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.717175</td>\n",
       "      <td>0.604220</td>\n",
       "      <td>0.399599</td>\n",
       "      <td>0.683835</td>\n",
       "      <td>0.401720</td>\n",
       "      <td>0.011320</td>\n",
       "      <td>-0.253742</td>\n",
       "      <td>-0.178094</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.354544</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.476563</td>\n",
       "      <td>-0.471870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>17</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.014726</td>\n",
       "      <td>0.666876</td>\n",
       "      <td>-0.203368</td>\n",
       "      <td>0.459449</td>\n",
       "      <td>0.295938</td>\n",
       "      <td>-0.261609</td>\n",
       "      <td>-0.950790</td>\n",
       "      <td>-0.083479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.825892</td>\n",
       "      <td>-0.461843</td>\n",
       "      <td>2.124389</td>\n",
       "      <td>-0.800110</td>\n",
       "      <td>0.862512</td>\n",
       "      <td>-0.366304</td>\n",
       "      <td>-0.510579</td>\n",
       "      <td>0.131181</td>\n",
       "      <td>0.580054</td>\n",
       "      <td>-0.278654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>7</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.946061</td>\n",
       "      <td>1.168124</td>\n",
       "      <td>-0.278739</td>\n",
       "      <td>0.010677</td>\n",
       "      <td>1.177456</td>\n",
       "      <td>-0.671003</td>\n",
       "      <td>1.040773</td>\n",
       "      <td>0.133579</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.439476</td>\n",
       "      <td>0.011066</td>\n",
       "      <td>1.297326</td>\n",
       "      <td>0.188535</td>\n",
       "      <td>0.143752</td>\n",
       "      <td>-0.283610</td>\n",
       "      <td>-0.200909</td>\n",
       "      <td>1.049447</td>\n",
       "      <td>-0.003205</td>\n",
       "      <td>1.690864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>19</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.625621</td>\n",
       "      <td>0.353596</td>\n",
       "      <td>-0.127997</td>\n",
       "      <td>0.796029</td>\n",
       "      <td>0.190156</td>\n",
       "      <td>-1.592140</td>\n",
       "      <td>-0.851210</td>\n",
       "      <td>0.556563</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.737209</td>\n",
       "      <td>0.611144</td>\n",
       "      <td>-0.494645</td>\n",
       "      <td>-1.541595</td>\n",
       "      <td>0.862512</td>\n",
       "      <td>-0.448998</td>\n",
       "      <td>-0.278326</td>\n",
       "      <td>-0.174908</td>\n",
       "      <td>-0.003205</td>\n",
       "      <td>-0.278654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>6</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.152590</td>\n",
       "      <td>-0.460932</td>\n",
       "      <td>1.241240</td>\n",
       "      <td>-1.560029</td>\n",
       "      <td>-0.250603</td>\n",
       "      <td>-0.065441</td>\n",
       "      <td>-1.249524</td>\n",
       "      <td>1.196605</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.451908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>10</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.190738</td>\n",
       "      <td>0.040316</td>\n",
       "      <td>-1.057571</td>\n",
       "      <td>0.235063</td>\n",
       "      <td>-0.462168</td>\n",
       "      <td>-1.268037</td>\n",
       "      <td>-0.552476</td>\n",
       "      <td>1.224433</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.365042</td>\n",
       "      <td>2.256389</td>\n",
       "      <td>0.470262</td>\n",
       "      <td>-0.058626</td>\n",
       "      <td>-0.215628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>11</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.740064</td>\n",
       "      <td>0.604220</td>\n",
       "      <td>0.160925</td>\n",
       "      <td>0.908221</td>\n",
       "      <td>-0.021409</td>\n",
       "      <td>-0.329842</td>\n",
       "      <td>-0.353319</td>\n",
       "      <td>0.225411</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.141742</td>\n",
       "      <td>-0.495622</td>\n",
       "      <td>0.022270</td>\n",
       "      <td>-0.305787</td>\n",
       "      <td>1.581271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>11</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.740064</td>\n",
       "      <td>0.541564</td>\n",
       "      <td>-0.065188</td>\n",
       "      <td>0.683835</td>\n",
       "      <td>-0.215342</td>\n",
       "      <td>0.966573</td>\n",
       "      <td>-0.552476</td>\n",
       "      <td>0.350636</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.141742</td>\n",
       "      <td>-0.475752</td>\n",
       "      <td>-0.529106</td>\n",
       "      <td>-0.800110</td>\n",
       "      <td>1.581271</td>\n",
       "      <td>-0.559257</td>\n",
       "      <td>-0.471870</td>\n",
       "      <td>-1.093174</td>\n",
       "      <td>-1.169722</td>\n",
       "      <td>-0.771034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>16</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.671398</td>\n",
       "      <td>0.290940</td>\n",
       "      <td>0.135801</td>\n",
       "      <td>0.010677</td>\n",
       "      <td>0.525133</td>\n",
       "      <td>0.173372</td>\n",
       "      <td>-1.249524</td>\n",
       "      <td>-0.653951</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.316791</td>\n",
       "      <td>0.194574</td>\n",
       "      <td>2.412989</td>\n",
       "      <td>0.862512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>6</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.221256</td>\n",
       "      <td>-0.084996</td>\n",
       "      <td>0.261419</td>\n",
       "      <td>1.356995</td>\n",
       "      <td>-0.162451</td>\n",
       "      <td>-0.031325</td>\n",
       "      <td>0.542882</td>\n",
       "      <td>-0.509246</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.521453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.816359</td>\n",
       "      <td>-0.836868</td>\n",
       "      <td>0.763892</td>\n",
       "      <td>-1.560029</td>\n",
       "      <td>-0.656101</td>\n",
       "      <td>-1.370385</td>\n",
       "      <td>-0.253742</td>\n",
       "      <td>1.666897</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.727844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>9</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.656139</td>\n",
       "      <td>-0.899524</td>\n",
       "      <td>-0.391795</td>\n",
       "      <td>0.796029</td>\n",
       "      <td>-0.409276</td>\n",
       "      <td>1.862123</td>\n",
       "      <td>-1.149948</td>\n",
       "      <td>-0.681779</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.519466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>19</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.518807</td>\n",
       "      <td>-0.586244</td>\n",
       "      <td>0.952319</td>\n",
       "      <td>0.010677</td>\n",
       "      <td>-0.144821</td>\n",
       "      <td>0.429243</td>\n",
       "      <td>-0.353319</td>\n",
       "      <td>-0.748566</td>\n",
       "      <td>...</td>\n",
       "      <td>1.198059</td>\n",
       "      <td>-0.283012</td>\n",
       "      <td>-0.873716</td>\n",
       "      <td>0.930020</td>\n",
       "      <td>0.503132</td>\n",
       "      <td>-0.531692</td>\n",
       "      <td>-0.510579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>17</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.442512</td>\n",
       "      <td>0.228284</td>\n",
       "      <td>-0.680717</td>\n",
       "      <td>0.459449</td>\n",
       "      <td>0.736697</td>\n",
       "      <td>-1.165688</td>\n",
       "      <td>-0.652057</td>\n",
       "      <td>-0.589947</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.365042</td>\n",
       "      <td>-0.404219</td>\n",
       "      <td>0.573645</td>\n",
       "      <td>-1.047272</td>\n",
       "      <td>-0.215628</td>\n",
       "      <td>1.149753</td>\n",
       "      <td>-0.239617</td>\n",
       "      <td>1.355535</td>\n",
       "      <td>0.580054</td>\n",
       "      <td>1.690864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>10</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.541696</td>\n",
       "      <td>-0.398276</td>\n",
       "      <td>-0.454604</td>\n",
       "      <td>-0.550290</td>\n",
       "      <td>-0.779514</td>\n",
       "      <td>-1.276566</td>\n",
       "      <td>0.443306</td>\n",
       "      <td>0.236542</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.034943</td>\n",
       "      <td>-0.243272</td>\n",
       "      <td>-0.977099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>18</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.946061</td>\n",
       "      <td>0.854844</td>\n",
       "      <td>-0.718402</td>\n",
       "      <td>0.908221</td>\n",
       "      <td>0.366460</td>\n",
       "      <td>0.540121</td>\n",
       "      <td>-0.054585</td>\n",
       "      <td>-1.032411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155991</td>\n",
       "      <td>-0.461843</td>\n",
       "      <td>0.573645</td>\n",
       "      <td>-0.058626</td>\n",
       "      <td>0.143752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>15</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.450142</td>\n",
       "      <td>-0.460932</td>\n",
       "      <td>-0.542537</td>\n",
       "      <td>1.132609</td>\n",
       "      <td>-0.779514</td>\n",
       "      <td>-0.671003</td>\n",
       "      <td>-0.154166</td>\n",
       "      <td>-1.138157</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.960510</td>\n",
       "      <td>-0.489661</td>\n",
       "      <td>-0.632489</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>14</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.220724</td>\n",
       "      <td>1.356092</td>\n",
       "      <td>0.500094</td>\n",
       "      <td>-0.550290</td>\n",
       "      <td>1.688736</td>\n",
       "      <td>0.463359</td>\n",
       "      <td>0.742040</td>\n",
       "      <td>1.152081</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.290609</td>\n",
       "      <td>0.650884</td>\n",
       "      <td>0.539184</td>\n",
       "      <td>1.177181</td>\n",
       "      <td>-1.293767</td>\n",
       "      <td>0.212554</td>\n",
       "      <td>-0.355744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5257</th>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>-2.418559</td>\n",
       "      <td>-2.152643</td>\n",
       "      <td>0.952319</td>\n",
       "      <td>-1.672222</td>\n",
       "      <td>-1.237902</td>\n",
       "      <td>-1.694489</td>\n",
       "      <td>0.642463</td>\n",
       "      <td>4.224283</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.183810</td>\n",
       "      <td>4.970647</td>\n",
       "      <td>-2.010928</td>\n",
       "      <td>-0.058626</td>\n",
       "      <td>-1.293767</td>\n",
       "      <td>1.563223</td>\n",
       "      <td>2.508704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5258</th>\n",
       "      <td>19</td>\n",
       "      <td>positive</td>\n",
       "      <td>-0.244145</td>\n",
       "      <td>-1.087492</td>\n",
       "      <td>-1.045009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.975753</td>\n",
       "      <td>-0.210435</td>\n",
       "      <td>-3.440245</td>\n",
       "      <td>-1.207727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.588343</td>\n",
       "      <td>-0.155843</td>\n",
       "      <td>0.056730</td>\n",
       "      <td>-2.035918</td>\n",
       "      <td>0.862512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5259</th>\n",
       "      <td>10</td>\n",
       "      <td>positive</td>\n",
       "      <td>-0.679027</td>\n",
       "      <td>-0.711556</td>\n",
       "      <td>-1.585167</td>\n",
       "      <td>2.254541</td>\n",
       "      <td>0.172526</td>\n",
       "      <td>-1.182746</td>\n",
       "      <td>-0.253742</td>\n",
       "      <td>0.158624</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.183810</td>\n",
       "      <td>-0.455882</td>\n",
       "      <td>-0.632489</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.886328</td>\n",
       "      <td>6.998919</td>\n",
       "      <td>-0.787085</td>\n",
       "      <td>-0.586463</td>\n",
       "      <td>-0.771034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5260</th>\n",
       "      <td>19</td>\n",
       "      <td>positive</td>\n",
       "      <td>-0.518807</td>\n",
       "      <td>-0.774212</td>\n",
       "      <td>-1.321369</td>\n",
       "      <td>0.683835</td>\n",
       "      <td>-0.567950</td>\n",
       "      <td>-0.287196</td>\n",
       "      <td>-1.149948</td>\n",
       "      <td>-1.007366</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216176</td>\n",
       "      <td>1.622533</td>\n",
       "      <td>-0.563567</td>\n",
       "      <td>0.682859</td>\n",
       "      <td>-0.215628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.480996</td>\n",
       "      <td>-0.003205</td>\n",
       "      <td>-0.771034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5285</th>\n",
       "      <td>19</td>\n",
       "      <td>negative</td>\n",
       "      <td>-3.242548</td>\n",
       "      <td>-3.029827</td>\n",
       "      <td>-2.075077</td>\n",
       "      <td>0.796029</td>\n",
       "      <td>-3.476958</td>\n",
       "      <td>-0.065441</td>\n",
       "      <td>0.044991</td>\n",
       "      <td>-1.636277</td>\n",
       "      <td>...</td>\n",
       "      <td>1.942393</td>\n",
       "      <td>1.547026</td>\n",
       "      <td>3.296062</td>\n",
       "      <td>-1.294433</td>\n",
       "      <td>-0.575008</td>\n",
       "      <td>0.763848</td>\n",
       "      <td>1.037771</td>\n",
       "      <td>-0.174908</td>\n",
       "      <td>0.580054</td>\n",
       "      <td>-0.771034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5329</th>\n",
       "      <td>17</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.968950</td>\n",
       "      <td>1.105468</td>\n",
       "      <td>-0.127997</td>\n",
       "      <td>-0.662483</td>\n",
       "      <td>0.930631</td>\n",
       "      <td>-0.039854</td>\n",
       "      <td>0.742040</td>\n",
       "      <td>-0.745784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007125</td>\n",
       "      <td>-0.342622</td>\n",
       "      <td>0.918255</td>\n",
       "      <td>-1.047272</td>\n",
       "      <td>0.862512</td>\n",
       "      <td>0.240119</td>\n",
       "      <td>0.147470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5341</th>\n",
       "      <td>13</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.556955</td>\n",
       "      <td>0.416252</td>\n",
       "      <td>-0.931953</td>\n",
       "      <td>-0.550290</td>\n",
       "      <td>0.842479</td>\n",
       "      <td>0.412185</td>\n",
       "      <td>-0.353319</td>\n",
       "      <td>-0.884923</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.811643</td>\n",
       "      <td>0.944962</td>\n",
       "      <td>0.573645</td>\n",
       "      <td>0.435697</td>\n",
       "      <td>0.143752</td>\n",
       "      <td>0.736283</td>\n",
       "      <td>0.186179</td>\n",
       "      <td>-0.174908</td>\n",
       "      <td>-0.003205</td>\n",
       "      <td>-0.278654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5410</th>\n",
       "      <td>19</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1.136799</td>\n",
       "      <td>-0.962180</td>\n",
       "      <td>0.110677</td>\n",
       "      <td>-0.325903</td>\n",
       "      <td>-1.378946</td>\n",
       "      <td>-0.508952</td>\n",
       "      <td>0.443306</td>\n",
       "      <td>0.403509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304858</td>\n",
       "      <td>0.895286</td>\n",
       "      <td>-0.977099</td>\n",
       "      <td>-1.541595</td>\n",
       "      <td>-2.012527</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.480996</td>\n",
       "      <td>-0.586463</td>\n",
       "      <td>-0.278654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5414</th>\n",
       "      <td>15</td>\n",
       "      <td>positive</td>\n",
       "      <td>-0.244145</td>\n",
       "      <td>0.102972</td>\n",
       "      <td>-1.170627</td>\n",
       "      <td>1.132609</td>\n",
       "      <td>-0.585580</td>\n",
       "      <td>-0.679533</td>\n",
       "      <td>1.339507</td>\n",
       "      <td>-1.024063</td>\n",
       "      <td>...</td>\n",
       "      <td>1.942393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.159482</td>\n",
       "      <td>0.682859</td>\n",
       "      <td>0.143752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.174908</td>\n",
       "      <td>-0.003205</td>\n",
       "      <td>-0.278654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>17</td>\n",
       "      <td>positive</td>\n",
       "      <td>-0.358588</td>\n",
       "      <td>-0.460932</td>\n",
       "      <td>-0.153121</td>\n",
       "      <td>0.122869</td>\n",
       "      <td>-0.215342</td>\n",
       "      <td>-1.353327</td>\n",
       "      <td>-0.452899</td>\n",
       "      <td>0.901629</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.883794</td>\n",
       "      <td>1.177181</td>\n",
       "      <td>0.143752</td>\n",
       "      <td>-0.007963</td>\n",
       "      <td>0.302305</td>\n",
       "      <td>-0.174908</td>\n",
       "      <td>-0.003205</td>\n",
       "      <td>-0.278654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5434</th>\n",
       "      <td>19</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.267033</td>\n",
       "      <td>-0.460932</td>\n",
       "      <td>2.082882</td>\n",
       "      <td>-1.111256</td>\n",
       "      <td>-0.832405</td>\n",
       "      <td>0.173372</td>\n",
       "      <td>-0.851210</td>\n",
       "      <td>0.623350</td>\n",
       "      <td>...</td>\n",
       "      <td>1.644660</td>\n",
       "      <td>0.654858</td>\n",
       "      <td>0.366879</td>\n",
       "      <td>0.930020</td>\n",
       "      <td>-1.293767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.480996</td>\n",
       "      <td>-0.586463</td>\n",
       "      <td>-0.278654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5437</th>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>-2.121008</td>\n",
       "      <td>-2.340612</td>\n",
       "      <td>0.952319</td>\n",
       "      <td>-0.774677</td>\n",
       "      <td>-0.973448</td>\n",
       "      <td>0.386598</td>\n",
       "      <td>-1.747415</td>\n",
       "      <td>0.820928</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.588343</td>\n",
       "      <td>-0.394284</td>\n",
       "      <td>-2.252155</td>\n",
       "      <td>-0.058626</td>\n",
       "      <td>0.143752</td>\n",
       "      <td>-0.338739</td>\n",
       "      <td>0.147470</td>\n",
       "      <td>-0.787085</td>\n",
       "      <td>-0.586463</td>\n",
       "      <td>-0.771034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5451</th>\n",
       "      <td>10</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.396736</td>\n",
       "      <td>0.165628</td>\n",
       "      <td>-0.153121</td>\n",
       "      <td>0.122869</td>\n",
       "      <td>-0.021409</td>\n",
       "      <td>1.009218</td>\n",
       "      <td>-0.751633</td>\n",
       "      <td>-0.837616</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.521453</td>\n",
       "      <td>-0.563567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5466</th>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1.182576</td>\n",
       "      <td>-0.836868</td>\n",
       "      <td>-0.693278</td>\n",
       "      <td>-0.101517</td>\n",
       "      <td>-0.462168</td>\n",
       "      <td>-0.671003</td>\n",
       "      <td>1.239930</td>\n",
       "      <td>0.495342</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.379584</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5511</th>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1.159688</td>\n",
       "      <td>-1.275460</td>\n",
       "      <td>3.276253</td>\n",
       "      <td>-0.438097</td>\n",
       "      <td>-1.872596</td>\n",
       "      <td>1.887710</td>\n",
       "      <td>-0.851210</td>\n",
       "      <td>2.874629</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.165778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5524</th>\n",
       "      <td>19</td>\n",
       "      <td>positive</td>\n",
       "      <td>-0.793470</td>\n",
       "      <td>-0.774212</td>\n",
       "      <td>-0.316424</td>\n",
       "      <td>1.020415</td>\n",
       "      <td>-0.638471</td>\n",
       "      <td>0.582766</td>\n",
       "      <td>-0.154166</td>\n",
       "      <td>-1.004583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.528158</td>\n",
       "      <td>-0.364479</td>\n",
       "      <td>-0.425723</td>\n",
       "      <td>-0.800110</td>\n",
       "      <td>0.503132</td>\n",
       "      <td>-0.063092</td>\n",
       "      <td>0.147470</td>\n",
       "      <td>0.437270</td>\n",
       "      <td>0.580054</td>\n",
       "      <td>0.213725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>14</td>\n",
       "      <td>positive</td>\n",
       "      <td>-0.312811</td>\n",
       "      <td>0.040316</td>\n",
       "      <td>-0.592784</td>\n",
       "      <td>0.571643</td>\n",
       "      <td>-0.338755</td>\n",
       "      <td>1.589193</td>\n",
       "      <td>1.339507</td>\n",
       "      <td>-1.285645</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.034943</td>\n",
       "      <td>-0.533375</td>\n",
       "      <td>-0.563567</td>\n",
       "      <td>-0.058626</td>\n",
       "      <td>0.503132</td>\n",
       "      <td>-0.559257</td>\n",
       "      <td>-0.433161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5553</th>\n",
       "      <td>18</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.602732</td>\n",
       "      <td>0.353596</td>\n",
       "      <td>-1.082694</td>\n",
       "      <td>1.581381</td>\n",
       "      <td>0.119635</td>\n",
       "      <td>-0.943933</td>\n",
       "      <td>-0.751633</td>\n",
       "      <td>-1.255035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.662776</td>\n",
       "      <td>0.744273</td>\n",
       "      <td>1.090560</td>\n",
       "      <td>1.671504</td>\n",
       "      <td>0.143752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5557</th>\n",
       "      <td>7</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1.388574</td>\n",
       "      <td>-1.588740</td>\n",
       "      <td>1.668342</td>\n",
       "      <td>-2.120995</td>\n",
       "      <td>-1.008708</td>\n",
       "      <td>0.437772</td>\n",
       "      <td>-1.349101</td>\n",
       "      <td>-0.509246</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.662776</td>\n",
       "      <td>2.592194</td>\n",
       "      <td>-0.287879</td>\n",
       "      <td>0.188535</td>\n",
       "      <td>-0.215628</td>\n",
       "      <td>-0.421433</td>\n",
       "      <td>-0.587996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>12</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.152058</td>\n",
       "      <td>0.604220</td>\n",
       "      <td>-0.529975</td>\n",
       "      <td>0.010677</td>\n",
       "      <td>0.930631</td>\n",
       "      <td>-0.679533</td>\n",
       "      <td>-1.647838</td>\n",
       "      <td>-0.662300</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.290609</td>\n",
       "      <td>0.239572</td>\n",
       "      <td>0.677028</td>\n",
       "      <td>-1.047272</td>\n",
       "      <td>-0.215628</td>\n",
       "      <td>-0.200916</td>\n",
       "      <td>-0.355744</td>\n",
       "      <td>-0.787085</td>\n",
       "      <td>-0.586463</td>\n",
       "      <td>-0.771034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>14</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.106281</td>\n",
       "      <td>1.042812</td>\n",
       "      <td>-0.253615</td>\n",
       "      <td>-0.438097</td>\n",
       "      <td>0.930631</td>\n",
       "      <td>-0.483364</td>\n",
       "      <td>0.044991</td>\n",
       "      <td>0.155841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304858</td>\n",
       "      <td>0.227650</td>\n",
       "      <td>1.710857</td>\n",
       "      <td>-1.047272</td>\n",
       "      <td>-0.575008</td>\n",
       "      <td>-0.366304</td>\n",
       "      <td>-0.317035</td>\n",
       "      <td>0.131181</td>\n",
       "      <td>-0.003205</td>\n",
       "      <td>0.213725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5581</th>\n",
       "      <td>19</td>\n",
       "      <td>negative</td>\n",
       "      <td>-2.212562</td>\n",
       "      <td>-2.027332</td>\n",
       "      <td>0.826701</td>\n",
       "      <td>-0.325903</td>\n",
       "      <td>-2.031269</td>\n",
       "      <td>-0.312784</td>\n",
       "      <td>0.244149</td>\n",
       "      <td>0.609436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.662776</td>\n",
       "      <td>0.648897</td>\n",
       "      <td>-0.839255</td>\n",
       "      <td>-1.541595</td>\n",
       "      <td>-0.215628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.131181</td>\n",
       "      <td>-0.003205</td>\n",
       "      <td>0.213725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5583</th>\n",
       "      <td>19</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1.731902</td>\n",
       "      <td>-1.588740</td>\n",
       "      <td>-0.856582</td>\n",
       "      <td>-0.101517</td>\n",
       "      <td>-1.555249</td>\n",
       "      <td>3.218241</td>\n",
       "      <td>0.144572</td>\n",
       "      <td>-1.928470</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.513909</td>\n",
       "      <td>-0.463830</td>\n",
       "      <td>-1.183864</td>\n",
       "      <td>-0.552949</td>\n",
       "      <td>0.503132</td>\n",
       "      <td>0.074731</td>\n",
       "      <td>-0.278326</td>\n",
       "      <td>-0.480996</td>\n",
       "      <td>-0.003205</td>\n",
       "      <td>-0.771034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5584</th>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1.869234</td>\n",
       "      <td>-1.776707</td>\n",
       "      <td>0.022745</td>\n",
       "      <td>-0.550290</td>\n",
       "      <td>-0.797144</td>\n",
       "      <td>2.570034</td>\n",
       "      <td>-0.054585</td>\n",
       "      <td>1.569499</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.960510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.217694</td>\n",
       "      <td>-1.294433</td>\n",
       "      <td>-0.215628</td>\n",
       "      <td>1.921564</td>\n",
       "      <td>2.276451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5585</th>\n",
       "      <td>18</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.197836</td>\n",
       "      <td>1.356092</td>\n",
       "      <td>-1.911774</td>\n",
       "      <td>1.132609</td>\n",
       "      <td>0.384090</td>\n",
       "      <td>0.966573</td>\n",
       "      <td>0.841616</td>\n",
       "      <td>-0.834833</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.662776</td>\n",
       "      <td>-0.302882</td>\n",
       "      <td>0.608106</td>\n",
       "      <td>0.188535</td>\n",
       "      <td>-0.575008</td>\n",
       "      <td>0.433072</td>\n",
       "      <td>0.418431</td>\n",
       "      <td>-0.174908</td>\n",
       "      <td>-0.003205</td>\n",
       "      <td>-0.278654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5602</th>\n",
       "      <td>19</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.190738</td>\n",
       "      <td>0.165628</td>\n",
       "      <td>-0.102873</td>\n",
       "      <td>0.908221</td>\n",
       "      <td>0.384090</td>\n",
       "      <td>-1.583611</td>\n",
       "      <td>-0.054585</td>\n",
       "      <td>-0.328365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379292</td>\n",
       "      <td>3.627427</td>\n",
       "      <td>0.470262</td>\n",
       "      <td>0.188535</td>\n",
       "      <td>-5.246946</td>\n",
       "      <td>7.930663</td>\n",
       "      <td>7.231172</td>\n",
       "      <td>-0.174908</td>\n",
       "      <td>-0.003205</td>\n",
       "      <td>-0.278654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5614</th>\n",
       "      <td>19</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.289922</td>\n",
       "      <td>-0.523588</td>\n",
       "      <td>0.663397</td>\n",
       "      <td>-0.774677</td>\n",
       "      <td>0.754327</td>\n",
       "      <td>-1.532437</td>\n",
       "      <td>-1.050367</td>\n",
       "      <td>1.569499</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067309</td>\n",
       "      <td>5.733660</td>\n",
       "      <td>0.504723</td>\n",
       "      <td>-0.552949</td>\n",
       "      <td>-0.215628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5615</th>\n",
       "      <td>15</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.717175</td>\n",
       "      <td>1.105468</td>\n",
       "      <td>-0.492289</td>\n",
       "      <td>-0.213711</td>\n",
       "      <td>0.613284</td>\n",
       "      <td>0.002791</td>\n",
       "      <td>1.538664</td>\n",
       "      <td>-0.550988</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.365042</td>\n",
       "      <td>0.561468</td>\n",
       "      <td>-0.494645</td>\n",
       "      <td>0.435697</td>\n",
       "      <td>0.143752</td>\n",
       "      <td>0.874106</td>\n",
       "      <td>1.386150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5618</th>\n",
       "      <td>17</td>\n",
       "      <td>negative</td>\n",
       "      <td>-3.242548</td>\n",
       "      <td>-2.779203</td>\n",
       "      <td>-1.773594</td>\n",
       "      <td>-0.550290</td>\n",
       "      <td>-3.318285</td>\n",
       "      <td>-1.830953</td>\n",
       "      <td>1.538664</td>\n",
       "      <td>-1.733675</td>\n",
       "      <td>...</td>\n",
       "      <td>2.240127</td>\n",
       "      <td>0.609157</td>\n",
       "      <td>0.470262</td>\n",
       "      <td>-0.305787</td>\n",
       "      <td>-1.293767</td>\n",
       "      <td>-0.504127</td>\n",
       "      <td>-0.665414</td>\n",
       "      <td>-0.480996</td>\n",
       "      <td>-0.003205</td>\n",
       "      <td>-0.771034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5643</th>\n",
       "      <td>19</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.694287</td>\n",
       "      <td>0.541564</td>\n",
       "      <td>-0.906829</td>\n",
       "      <td>-0.325903</td>\n",
       "      <td>0.578024</td>\n",
       "      <td>-0.295726</td>\n",
       "      <td>-0.353319</td>\n",
       "      <td>-1.288428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453725</td>\n",
       "      <td>-0.503570</td>\n",
       "      <td>-0.735872</td>\n",
       "      <td>-0.552949</td>\n",
       "      <td>-0.934388</td>\n",
       "      <td>-0.283610</td>\n",
       "      <td>0.108761</td>\n",
       "      <td>-0.480996</td>\n",
       "      <td>-0.586463</td>\n",
       "      <td>-0.278654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>603 rows Ã 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Patient age quantile SARS-Cov-2 exam result  Hematocrit  Hemoglobin  \\\n",
       "1                       17               negative    0.236515   -0.022340   \n",
       "8                        1               negative   -1.571682   -0.774212   \n",
       "15                       9               negative   -0.747693   -0.586244   \n",
       "18                      11               negative    0.991838    0.792188   \n",
       "22                       9               negative    0.190738   -0.147652   \n",
       "28                      13               negative    1.014726    0.854844   \n",
       "29                      14               negative    0.740064    0.854844   \n",
       "30                       9               negative   -0.679027   -0.711556   \n",
       "32                       8               negative    0.236515    0.040316   \n",
       "34                      17               negative    0.808730    1.042812   \n",
       "36                      14               negative   -0.106813   -0.335620   \n",
       "38                      16               negative    1.426721    1.230779   \n",
       "40                      15               negative    0.717175    0.604220   \n",
       "50                      17               negative    1.014726    0.666876   \n",
       "51                       7               negative    0.946061    1.168124   \n",
       "55                      19               negative    0.625621    0.353596   \n",
       "56                       6               negative   -0.152590   -0.460932   \n",
       "59                      10               negative    0.190738    0.040316   \n",
       "61                      11               negative    0.740064    0.604220   \n",
       "62                      11               negative    0.740064    0.541564   \n",
       "71                      16               negative    0.671398    0.290940   \n",
       "73                       6               negative   -0.221256   -0.084996   \n",
       "78                       1               negative   -0.816359   -0.836868   \n",
       "84                       9               negative   -0.656139   -0.899524   \n",
       "86                      19               negative   -0.518807   -0.586244   \n",
       "87                      17               negative    0.442512    0.228284   \n",
       "88                      10               negative   -0.541696   -0.398276   \n",
       "95                      18               negative    0.946061    0.854844   \n",
       "105                     15               negative   -0.450142   -0.460932   \n",
       "106                     14               negative    1.220724    1.356092   \n",
       "...                    ...                    ...         ...         ...   \n",
       "5257                     0               negative   -2.418559   -2.152643   \n",
       "5258                    19               positive   -0.244145   -1.087492   \n",
       "5259                    10               positive   -0.679027   -0.711556   \n",
       "5260                    19               positive   -0.518807   -0.774212   \n",
       "5285                    19               negative   -3.242548   -3.029827   \n",
       "5329                    17               positive    0.968950    1.105468   \n",
       "5341                    13               positive    0.556955    0.416252   \n",
       "5410                    19               negative   -1.136799   -0.962180   \n",
       "5414                    15               positive   -0.244145    0.102972   \n",
       "5423                    17               positive   -0.358588   -0.460932   \n",
       "5434                    19               negative   -0.267033   -0.460932   \n",
       "5437                     0               negative   -2.121008   -2.340612   \n",
       "5451                    10               negative    0.396736    0.165628   \n",
       "5466                     0               negative   -1.182576   -0.836868   \n",
       "5511                     0               negative   -1.159688   -1.275460   \n",
       "5524                    19               positive   -0.793470   -0.774212   \n",
       "5540                    14               positive   -0.312811    0.040316   \n",
       "5553                    18               positive    0.602732    0.353596   \n",
       "5557                     7               negative   -1.388574   -1.588740   \n",
       "5564                    12               positive    1.152058    0.604220   \n",
       "5566                    14               positive    1.106281    1.042812   \n",
       "5581                    19               negative   -2.212562   -2.027332   \n",
       "5583                    19               negative   -1.731902   -1.588740   \n",
       "5584                     0               negative   -1.869234   -1.776707   \n",
       "5585                    18               positive    1.197836    1.356092   \n",
       "5602                    19               negative    0.190738    0.165628   \n",
       "5614                    19               negative   -0.289922   -0.523588   \n",
       "5615                    15               negative    0.717175    1.105468   \n",
       "5618                    17               negative   -3.242548   -2.779203   \n",
       "5643                    19               positive    0.694287    0.541564   \n",
       "\n",
       "      Platelets  Mean platelet volume   Red blood Cells  Lymphocytes  \\\n",
       "1     -0.517413               0.010677         0.102004     0.318366   \n",
       "8      1.429667              -1.672222        -0.850035    -0.005738   \n",
       "15    -0.429480              -0.213711        -1.361315    -1.114514   \n",
       "18     0.072992              -0.550290         0.542763     0.045436   \n",
       "22    -0.668155               1.020415        -0.127191     0.002791   \n",
       "28    -0.178244               0.796029         0.489872    -0.730707   \n",
       "29     0.361914              -0.550290         0.436981    -0.227493   \n",
       "30     0.952319              -0.886869        -0.321124    -0.875701   \n",
       "32     0.072992               0.571643         0.066744     1.239503   \n",
       "34    -0.278739               1.581381         0.701437    -0.261609   \n",
       "36     1.429667              -0.213711        -0.603210     0.326895   \n",
       "38     0.600588              -1.111256         1.265607     0.506005   \n",
       "40     0.399599               0.683835         0.401720     0.011320   \n",
       "50    -0.203368               0.459449         0.295938    -0.261609   \n",
       "51    -0.278739               0.010677         1.177456    -0.671003   \n",
       "55    -0.127997               0.796029         0.190156    -1.592140   \n",
       "56     1.241240              -1.560029        -0.250603    -0.065441   \n",
       "59    -1.057571               0.235063        -0.462168    -1.268037   \n",
       "61     0.160925               0.908221        -0.021409    -0.329842   \n",
       "62    -0.065188               0.683835        -0.215342     0.966573   \n",
       "71     0.135801               0.010677         0.525133     0.173372   \n",
       "73     0.261419               1.356995        -0.162451    -0.031325   \n",
       "78     0.763892              -1.560029        -0.656101    -1.370385   \n",
       "84    -0.391795               0.796029        -0.409276     1.862123   \n",
       "86     0.952319               0.010677        -0.144821     0.429243   \n",
       "87    -0.680717               0.459449         0.736697    -1.165688   \n",
       "88    -0.454604              -0.550290        -0.779514    -1.276566   \n",
       "95    -0.718402               0.908221         0.366460     0.540121   \n",
       "105   -0.542537               1.132609        -0.779514    -0.671003   \n",
       "106    0.500094              -0.550290         1.688736     0.463359   \n",
       "...         ...                    ...              ...          ...   \n",
       "5257   0.952319              -1.672222        -1.237902    -1.694489   \n",
       "5258  -1.045009                    NaN         2.975753    -0.210435   \n",
       "5259  -1.585167               2.254541         0.172526    -1.182746   \n",
       "5260  -1.321369               0.683835        -0.567950    -0.287196   \n",
       "5285  -2.075077               0.796029        -3.476958    -0.065441   \n",
       "5329  -0.127997              -0.662483         0.930631    -0.039854   \n",
       "5341  -0.931953              -0.550290         0.842479     0.412185   \n",
       "5410   0.110677              -0.325903        -1.378946    -0.508952   \n",
       "5414  -1.170627               1.132609        -0.585580    -0.679533   \n",
       "5423  -0.153121               0.122869        -0.215342    -1.353327   \n",
       "5434   2.082882              -1.111256        -0.832405     0.173372   \n",
       "5437   0.952319              -0.774677        -0.973448     0.386598   \n",
       "5451  -0.153121               0.122869        -0.021409     1.009218   \n",
       "5466  -0.693278              -0.101517        -0.462168    -0.671003   \n",
       "5511   3.276253              -0.438097        -1.872596     1.887710   \n",
       "5524  -0.316424               1.020415        -0.638471     0.582766   \n",
       "5540  -0.592784               0.571643        -0.338755     1.589193   \n",
       "5553  -1.082694               1.581381         0.119635    -0.943933   \n",
       "5557   1.668342              -2.120995        -1.008708     0.437772   \n",
       "5564  -0.529975               0.010677         0.930631    -0.679533   \n",
       "5566  -0.253615              -0.438097         0.930631    -0.483364   \n",
       "5581   0.826701              -0.325903        -2.031269    -0.312784   \n",
       "5583  -0.856582              -0.101517        -1.555249     3.218241   \n",
       "5584   0.022745              -0.550290        -0.797144     2.570034   \n",
       "5585  -1.911774               1.132609         0.384090     0.966573   \n",
       "5602  -0.102873               0.908221         0.384090    -1.583611   \n",
       "5614   0.663397              -0.774677         0.754327    -1.532437   \n",
       "5615  -0.492289              -0.213711         0.613284     0.002791   \n",
       "5618  -1.773594              -0.550290        -3.318285    -1.830953   \n",
       "5643  -0.906829              -0.325903         0.578024    -0.295726   \n",
       "\n",
       "      Mean corpuscular hemoglobin concentrationÂ (MCHC)  Leukocytes  ...  \\\n",
       "1                                            -0.950790   -0.094610  ...   \n",
       "8                                             3.331071    0.364550  ...   \n",
       "15                                            0.542882   -0.884923  ...   \n",
       "18                                           -0.452899   -0.211488  ...   \n",
       "22                                           -1.249524   -1.132592  ...   \n",
       "28                                           -0.353319   -0.075131  ...   \n",
       "29                                            0.642463    0.105751  ...   \n",
       "30                                           -0.253742   -0.286623  ...   \n",
       "32                                           -0.652057   -0.545423  ...   \n",
       "34                                            1.040773    0.000005  ...   \n",
       "36                                           -0.950790    0.726313  ...   \n",
       "38                                           -0.353319   -0.022258  ...   \n",
       "40                                           -0.253742   -0.178094  ...   \n",
       "50                                           -0.950790   -0.083479  ...   \n",
       "51                                            1.040773    0.133579  ...   \n",
       "55                                           -0.851210    0.556563  ...   \n",
       "56                                           -1.249524    1.196605  ...   \n",
       "59                                           -0.552476    1.224433  ...   \n",
       "61                                           -0.353319    0.225411  ...   \n",
       "62                                           -0.552476    0.350636  ...   \n",
       "71                                           -1.249524   -0.653951  ...   \n",
       "73                                            0.542882   -0.509246  ...   \n",
       "78                                           -0.253742    1.666897  ...   \n",
       "84                                           -1.149948   -0.681779  ...   \n",
       "86                                           -0.353319   -0.748566  ...   \n",
       "87                                           -0.652057   -0.589947  ...   \n",
       "88                                            0.443306    0.236542  ...   \n",
       "95                                           -0.054585   -1.032411  ...   \n",
       "105                                          -0.154166   -1.138157  ...   \n",
       "106                                           0.742040    1.152081  ...   \n",
       "...                                                ...         ...  ...   \n",
       "5257                                          0.642463    4.224283  ...   \n",
       "5258                                         -3.440245   -1.207727  ...   \n",
       "5259                                         -0.253742    0.158624  ...   \n",
       "5260                                         -1.149948   -1.007366  ...   \n",
       "5285                                          0.044991   -1.636277  ...   \n",
       "5329                                          0.742040   -0.745784  ...   \n",
       "5341                                         -0.353319   -0.884923  ...   \n",
       "5410                                          0.443306    0.403509  ...   \n",
       "5414                                          1.339507   -1.024063  ...   \n",
       "5423                                         -0.452899    0.901629  ...   \n",
       "5434                                         -0.851210    0.623350  ...   \n",
       "5437                                         -1.747415    0.820928  ...   \n",
       "5451                                         -0.751633   -0.837616  ...   \n",
       "5466                                          1.239930    0.495342  ...   \n",
       "5511                                         -0.851210    2.874629  ...   \n",
       "5524                                         -0.154166   -1.004583  ...   \n",
       "5540                                          1.339507   -1.285645  ...   \n",
       "5553                                         -0.751633   -1.255035  ...   \n",
       "5557                                         -1.349101   -0.509246  ...   \n",
       "5564                                         -1.647838   -0.662300  ...   \n",
       "5566                                          0.044991    0.155841  ...   \n",
       "5581                                          0.244149    0.609436  ...   \n",
       "5583                                          0.144572   -1.928470  ...   \n",
       "5584                                         -0.054585    1.569499  ...   \n",
       "5585                                          0.841616   -0.834833  ...   \n",
       "5602                                         -0.054585   -0.328365  ...   \n",
       "5614                                         -1.050367    1.569499  ...   \n",
       "5615                                          1.538664   -0.550988  ...   \n",
       "5618                                          1.538664   -1.733675  ...   \n",
       "5643                                         -0.353319   -1.288428  ...   \n",
       "\n",
       "          Urea  C-reactive protein mg/dL  Creatinine  Potassium    Sodium  \\\n",
       "1     1.198059                 -0.147895    2.089928  -0.305787  0.862512   \n",
       "8    -0.067309                 -0.286986   -1.838623   0.930020  0.503132   \n",
       "15   -0.811643                       NaN   -0.908177   0.435697 -0.215628   \n",
       "18         NaN                 -0.487674         NaN        NaN       NaN   \n",
       "22   -1.332677                       NaN   -0.908177  -0.552949 -0.575008   \n",
       "28   -0.737209                 -0.434025   -0.701411        NaN       NaN   \n",
       "29   -0.141742                 -0.529401    0.332418        NaN       NaN   \n",
       "30   -0.439476                  0.545572    1.021638   0.435697 -1.653147   \n",
       "32   -0.513909                       NaN   -0.391262   0.930020  0.143752   \n",
       "34         NaN                 -0.360505         NaN        NaN       NaN   \n",
       "36         NaN                 -0.519466         NaN        NaN       NaN   \n",
       "38    0.453725                 -0.414154   -0.563567        NaN       NaN   \n",
       "40         NaN                 -0.354544         NaN        NaN       NaN   \n",
       "50    0.825892                 -0.461843    2.124389  -0.800110  0.862512   \n",
       "51   -0.439476                  0.011066    1.297326   0.188535  0.143752   \n",
       "55   -0.737209                  0.611144   -0.494645  -1.541595  0.862512   \n",
       "56         NaN                 -0.451908         NaN        NaN       NaN   \n",
       "59   -0.365042                  2.256389    0.470262  -0.058626 -0.215628   \n",
       "61   -0.141742                 -0.495622    0.022270  -0.305787  1.581271   \n",
       "62   -0.141742                 -0.475752   -0.529106  -0.800110  1.581271   \n",
       "71         NaN                 -0.316791    0.194574   2.412989  0.862512   \n",
       "73         NaN                 -0.521453         NaN        NaN       NaN   \n",
       "78         NaN                  1.727844         NaN        NaN       NaN   \n",
       "84         NaN                 -0.519466         NaN        NaN       NaN   \n",
       "86    1.198059                 -0.283012   -0.873716   0.930020  0.503132   \n",
       "87   -0.365042                 -0.404219    0.573645  -1.047272 -0.215628   \n",
       "88   -1.034943                 -0.243272   -0.977099        NaN       NaN   \n",
       "95    0.155991                 -0.461843    0.573645  -0.058626  0.143752   \n",
       "105  -0.960510                 -0.489661   -0.632489        NaN       NaN   \n",
       "106  -0.290609                  0.650884    0.539184   1.177181 -1.293767   \n",
       "...        ...                       ...         ...        ...       ...   \n",
       "5257 -1.183810                  4.970647   -2.010928  -0.058626 -1.293767   \n",
       "5258 -0.588343                 -0.155843    0.056730  -2.035918  0.862512   \n",
       "5259 -1.183810                 -0.455882   -0.632489        NaN       NaN   \n",
       "5260 -0.216176                  1.622533   -0.563567   0.682859 -0.215628   \n",
       "5285  1.942393                  1.547026    3.296062  -1.294433 -0.575008   \n",
       "5329  0.007125                 -0.342622    0.918255  -1.047272  0.862512   \n",
       "5341 -0.811643                  0.944962    0.573645   0.435697  0.143752   \n",
       "5410  0.304858                  0.895286   -0.977099  -1.541595 -2.012527   \n",
       "5414  1.942393                       NaN    1.159482   0.682859  0.143752   \n",
       "5423  0.900325                       NaN    0.883794   1.177181  0.143752   \n",
       "5434  1.644660                  0.654858    0.366879   0.930020 -1.293767   \n",
       "5437 -0.588343                 -0.394284   -2.252155  -0.058626  0.143752   \n",
       "5451       NaN                 -0.521453   -0.563567        NaN       NaN   \n",
       "5466       NaN                  2.379584         NaN        NaN       NaN   \n",
       "5511       NaN                 -0.165778         NaN        NaN       NaN   \n",
       "5524  0.528158                 -0.364479   -0.425723  -0.800110  0.503132   \n",
       "5540 -1.034943                 -0.533375   -0.563567  -0.058626  0.503132   \n",
       "5553 -0.662776                  0.744273    1.090560   1.671504  0.143752   \n",
       "5557 -0.662776                  2.592194   -0.287879   0.188535 -0.215628   \n",
       "5564 -0.290609                  0.239572    0.677028  -1.047272 -0.215628   \n",
       "5566  0.304858                  0.227650    1.710857  -1.047272 -0.575008   \n",
       "5581 -0.662776                  0.648897   -0.839255  -1.541595 -0.215628   \n",
       "5583 -0.513909                 -0.463830   -1.183864  -0.552949  0.503132   \n",
       "5584 -0.960510                       NaN   -2.217694  -1.294433 -0.215628   \n",
       "5585 -0.662776                 -0.302882    0.608106   0.188535 -0.575008   \n",
       "5602  0.379292                  3.627427    0.470262   0.188535 -5.246946   \n",
       "5614 -0.067309                  5.733660    0.504723  -0.552949 -0.215628   \n",
       "5615 -0.365042                  0.561468   -0.494645   0.435697  0.143752   \n",
       "5618  2.240127                  0.609157    0.470262  -0.305787 -1.293767   \n",
       "5643  0.453725                 -0.503570   -0.735872  -0.552949 -0.934388   \n",
       "\n",
       "      Alanine transaminase  Aspartate transaminase  Total Bilirubin  \\\n",
       "1                      NaN                     NaN              NaN   \n",
       "8                -0.586821               -0.162200              NaN   \n",
       "15               -0.559257               -0.549287              NaN   \n",
       "18                     NaN                     NaN              NaN   \n",
       "22                     NaN                     NaN              NaN   \n",
       "28                     NaN                     NaN              NaN   \n",
       "29                     NaN                     NaN              NaN   \n",
       "30                     NaN                     NaN              NaN   \n",
       "32                     NaN                     NaN              NaN   \n",
       "34                     NaN                     NaN              NaN   \n",
       "36                     NaN                     NaN              NaN   \n",
       "38                     NaN                     NaN              NaN   \n",
       "40               -0.476563               -0.471870              NaN   \n",
       "50               -0.366304               -0.510579         0.131181   \n",
       "51               -0.283610               -0.200909         1.049447   \n",
       "55               -0.448998               -0.278326        -0.174908   \n",
       "56                     NaN                     NaN              NaN   \n",
       "59                     NaN                     NaN              NaN   \n",
       "61                     NaN                     NaN              NaN   \n",
       "62               -0.559257               -0.471870        -1.093174   \n",
       "71                     NaN                     NaN              NaN   \n",
       "73                     NaN                     NaN              NaN   \n",
       "78                     NaN                     NaN              NaN   \n",
       "84                     NaN                     NaN              NaN   \n",
       "86               -0.531692               -0.510579              NaN   \n",
       "87                1.149753               -0.239617         1.355535   \n",
       "88                     NaN                     NaN              NaN   \n",
       "95                     NaN                     NaN              NaN   \n",
       "105                    NaN                     NaN              NaN   \n",
       "106               0.212554               -0.355744              NaN   \n",
       "...                    ...                     ...              ...   \n",
       "5257              1.563223                2.508704              NaN   \n",
       "5258                   NaN                     NaN              NaN   \n",
       "5259              2.886328                6.998919        -0.787085   \n",
       "5260                   NaN                     NaN        -0.480996   \n",
       "5285              0.763848                1.037771        -0.174908   \n",
       "5329              0.240119                0.147470              NaN   \n",
       "5341              0.736283                0.186179        -0.174908   \n",
       "5410                   NaN                     NaN        -0.480996   \n",
       "5414                   NaN                     NaN        -0.174908   \n",
       "5423             -0.007963                0.302305        -0.174908   \n",
       "5434                   NaN                     NaN        -0.480996   \n",
       "5437             -0.338739                0.147470        -0.787085   \n",
       "5451                   NaN                     NaN              NaN   \n",
       "5466                   NaN                     NaN              NaN   \n",
       "5511                   NaN                     NaN              NaN   \n",
       "5524             -0.063092                0.147470         0.437270   \n",
       "5540             -0.559257               -0.433161              NaN   \n",
       "5553                   NaN                     NaN              NaN   \n",
       "5557             -0.421433               -0.587996              NaN   \n",
       "5564             -0.200916               -0.355744        -0.787085   \n",
       "5566             -0.366304               -0.317035         0.131181   \n",
       "5581                   NaN                     NaN         0.131181   \n",
       "5583              0.074731               -0.278326        -0.480996   \n",
       "5584              1.921564                2.276451              NaN   \n",
       "5585              0.433072                0.418431        -0.174908   \n",
       "5602              7.930663                7.231172        -0.174908   \n",
       "5614                   NaN                     NaN              NaN   \n",
       "5615              0.874106                1.386150              NaN   \n",
       "5618             -0.504127               -0.665414        -0.480996   \n",
       "5643             -0.283610                0.108761        -0.480996   \n",
       "\n",
       "      Direct Bilirubin  Indirect Bilirubin  \n",
       "1                  NaN                 NaN  \n",
       "8                  NaN                 NaN  \n",
       "15                 NaN                 NaN  \n",
       "18                 NaN                 NaN  \n",
       "22                 NaN                 NaN  \n",
       "28                 NaN                 NaN  \n",
       "29                 NaN                 NaN  \n",
       "30                 NaN                 NaN  \n",
       "32                 NaN                 NaN  \n",
       "34                 NaN                 NaN  \n",
       "36                 NaN                 NaN  \n",
       "38                 NaN                 NaN  \n",
       "40                 NaN                 NaN  \n",
       "50            0.580054           -0.278654  \n",
       "51           -0.003205            1.690864  \n",
       "55           -0.003205           -0.278654  \n",
       "56                 NaN                 NaN  \n",
       "59                 NaN                 NaN  \n",
       "61                 NaN                 NaN  \n",
       "62           -1.169722           -0.771034  \n",
       "71                 NaN                 NaN  \n",
       "73                 NaN                 NaN  \n",
       "78                 NaN                 NaN  \n",
       "84                 NaN                 NaN  \n",
       "86                 NaN                 NaN  \n",
       "87            0.580054            1.690864  \n",
       "88                 NaN                 NaN  \n",
       "95                 NaN                 NaN  \n",
       "105                NaN                 NaN  \n",
       "106                NaN                 NaN  \n",
       "...                ...                 ...  \n",
       "5257               NaN                 NaN  \n",
       "5258               NaN                 NaN  \n",
       "5259         -0.586463           -0.771034  \n",
       "5260         -0.003205           -0.771034  \n",
       "5285          0.580054           -0.771034  \n",
       "5329               NaN                 NaN  \n",
       "5341         -0.003205           -0.278654  \n",
       "5410         -0.586463           -0.278654  \n",
       "5414         -0.003205           -0.278654  \n",
       "5423         -0.003205           -0.278654  \n",
       "5434         -0.586463           -0.278654  \n",
       "5437         -0.586463           -0.771034  \n",
       "5451               NaN                 NaN  \n",
       "5466               NaN                 NaN  \n",
       "5511               NaN                 NaN  \n",
       "5524          0.580054            0.213725  \n",
       "5540               NaN                 NaN  \n",
       "5553               NaN                 NaN  \n",
       "5557               NaN                 NaN  \n",
       "5564         -0.586463           -0.771034  \n",
       "5566         -0.003205            0.213725  \n",
       "5581         -0.003205            0.213725  \n",
       "5583         -0.003205           -0.771034  \n",
       "5584               NaN                 NaN  \n",
       "5585         -0.003205           -0.278654  \n",
       "5602         -0.003205           -0.278654  \n",
       "5614               NaN                 NaN  \n",
       "5615               NaN                 NaN  \n",
       "5618         -0.003205           -0.771034  \n",
       "5643         -0.586463           -0.278654  \n",
       "\n",
       "[603 rows x 28 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No categorical_cols passed so inferred using np.object, np.int8 and np.bool: Index(['SARS-Cov-2 exam result'], dtype='object'). If you see an error these are not correct, please provide them as a string array as: categorical_cols=['col1', 'col2', ...]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ims = xai.imbalance_plot(df_clean, \"SARS-Cov-2 exam result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bal_df = xai.balance(df_clean, \"SARS-Cov-2 exam result\", upsample=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.asarray(bal_df['SARS-Cov-2 exam result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [1 if x == 'positive' else 0 for x in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bal_df.drop(['SARS-Cov-2 exam result'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = pd.DataFrame(imputer.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf.columns=X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf.index=X.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient age quantile</th>\n",
       "      <th>Hematocrit</th>\n",
       "      <th>Hemoglobin</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Mean platelet volume</th>\n",
       "      <th>Red blood Cells</th>\n",
       "      <th>Lymphocytes</th>\n",
       "      <th>Mean corpuscular hemoglobin concentrationÂ (MCHC)</th>\n",
       "      <th>Leukocytes</th>\n",
       "      <th>Basophils</th>\n",
       "      <th>...</th>\n",
       "      <th>Urea</th>\n",
       "      <th>C-reactive protein mg/dL</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>Potassium</th>\n",
       "      <th>Sodium</th>\n",
       "      <th>Alanine transaminase</th>\n",
       "      <th>Aspartate transaminase</th>\n",
       "      <th>Total Bilirubin</th>\n",
       "      <th>Direct Bilirubin</th>\n",
       "      <th>Indirect Bilirubin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.236515</td>\n",
       "      <td>-0.022340</td>\n",
       "      <td>-0.517413</td>\n",
       "      <td>0.010677</td>\n",
       "      <td>0.102004</td>\n",
       "      <td>0.318366</td>\n",
       "      <td>-0.950790</td>\n",
       "      <td>-0.094610</td>\n",
       "      <td>-0.223767</td>\n",
       "      <td>...</td>\n",
       "      <td>1.198059</td>\n",
       "      <td>-0.147895</td>\n",
       "      <td>2.089928</td>\n",
       "      <td>-0.305787</td>\n",
       "      <td>0.862512</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.571682</td>\n",
       "      <td>-0.774212</td>\n",
       "      <td>1.429667</td>\n",
       "      <td>-1.672222</td>\n",
       "      <td>-0.850035</td>\n",
       "      <td>-0.005738</td>\n",
       "      <td>3.331071</td>\n",
       "      <td>0.364550</td>\n",
       "      <td>-0.223767</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067309</td>\n",
       "      <td>-0.286986</td>\n",
       "      <td>-1.838623</td>\n",
       "      <td>0.930020</td>\n",
       "      <td>0.503132</td>\n",
       "      <td>-0.586821</td>\n",
       "      <td>-0.162200</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.747693</td>\n",
       "      <td>-0.586244</td>\n",
       "      <td>-0.429480</td>\n",
       "      <td>-0.213711</td>\n",
       "      <td>-1.361315</td>\n",
       "      <td>-1.114514</td>\n",
       "      <td>0.542882</td>\n",
       "      <td>-0.884923</td>\n",
       "      <td>0.081693</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.811643</td>\n",
       "      <td>0.046557</td>\n",
       "      <td>-0.908177</td>\n",
       "      <td>0.435697</td>\n",
       "      <td>-0.215628</td>\n",
       "      <td>-0.559257</td>\n",
       "      <td>-0.549287</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.991838</td>\n",
       "      <td>0.792188</td>\n",
       "      <td>0.072992</td>\n",
       "      <td>-0.550290</td>\n",
       "      <td>0.542763</td>\n",
       "      <td>0.045436</td>\n",
       "      <td>-0.452899</td>\n",
       "      <td>-0.211488</td>\n",
       "      <td>-0.834685</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037446</td>\n",
       "      <td>-0.487674</td>\n",
       "      <td>0.039630</td>\n",
       "      <td>-0.058104</td>\n",
       "      <td>-0.082581</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.190738</td>\n",
       "      <td>-0.147652</td>\n",
       "      <td>-0.668155</td>\n",
       "      <td>1.020415</td>\n",
       "      <td>-0.127191</td>\n",
       "      <td>0.002791</td>\n",
       "      <td>-1.249524</td>\n",
       "      <td>-1.132592</td>\n",
       "      <td>0.387152</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.332677</td>\n",
       "      <td>0.046557</td>\n",
       "      <td>-0.908177</td>\n",
       "      <td>-0.552949</td>\n",
       "      <td>-0.575008</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.014726</td>\n",
       "      <td>0.854844</td>\n",
       "      <td>-0.178244</td>\n",
       "      <td>0.796029</td>\n",
       "      <td>0.489872</td>\n",
       "      <td>-0.730707</td>\n",
       "      <td>-0.353319</td>\n",
       "      <td>-0.075131</td>\n",
       "      <td>2.525365</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.737209</td>\n",
       "      <td>-0.434025</td>\n",
       "      <td>-0.701411</td>\n",
       "      <td>-0.058104</td>\n",
       "      <td>-0.082581</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.740064</td>\n",
       "      <td>0.854844</td>\n",
       "      <td>0.361914</td>\n",
       "      <td>-0.550290</td>\n",
       "      <td>0.436981</td>\n",
       "      <td>-0.227493</td>\n",
       "      <td>0.642463</td>\n",
       "      <td>0.105751</td>\n",
       "      <td>-0.529226</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.141742</td>\n",
       "      <td>-0.529401</td>\n",
       "      <td>0.332418</td>\n",
       "      <td>-0.058104</td>\n",
       "      <td>-0.082581</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.679027</td>\n",
       "      <td>-0.711556</td>\n",
       "      <td>0.952319</td>\n",
       "      <td>-0.886869</td>\n",
       "      <td>-0.321124</td>\n",
       "      <td>-0.875701</td>\n",
       "      <td>-0.253742</td>\n",
       "      <td>-0.286623</td>\n",
       "      <td>-0.223767</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.439476</td>\n",
       "      <td>0.545572</td>\n",
       "      <td>1.021638</td>\n",
       "      <td>0.435697</td>\n",
       "      <td>-1.653147</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.236515</td>\n",
       "      <td>0.040316</td>\n",
       "      <td>0.072992</td>\n",
       "      <td>0.571643</td>\n",
       "      <td>0.066744</td>\n",
       "      <td>1.239503</td>\n",
       "      <td>-0.652057</td>\n",
       "      <td>-0.545423</td>\n",
       "      <td>0.998070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.513909</td>\n",
       "      <td>0.046557</td>\n",
       "      <td>-0.391262</td>\n",
       "      <td>0.930020</td>\n",
       "      <td>0.143752</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.808730</td>\n",
       "      <td>1.042812</td>\n",
       "      <td>-0.278739</td>\n",
       "      <td>1.581381</td>\n",
       "      <td>0.701437</td>\n",
       "      <td>-0.261609</td>\n",
       "      <td>1.040773</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.387152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037446</td>\n",
       "      <td>-0.360505</td>\n",
       "      <td>0.039630</td>\n",
       "      <td>-0.058104</td>\n",
       "      <td>-0.082581</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14.0</td>\n",
       "      <td>-0.106813</td>\n",
       "      <td>-0.335620</td>\n",
       "      <td>1.429667</td>\n",
       "      <td>-0.213711</td>\n",
       "      <td>-0.603210</td>\n",
       "      <td>0.326895</td>\n",
       "      <td>-0.950790</td>\n",
       "      <td>0.726313</td>\n",
       "      <td>0.081693</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037446</td>\n",
       "      <td>-0.519466</td>\n",
       "      <td>0.039630</td>\n",
       "      <td>-0.058104</td>\n",
       "      <td>-0.082581</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1.426721</td>\n",
       "      <td>1.230779</td>\n",
       "      <td>0.600588</td>\n",
       "      <td>-1.111256</td>\n",
       "      <td>1.265607</td>\n",
       "      <td>0.506005</td>\n",
       "      <td>-0.353319</td>\n",
       "      <td>-0.022258</td>\n",
       "      <td>0.692611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453725</td>\n",
       "      <td>-0.414154</td>\n",
       "      <td>-0.563567</td>\n",
       "      <td>-0.058104</td>\n",
       "      <td>-0.082581</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.717175</td>\n",
       "      <td>0.604220</td>\n",
       "      <td>0.399599</td>\n",
       "      <td>0.683835</td>\n",
       "      <td>0.401720</td>\n",
       "      <td>0.011320</td>\n",
       "      <td>-0.253742</td>\n",
       "      <td>-0.178094</td>\n",
       "      <td>0.387152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037446</td>\n",
       "      <td>-0.354544</td>\n",
       "      <td>0.039630</td>\n",
       "      <td>-0.058104</td>\n",
       "      <td>-0.082581</td>\n",
       "      <td>-0.476563</td>\n",
       "      <td>-0.471870</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1.014726</td>\n",
       "      <td>0.666876</td>\n",
       "      <td>-0.203368</td>\n",
       "      <td>0.459449</td>\n",
       "      <td>0.295938</td>\n",
       "      <td>-0.261609</td>\n",
       "      <td>-0.950790</td>\n",
       "      <td>-0.083479</td>\n",
       "      <td>-0.223767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.825892</td>\n",
       "      <td>-0.461843</td>\n",
       "      <td>2.124389</td>\n",
       "      <td>-0.800110</td>\n",
       "      <td>0.862512</td>\n",
       "      <td>-0.366304</td>\n",
       "      <td>-0.510579</td>\n",
       "      <td>0.131181</td>\n",
       "      <td>0.580054</td>\n",
       "      <td>-0.278654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.946061</td>\n",
       "      <td>1.168124</td>\n",
       "      <td>-0.278739</td>\n",
       "      <td>0.010677</td>\n",
       "      <td>1.177456</td>\n",
       "      <td>-0.671003</td>\n",
       "      <td>1.040773</td>\n",
       "      <td>0.133579</td>\n",
       "      <td>0.692611</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.439476</td>\n",
       "      <td>0.011066</td>\n",
       "      <td>1.297326</td>\n",
       "      <td>0.188535</td>\n",
       "      <td>0.143752</td>\n",
       "      <td>-0.283610</td>\n",
       "      <td>-0.200909</td>\n",
       "      <td>1.049447</td>\n",
       "      <td>-0.003205</td>\n",
       "      <td>1.690864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.625621</td>\n",
       "      <td>0.353596</td>\n",
       "      <td>-0.127997</td>\n",
       "      <td>0.796029</td>\n",
       "      <td>0.190156</td>\n",
       "      <td>-1.592140</td>\n",
       "      <td>-0.851210</td>\n",
       "      <td>0.556563</td>\n",
       "      <td>0.081693</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.737209</td>\n",
       "      <td>0.611144</td>\n",
       "      <td>-0.494645</td>\n",
       "      <td>-1.541595</td>\n",
       "      <td>0.862512</td>\n",
       "      <td>-0.448998</td>\n",
       "      <td>-0.278326</td>\n",
       "      <td>-0.174908</td>\n",
       "      <td>-0.003205</td>\n",
       "      <td>-0.278654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.152590</td>\n",
       "      <td>-0.460932</td>\n",
       "      <td>1.241240</td>\n",
       "      <td>-1.560029</td>\n",
       "      <td>-0.250603</td>\n",
       "      <td>-0.065441</td>\n",
       "      <td>-1.249524</td>\n",
       "      <td>1.196605</td>\n",
       "      <td>-0.529226</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037446</td>\n",
       "      <td>-0.451908</td>\n",
       "      <td>0.039630</td>\n",
       "      <td>-0.058104</td>\n",
       "      <td>-0.082581</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.190738</td>\n",
       "      <td>0.040316</td>\n",
       "      <td>-1.057571</td>\n",
       "      <td>0.235063</td>\n",
       "      <td>-0.462168</td>\n",
       "      <td>-1.268037</td>\n",
       "      <td>-0.552476</td>\n",
       "      <td>1.224433</td>\n",
       "      <td>-0.529226</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.365042</td>\n",
       "      <td>2.256389</td>\n",
       "      <td>0.470262</td>\n",
       "      <td>-0.058626</td>\n",
       "      <td>-0.215628</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.740064</td>\n",
       "      <td>0.604220</td>\n",
       "      <td>0.160925</td>\n",
       "      <td>0.908221</td>\n",
       "      <td>-0.021409</td>\n",
       "      <td>-0.329842</td>\n",
       "      <td>-0.353319</td>\n",
       "      <td>0.225411</td>\n",
       "      <td>-0.223767</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.141742</td>\n",
       "      <td>-0.495622</td>\n",
       "      <td>0.022270</td>\n",
       "      <td>-0.305787</td>\n",
       "      <td>1.581271</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.740064</td>\n",
       "      <td>0.541564</td>\n",
       "      <td>-0.065188</td>\n",
       "      <td>0.683835</td>\n",
       "      <td>-0.215342</td>\n",
       "      <td>0.966573</td>\n",
       "      <td>-0.552476</td>\n",
       "      <td>0.350636</td>\n",
       "      <td>0.081693</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.141742</td>\n",
       "      <td>-0.475752</td>\n",
       "      <td>-0.529106</td>\n",
       "      <td>-0.800110</td>\n",
       "      <td>1.581271</td>\n",
       "      <td>-0.559257</td>\n",
       "      <td>-0.471870</td>\n",
       "      <td>-1.093174</td>\n",
       "      <td>-1.169722</td>\n",
       "      <td>-0.771034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.671398</td>\n",
       "      <td>0.290940</td>\n",
       "      <td>0.135801</td>\n",
       "      <td>0.010677</td>\n",
       "      <td>0.525133</td>\n",
       "      <td>0.173372</td>\n",
       "      <td>-1.249524</td>\n",
       "      <td>-0.653951</td>\n",
       "      <td>0.081693</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037446</td>\n",
       "      <td>-0.316791</td>\n",
       "      <td>0.194574</td>\n",
       "      <td>2.412989</td>\n",
       "      <td>0.862512</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.221256</td>\n",
       "      <td>-0.084996</td>\n",
       "      <td>0.261419</td>\n",
       "      <td>1.356995</td>\n",
       "      <td>-0.162451</td>\n",
       "      <td>-0.031325</td>\n",
       "      <td>0.542882</td>\n",
       "      <td>-0.509246</td>\n",
       "      <td>-0.529226</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037446</td>\n",
       "      <td>-0.521453</td>\n",
       "      <td>0.039630</td>\n",
       "      <td>-0.058104</td>\n",
       "      <td>-0.082581</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.816359</td>\n",
       "      <td>-0.836868</td>\n",
       "      <td>0.763892</td>\n",
       "      <td>-1.560029</td>\n",
       "      <td>-0.656101</td>\n",
       "      <td>-1.370385</td>\n",
       "      <td>-0.253742</td>\n",
       "      <td>1.666897</td>\n",
       "      <td>-0.529226</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037446</td>\n",
       "      <td>1.727844</td>\n",
       "      <td>0.039630</td>\n",
       "      <td>-0.058104</td>\n",
       "      <td>-0.082581</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.656139</td>\n",
       "      <td>-0.899524</td>\n",
       "      <td>-0.391795</td>\n",
       "      <td>0.796029</td>\n",
       "      <td>-0.409276</td>\n",
       "      <td>1.862123</td>\n",
       "      <td>-1.149948</td>\n",
       "      <td>-0.681779</td>\n",
       "      <td>-0.529226</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037446</td>\n",
       "      <td>-0.519466</td>\n",
       "      <td>0.039630</td>\n",
       "      <td>-0.058104</td>\n",
       "      <td>-0.082581</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>19.0</td>\n",
       "      <td>-0.518807</td>\n",
       "      <td>-0.586244</td>\n",
       "      <td>0.952319</td>\n",
       "      <td>0.010677</td>\n",
       "      <td>-0.144821</td>\n",
       "      <td>0.429243</td>\n",
       "      <td>-0.353319</td>\n",
       "      <td>-0.748566</td>\n",
       "      <td>1.303529</td>\n",
       "      <td>...</td>\n",
       "      <td>1.198059</td>\n",
       "      <td>-0.283012</td>\n",
       "      <td>-0.873716</td>\n",
       "      <td>0.930020</td>\n",
       "      <td>0.503132</td>\n",
       "      <td>-0.531692</td>\n",
       "      <td>-0.510579</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.442512</td>\n",
       "      <td>0.228284</td>\n",
       "      <td>-0.680717</td>\n",
       "      <td>0.459449</td>\n",
       "      <td>0.736697</td>\n",
       "      <td>-1.165688</td>\n",
       "      <td>-0.652057</td>\n",
       "      <td>-0.589947</td>\n",
       "      <td>-0.529226</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.365042</td>\n",
       "      <td>-0.404219</td>\n",
       "      <td>0.573645</td>\n",
       "      <td>-1.047272</td>\n",
       "      <td>-0.215628</td>\n",
       "      <td>1.149753</td>\n",
       "      <td>-0.239617</td>\n",
       "      <td>1.355535</td>\n",
       "      <td>0.580054</td>\n",
       "      <td>1.690864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.541696</td>\n",
       "      <td>-0.398276</td>\n",
       "      <td>-0.454604</td>\n",
       "      <td>-0.550290</td>\n",
       "      <td>-0.779514</td>\n",
       "      <td>-1.276566</td>\n",
       "      <td>0.443306</td>\n",
       "      <td>0.236542</td>\n",
       "      <td>-0.223767</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.034943</td>\n",
       "      <td>-0.243272</td>\n",
       "      <td>-0.977099</td>\n",
       "      <td>-0.058104</td>\n",
       "      <td>-0.082581</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.946061</td>\n",
       "      <td>0.854844</td>\n",
       "      <td>-0.718402</td>\n",
       "      <td>0.908221</td>\n",
       "      <td>0.366460</td>\n",
       "      <td>0.540121</td>\n",
       "      <td>-0.054585</td>\n",
       "      <td>-1.032411</td>\n",
       "      <td>0.387152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155991</td>\n",
       "      <td>-0.461843</td>\n",
       "      <td>0.573645</td>\n",
       "      <td>-0.058626</td>\n",
       "      <td>0.143752</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.450142</td>\n",
       "      <td>-0.460932</td>\n",
       "      <td>-0.542537</td>\n",
       "      <td>1.132609</td>\n",
       "      <td>-0.779514</td>\n",
       "      <td>-0.671003</td>\n",
       "      <td>-0.154166</td>\n",
       "      <td>-1.138157</td>\n",
       "      <td>-1.140144</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.960510</td>\n",
       "      <td>-0.489661</td>\n",
       "      <td>-0.632489</td>\n",
       "      <td>-0.058104</td>\n",
       "      <td>-0.082581</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.220724</td>\n",
       "      <td>1.356092</td>\n",
       "      <td>0.500094</td>\n",
       "      <td>-0.550290</td>\n",
       "      <td>1.688736</td>\n",
       "      <td>0.463359</td>\n",
       "      <td>0.742040</td>\n",
       "      <td>1.152081</td>\n",
       "      <td>-0.834685</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.290609</td>\n",
       "      <td>0.650884</td>\n",
       "      <td>0.539184</td>\n",
       "      <td>1.177181</td>\n",
       "      <td>-1.293767</td>\n",
       "      <td>0.212554</td>\n",
       "      <td>-0.355744</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>14.0</td>\n",
       "      <td>-0.518807</td>\n",
       "      <td>-0.272964</td>\n",
       "      <td>-0.215930</td>\n",
       "      <td>0.459449</td>\n",
       "      <td>-0.515058</td>\n",
       "      <td>-0.457777</td>\n",
       "      <td>0.941197</td>\n",
       "      <td>-0.573250</td>\n",
       "      <td>-0.223767</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.588343</td>\n",
       "      <td>-0.340635</td>\n",
       "      <td>0.435801</td>\n",
       "      <td>-0.800110</td>\n",
       "      <td>-0.575008</td>\n",
       "      <td>0.598460</td>\n",
       "      <td>0.147470</td>\n",
       "      <td>-0.787085</td>\n",
       "      <td>-0.586463</td>\n",
       "      <td>-0.771034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>13.0</td>\n",
       "      <td>-0.953691</td>\n",
       "      <td>-0.962180</td>\n",
       "      <td>-1.057571</td>\n",
       "      <td>0.796029</td>\n",
       "      <td>-1.008708</td>\n",
       "      <td>2.075349</td>\n",
       "      <td>-0.253742</td>\n",
       "      <td>-1.071370</td>\n",
       "      <td>0.387152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304858</td>\n",
       "      <td>-0.485687</td>\n",
       "      <td>-0.425723</td>\n",
       "      <td>0.435697</td>\n",
       "      <td>0.143752</td>\n",
       "      <td>-0.559257</td>\n",
       "      <td>-0.355744</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.167850</td>\n",
       "      <td>0.165628</td>\n",
       "      <td>-1.007324</td>\n",
       "      <td>0.571643</td>\n",
       "      <td>-0.021409</td>\n",
       "      <td>-0.082499</td>\n",
       "      <td>0.044991</td>\n",
       "      <td>-0.843181</td>\n",
       "      <td>0.081693</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.811643</td>\n",
       "      <td>0.046557</td>\n",
       "      <td>0.056730</td>\n",
       "      <td>-0.552949</td>\n",
       "      <td>-0.215628</td>\n",
       "      <td>-0.311175</td>\n",
       "      <td>-0.162200</td>\n",
       "      <td>-0.787085</td>\n",
       "      <td>-0.586463</td>\n",
       "      <td>-0.771034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>14.0</td>\n",
       "      <td>-0.312811</td>\n",
       "      <td>-0.648900</td>\n",
       "      <td>-0.027502</td>\n",
       "      <td>-0.101517</td>\n",
       "      <td>-0.656101</td>\n",
       "      <td>-0.099557</td>\n",
       "      <td>-1.448681</td>\n",
       "      <td>-0.968407</td>\n",
       "      <td>-0.529226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304858</td>\n",
       "      <td>-0.479726</td>\n",
       "      <td>-0.046652</td>\n",
       "      <td>0.682859</td>\n",
       "      <td>1.940651</td>\n",
       "      <td>-0.504127</td>\n",
       "      <td>-0.394452</td>\n",
       "      <td>-0.787085</td>\n",
       "      <td>-0.586463</td>\n",
       "      <td>-0.771034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1.197836</td>\n",
       "      <td>1.356092</td>\n",
       "      <td>-1.911774</td>\n",
       "      <td>1.132609</td>\n",
       "      <td>0.384090</td>\n",
       "      <td>0.966573</td>\n",
       "      <td>0.841616</td>\n",
       "      <td>-0.834833</td>\n",
       "      <td>-0.529226</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.662776</td>\n",
       "      <td>-0.302882</td>\n",
       "      <td>0.608106</td>\n",
       "      <td>0.188535</td>\n",
       "      <td>-0.575008</td>\n",
       "      <td>0.433072</td>\n",
       "      <td>0.418431</td>\n",
       "      <td>-0.174908</td>\n",
       "      <td>-0.003205</td>\n",
       "      <td>-0.278654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.495919</td>\n",
       "      <td>-0.398276</td>\n",
       "      <td>-0.718402</td>\n",
       "      <td>-0.438097</td>\n",
       "      <td>-0.567950</td>\n",
       "      <td>-0.935404</td>\n",
       "      <td>0.244149</td>\n",
       "      <td>-0.820919</td>\n",
       "      <td>-1.140144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974759</td>\n",
       "      <td>-0.247246</td>\n",
       "      <td>0.160114</td>\n",
       "      <td>-1.047272</td>\n",
       "      <td>0.862512</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>14.0</td>\n",
       "      <td>-0.518807</td>\n",
       "      <td>-0.272964</td>\n",
       "      <td>-0.215930</td>\n",
       "      <td>0.459449</td>\n",
       "      <td>-0.515058</td>\n",
       "      <td>-0.457777</td>\n",
       "      <td>0.941197</td>\n",
       "      <td>-0.573250</td>\n",
       "      <td>-0.223767</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.588343</td>\n",
       "      <td>-0.340635</td>\n",
       "      <td>0.435801</td>\n",
       "      <td>-0.800110</td>\n",
       "      <td>-0.575008</td>\n",
       "      <td>0.598460</td>\n",
       "      <td>0.147470</td>\n",
       "      <td>-0.787085</td>\n",
       "      <td>-0.586463</td>\n",
       "      <td>-0.771034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>14.0</td>\n",
       "      <td>-0.518807</td>\n",
       "      <td>-0.272964</td>\n",
       "      <td>-0.215930</td>\n",
       "      <td>0.459449</td>\n",
       "      <td>-0.515058</td>\n",
       "      <td>-0.457777</td>\n",
       "      <td>0.941197</td>\n",
       "      <td>-0.573250</td>\n",
       "      <td>-0.223767</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.588343</td>\n",
       "      <td>-0.340635</td>\n",
       "      <td>0.435801</td>\n",
       "      <td>-0.800110</td>\n",
       "      <td>-0.575008</td>\n",
       "      <td>0.598460</td>\n",
       "      <td>0.147470</td>\n",
       "      <td>-0.787085</td>\n",
       "      <td>-0.586463</td>\n",
       "      <td>-0.771034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.495919</td>\n",
       "      <td>-0.398276</td>\n",
       "      <td>-0.718402</td>\n",
       "      <td>-0.438097</td>\n",
       "      <td>-0.567950</td>\n",
       "      <td>-0.935404</td>\n",
       "      <td>0.244149</td>\n",
       "      <td>-0.820919</td>\n",
       "      <td>-1.140144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974759</td>\n",
       "      <td>-0.247246</td>\n",
       "      <td>0.160114</td>\n",
       "      <td>-1.047272</td>\n",
       "      <td>0.862512</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.106813</td>\n",
       "      <td>-0.398276</td>\n",
       "      <td>-0.391795</td>\n",
       "      <td>-0.213711</td>\n",
       "      <td>-0.708992</td>\n",
       "      <td>-0.679533</td>\n",
       "      <td>-1.149948</td>\n",
       "      <td>-0.909968</td>\n",
       "      <td>-0.529226</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037446</td>\n",
       "      <td>0.046557</td>\n",
       "      <td>0.039630</td>\n",
       "      <td>-0.058104</td>\n",
       "      <td>-0.082581</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>11.0</td>\n",
       "      <td>-0.450142</td>\n",
       "      <td>0.040316</td>\n",
       "      <td>-0.492289</td>\n",
       "      <td>-0.774677</td>\n",
       "      <td>-0.409276</td>\n",
       "      <td>-1.378914</td>\n",
       "      <td>1.936978</td>\n",
       "      <td>0.038964</td>\n",
       "      <td>-0.529226</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.365042</td>\n",
       "      <td>3.086960</td>\n",
       "      <td>-0.356801</td>\n",
       "      <td>-0.552949</td>\n",
       "      <td>-1.293767</td>\n",
       "      <td>0.322813</td>\n",
       "      <td>-0.046074</td>\n",
       "      <td>0.131181</td>\n",
       "      <td>-0.003205</td>\n",
       "      <td>0.213725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>17.0</td>\n",
       "      <td>-0.358588</td>\n",
       "      <td>-0.460932</td>\n",
       "      <td>-0.153121</td>\n",
       "      <td>0.122869</td>\n",
       "      <td>-0.215342</td>\n",
       "      <td>-1.353327</td>\n",
       "      <td>-0.452899</td>\n",
       "      <td>0.901629</td>\n",
       "      <td>-0.529226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900325</td>\n",
       "      <td>0.046557</td>\n",
       "      <td>0.883794</td>\n",
       "      <td>1.177181</td>\n",
       "      <td>0.143752</td>\n",
       "      <td>-0.007963</td>\n",
       "      <td>0.302305</td>\n",
       "      <td>-0.174908</td>\n",
       "      <td>-0.003205</td>\n",
       "      <td>-0.278654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.694287</td>\n",
       "      <td>0.729532</td>\n",
       "      <td>-0.743526</td>\n",
       "      <td>0.235063</td>\n",
       "      <td>0.595655</td>\n",
       "      <td>-0.636887</td>\n",
       "      <td>0.343725</td>\n",
       "      <td>-0.606644</td>\n",
       "      <td>-0.223767</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037446</td>\n",
       "      <td>-0.511518</td>\n",
       "      <td>0.039630</td>\n",
       "      <td>-0.058104</td>\n",
       "      <td>-0.082581</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>14.0</td>\n",
       "      <td>-0.312811</td>\n",
       "      <td>-0.648900</td>\n",
       "      <td>-0.027502</td>\n",
       "      <td>-0.101517</td>\n",
       "      <td>-0.656101</td>\n",
       "      <td>-0.099557</td>\n",
       "      <td>-1.448681</td>\n",
       "      <td>-0.968407</td>\n",
       "      <td>-0.529226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304858</td>\n",
       "      <td>-0.479726</td>\n",
       "      <td>-0.046652</td>\n",
       "      <td>0.682859</td>\n",
       "      <td>1.940651</td>\n",
       "      <td>-0.504127</td>\n",
       "      <td>-0.394452</td>\n",
       "      <td>-0.787085</td>\n",
       "      <td>-0.586463</td>\n",
       "      <td>-0.771034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>19.0</td>\n",
       "      <td>-0.106813</td>\n",
       "      <td>-0.272964</td>\n",
       "      <td>-0.894267</td>\n",
       "      <td>0.796029</td>\n",
       "      <td>-0.338755</td>\n",
       "      <td>-0.346900</td>\n",
       "      <td>-0.652057</td>\n",
       "      <td>-0.898837</td>\n",
       "      <td>0.081693</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.141742</td>\n",
       "      <td>0.217715</td>\n",
       "      <td>0.849333</td>\n",
       "      <td>0.930020</td>\n",
       "      <td>-0.934388</td>\n",
       "      <td>-0.504127</td>\n",
       "      <td>-0.239617</td>\n",
       "      <td>0.131181</td>\n",
       "      <td>-0.003205</td>\n",
       "      <td>0.213725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.129169</td>\n",
       "      <td>1.606716</td>\n",
       "      <td>-0.944515</td>\n",
       "      <td>-0.325903</td>\n",
       "      <td>1.582954</td>\n",
       "      <td>0.096611</td>\n",
       "      <td>1.936978</td>\n",
       "      <td>-0.473070</td>\n",
       "      <td>-0.529226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453725</td>\n",
       "      <td>0.120352</td>\n",
       "      <td>-0.081113</td>\n",
       "      <td>-1.294433</td>\n",
       "      <td>-0.215628</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.740064</td>\n",
       "      <td>1.042812</td>\n",
       "      <td>-1.245998</td>\n",
       "      <td>0.010677</td>\n",
       "      <td>0.860109</td>\n",
       "      <td>-1.012165</td>\n",
       "      <td>1.239930</td>\n",
       "      <td>-1.085284</td>\n",
       "      <td>-1.140144</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216176</td>\n",
       "      <td>0.372702</td>\n",
       "      <td>1.952085</td>\n",
       "      <td>-0.552949</td>\n",
       "      <td>-1.293767</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.015259</td>\n",
       "      <td>-0.147652</td>\n",
       "      <td>-1.007324</td>\n",
       "      <td>0.908221</td>\n",
       "      <td>-0.550319</td>\n",
       "      <td>1.614780</td>\n",
       "      <td>-0.552476</td>\n",
       "      <td>-1.335736</td>\n",
       "      <td>-0.223767</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.886076</td>\n",
       "      <td>-0.521453</td>\n",
       "      <td>-0.460184</td>\n",
       "      <td>-0.305787</td>\n",
       "      <td>0.143752</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.946061</td>\n",
       "      <td>0.980156</td>\n",
       "      <td>-0.605346</td>\n",
       "      <td>0.908221</td>\n",
       "      <td>1.071674</td>\n",
       "      <td>0.906870</td>\n",
       "      <td>0.343725</td>\n",
       "      <td>-0.745784</td>\n",
       "      <td>0.081693</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037446</td>\n",
       "      <td>-0.467804</td>\n",
       "      <td>0.194574</td>\n",
       "      <td>-0.058104</td>\n",
       "      <td>-0.082581</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.991838</td>\n",
       "      <td>0.792188</td>\n",
       "      <td>-0.341548</td>\n",
       "      <td>1.469188</td>\n",
       "      <td>1.653476</td>\n",
       "      <td>-0.048383</td>\n",
       "      <td>-0.452899</td>\n",
       "      <td>-0.420197</td>\n",
       "      <td>1.303529</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.513909</td>\n",
       "      <td>0.046557</td>\n",
       "      <td>-0.322340</td>\n",
       "      <td>-0.058626</td>\n",
       "      <td>0.143752</td>\n",
       "      <td>-0.504127</td>\n",
       "      <td>-0.317035</td>\n",
       "      <td>1.355535</td>\n",
       "      <td>1.163312</td>\n",
       "      <td>1.198484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>13.0</td>\n",
       "      <td>-0.953691</td>\n",
       "      <td>-0.962180</td>\n",
       "      <td>-1.057571</td>\n",
       "      <td>0.796029</td>\n",
       "      <td>-1.008708</td>\n",
       "      <td>2.075349</td>\n",
       "      <td>-0.253742</td>\n",
       "      <td>-1.071370</td>\n",
       "      <td>0.387152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304858</td>\n",
       "      <td>-0.485687</td>\n",
       "      <td>-0.425723</td>\n",
       "      <td>0.435697</td>\n",
       "      <td>0.143752</td>\n",
       "      <td>-0.559257</td>\n",
       "      <td>-0.355744</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>18.0</td>\n",
       "      <td>-1.617460</td>\n",
       "      <td>-1.463427</td>\n",
       "      <td>0.550341</td>\n",
       "      <td>-0.438097</td>\n",
       "      <td>-1.625771</td>\n",
       "      <td>-0.568655</td>\n",
       "      <td>0.244149</td>\n",
       "      <td>-0.773612</td>\n",
       "      <td>-0.529226</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.407110</td>\n",
       "      <td>0.841637</td>\n",
       "      <td>-1.666318</td>\n",
       "      <td>-0.800110</td>\n",
       "      <td>0.503132</td>\n",
       "      <td>6.442170</td>\n",
       "      <td>6.224744</td>\n",
       "      <td>-0.787085</td>\n",
       "      <td>-0.586463</td>\n",
       "      <td>-0.771034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.923173</td>\n",
       "      <td>1.105468</td>\n",
       "      <td>-1.346492</td>\n",
       "      <td>0.347255</td>\n",
       "      <td>1.159825</td>\n",
       "      <td>-0.005738</td>\n",
       "      <td>0.841616</td>\n",
       "      <td>-0.859878</td>\n",
       "      <td>0.081693</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.513909</td>\n",
       "      <td>0.114391</td>\n",
       "      <td>0.091192</td>\n",
       "      <td>-0.800110</td>\n",
       "      <td>-0.934388</td>\n",
       "      <td>0.129860</td>\n",
       "      <td>-0.162200</td>\n",
       "      <td>-0.480996</td>\n",
       "      <td>-0.586463</td>\n",
       "      <td>-0.278654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.968950</td>\n",
       "      <td>1.105468</td>\n",
       "      <td>-0.517413</td>\n",
       "      <td>0.010677</td>\n",
       "      <td>0.877740</td>\n",
       "      <td>0.292779</td>\n",
       "      <td>0.742040</td>\n",
       "      <td>-0.417414</td>\n",
       "      <td>-0.223767</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037446</td>\n",
       "      <td>0.046557</td>\n",
       "      <td>0.039630</td>\n",
       "      <td>-0.058104</td>\n",
       "      <td>-0.082581</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.427254</td>\n",
       "      <td>-0.022340</td>\n",
       "      <td>-1.107818</td>\n",
       "      <td>-0.550290</td>\n",
       "      <td>-0.250603</td>\n",
       "      <td>0.147785</td>\n",
       "      <td>1.538664</td>\n",
       "      <td>-1.332953</td>\n",
       "      <td>-0.223767</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.513909</td>\n",
       "      <td>1.207247</td>\n",
       "      <td>0.194574</td>\n",
       "      <td>-1.541595</td>\n",
       "      <td>-1.653147</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.787085</td>\n",
       "      <td>-0.586463</td>\n",
       "      <td>-0.771034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.282293</td>\n",
       "      <td>0.478908</td>\n",
       "      <td>-0.743526</td>\n",
       "      <td>2.703313</td>\n",
       "      <td>-0.127191</td>\n",
       "      <td>1.555077</td>\n",
       "      <td>0.841616</td>\n",
       "      <td>-1.218858</td>\n",
       "      <td>-0.223767</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.960510</td>\n",
       "      <td>0.046557</td>\n",
       "      <td>-0.322340</td>\n",
       "      <td>0.682859</td>\n",
       "      <td>0.143752</td>\n",
       "      <td>-0.421433</td>\n",
       "      <td>-0.239617</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1.358055</td>\n",
       "      <td>1.356092</td>\n",
       "      <td>-0.693278</td>\n",
       "      <td>-0.213711</td>\n",
       "      <td>1.900301</td>\n",
       "      <td>-0.253080</td>\n",
       "      <td>0.244149</td>\n",
       "      <td>-1.171551</td>\n",
       "      <td>-0.223767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453725</td>\n",
       "      <td>1.549013</td>\n",
       "      <td>1.090560</td>\n",
       "      <td>0.435697</td>\n",
       "      <td>-2.371907</td>\n",
       "      <td>0.129860</td>\n",
       "      <td>0.224888</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.427254</td>\n",
       "      <td>-0.022340</td>\n",
       "      <td>-1.107818</td>\n",
       "      <td>-0.550290</td>\n",
       "      <td>-0.250603</td>\n",
       "      <td>0.147785</td>\n",
       "      <td>1.538664</td>\n",
       "      <td>-1.332953</td>\n",
       "      <td>-0.223767</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.513909</td>\n",
       "      <td>1.207247</td>\n",
       "      <td>0.194574</td>\n",
       "      <td>-1.541595</td>\n",
       "      <td>-1.653147</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.787085</td>\n",
       "      <td>-0.586463</td>\n",
       "      <td>-0.771034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.923173</td>\n",
       "      <td>0.666876</td>\n",
       "      <td>-1.258560</td>\n",
       "      <td>0.796029</td>\n",
       "      <td>0.454611</td>\n",
       "      <td>-0.014267</td>\n",
       "      <td>-0.652057</td>\n",
       "      <td>-1.472092</td>\n",
       "      <td>-1.140144</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.588343</td>\n",
       "      <td>0.235598</td>\n",
       "      <td>0.125653</td>\n",
       "      <td>-0.058626</td>\n",
       "      <td>-1.293767</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.106813</td>\n",
       "      <td>-0.398276</td>\n",
       "      <td>-0.391795</td>\n",
       "      <td>-0.213711</td>\n",
       "      <td>-0.708992</td>\n",
       "      <td>-0.679533</td>\n",
       "      <td>-1.149948</td>\n",
       "      <td>-0.909968</td>\n",
       "      <td>-0.529226</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037446</td>\n",
       "      <td>0.046557</td>\n",
       "      <td>0.039630</td>\n",
       "      <td>-0.058104</td>\n",
       "      <td>-0.082581</td>\n",
       "      <td>0.089108</td>\n",
       "      <td>0.119143</td>\n",
       "      <td>-0.062836</td>\n",
       "      <td>-0.035353</td>\n",
       "      <td>-0.071235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>728 rows Ã 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Patient age quantile  Hematocrit  Hemoglobin  Platelets  \\\n",
       "0                    17.0    0.236515   -0.022340  -0.517413   \n",
       "1                     1.0   -1.571682   -0.774212   1.429667   \n",
       "2                     9.0   -0.747693   -0.586244  -0.429480   \n",
       "3                    11.0    0.991838    0.792188   0.072992   \n",
       "4                     9.0    0.190738   -0.147652  -0.668155   \n",
       "5                    13.0    1.014726    0.854844  -0.178244   \n",
       "6                    14.0    0.740064    0.854844   0.361914   \n",
       "7                     9.0   -0.679027   -0.711556   0.952319   \n",
       "8                     8.0    0.236515    0.040316   0.072992   \n",
       "9                    17.0    0.808730    1.042812  -0.278739   \n",
       "10                   14.0   -0.106813   -0.335620   1.429667   \n",
       "11                   16.0    1.426721    1.230779   0.600588   \n",
       "12                   15.0    0.717175    0.604220   0.399599   \n",
       "13                   17.0    1.014726    0.666876  -0.203368   \n",
       "14                    7.0    0.946061    1.168124  -0.278739   \n",
       "15                   19.0    0.625621    0.353596  -0.127997   \n",
       "16                    6.0   -0.152590   -0.460932   1.241240   \n",
       "17                   10.0    0.190738    0.040316  -1.057571   \n",
       "18                   11.0    0.740064    0.604220   0.160925   \n",
       "19                   11.0    0.740064    0.541564  -0.065188   \n",
       "20                   16.0    0.671398    0.290940   0.135801   \n",
       "21                    6.0   -0.221256   -0.084996   0.261419   \n",
       "22                    1.0   -0.816359   -0.836868   0.763892   \n",
       "23                    9.0   -0.656139   -0.899524  -0.391795   \n",
       "24                   19.0   -0.518807   -0.586244   0.952319   \n",
       "25                   17.0    0.442512    0.228284  -0.680717   \n",
       "26                   10.0   -0.541696   -0.398276  -0.454604   \n",
       "27                   18.0    0.946061    0.854844  -0.718402   \n",
       "28                   15.0   -0.450142   -0.460932  -0.542537   \n",
       "29                   14.0    1.220724    1.356092   0.500094   \n",
       "..                    ...         ...         ...        ...   \n",
       "698                  14.0   -0.518807   -0.272964  -0.215930   \n",
       "699                  13.0   -0.953691   -0.962180  -1.057571   \n",
       "700                  17.0    0.167850    0.165628  -1.007324   \n",
       "701                  14.0   -0.312811   -0.648900  -0.027502   \n",
       "702                  18.0    1.197836    1.356092  -1.911774   \n",
       "703                  15.0   -0.495919   -0.398276  -0.718402   \n",
       "704                  14.0   -0.518807   -0.272964  -0.215930   \n",
       "705                  14.0   -0.518807   -0.272964  -0.215930   \n",
       "706                  15.0   -0.495919   -0.398276  -0.718402   \n",
       "707                   5.0   -0.106813   -0.398276  -0.391795   \n",
       "708                  11.0   -0.450142    0.040316  -0.492289   \n",
       "709                  17.0   -0.358588   -0.460932  -0.153121   \n",
       "710                   7.0    0.694287    0.729532  -0.743526   \n",
       "711                  14.0   -0.312811   -0.648900  -0.027502   \n",
       "712                  19.0   -0.106813   -0.272964  -0.894267   \n",
       "713                  15.0    1.129169    1.606716  -0.944515   \n",
       "714                  14.0    0.740064    1.042812  -1.245998   \n",
       "715                   5.0   -0.015259   -0.147652  -1.007324   \n",
       "716                  12.0    0.946061    0.980156  -0.605346   \n",
       "717                   2.0    0.991838    0.792188  -0.341548   \n",
       "718                  13.0   -0.953691   -0.962180  -1.057571   \n",
       "719                  18.0   -1.617460   -1.463427   0.550341   \n",
       "720                  13.0    0.923173    1.105468  -1.346492   \n",
       "721                   4.0    0.968950    1.105468  -0.517413   \n",
       "722                  15.0   -0.427254   -0.022340  -1.107818   \n",
       "723                   5.0    0.282293    0.478908  -0.743526   \n",
       "724                  18.0    1.358055    1.356092  -0.693278   \n",
       "725                  15.0   -0.427254   -0.022340  -1.107818   \n",
       "726                  14.0    0.923173    0.666876  -1.258560   \n",
       "727                   5.0   -0.106813   -0.398276  -0.391795   \n",
       "\n",
       "     Mean platelet volume   Red blood Cells  Lymphocytes  \\\n",
       "0                 0.010677         0.102004     0.318366   \n",
       "1                -1.672222        -0.850035    -0.005738   \n",
       "2                -0.213711        -1.361315    -1.114514   \n",
       "3                -0.550290         0.542763     0.045436   \n",
       "4                 1.020415        -0.127191     0.002791   \n",
       "5                 0.796029         0.489872    -0.730707   \n",
       "6                -0.550290         0.436981    -0.227493   \n",
       "7                -0.886869        -0.321124    -0.875701   \n",
       "8                 0.571643         0.066744     1.239503   \n",
       "9                 1.581381         0.701437    -0.261609   \n",
       "10               -0.213711        -0.603210     0.326895   \n",
       "11               -1.111256         1.265607     0.506005   \n",
       "12                0.683835         0.401720     0.011320   \n",
       "13                0.459449         0.295938    -0.261609   \n",
       "14                0.010677         1.177456    -0.671003   \n",
       "15                0.796029         0.190156    -1.592140   \n",
       "16               -1.560029        -0.250603    -0.065441   \n",
       "17                0.235063        -0.462168    -1.268037   \n",
       "18                0.908221        -0.021409    -0.329842   \n",
       "19                0.683835        -0.215342     0.966573   \n",
       "20                0.010677         0.525133     0.173372   \n",
       "21                1.356995        -0.162451    -0.031325   \n",
       "22               -1.560029        -0.656101    -1.370385   \n",
       "23                0.796029        -0.409276     1.862123   \n",
       "24                0.010677        -0.144821     0.429243   \n",
       "25                0.459449         0.736697    -1.165688   \n",
       "26               -0.550290        -0.779514    -1.276566   \n",
       "27                0.908221         0.366460     0.540121   \n",
       "28                1.132609        -0.779514    -0.671003   \n",
       "29               -0.550290         1.688736     0.463359   \n",
       "..                     ...              ...          ...   \n",
       "698               0.459449        -0.515058    -0.457777   \n",
       "699               0.796029        -1.008708     2.075349   \n",
       "700               0.571643        -0.021409    -0.082499   \n",
       "701              -0.101517        -0.656101    -0.099557   \n",
       "702               1.132609         0.384090     0.966573   \n",
       "703              -0.438097        -0.567950    -0.935404   \n",
       "704               0.459449        -0.515058    -0.457777   \n",
       "705               0.459449        -0.515058    -0.457777   \n",
       "706              -0.438097        -0.567950    -0.935404   \n",
       "707              -0.213711        -0.708992    -0.679533   \n",
       "708              -0.774677        -0.409276    -1.378914   \n",
       "709               0.122869        -0.215342    -1.353327   \n",
       "710               0.235063         0.595655    -0.636887   \n",
       "711              -0.101517        -0.656101    -0.099557   \n",
       "712               0.796029        -0.338755    -0.346900   \n",
       "713              -0.325903         1.582954     0.096611   \n",
       "714               0.010677         0.860109    -1.012165   \n",
       "715               0.908221        -0.550319     1.614780   \n",
       "716               0.908221         1.071674     0.906870   \n",
       "717               1.469188         1.653476    -0.048383   \n",
       "718               0.796029        -1.008708     2.075349   \n",
       "719              -0.438097        -1.625771    -0.568655   \n",
       "720               0.347255         1.159825    -0.005738   \n",
       "721               0.010677         0.877740     0.292779   \n",
       "722              -0.550290        -0.250603     0.147785   \n",
       "723               2.703313        -0.127191     1.555077   \n",
       "724              -0.213711         1.900301    -0.253080   \n",
       "725              -0.550290        -0.250603     0.147785   \n",
       "726               0.796029         0.454611    -0.014267   \n",
       "727              -0.213711        -0.708992    -0.679533   \n",
       "\n",
       "     Mean corpuscular hemoglobin concentrationÂ (MCHC)  Leukocytes  Basophils  \\\n",
       "0                                           -0.950790   -0.094610  -0.223767   \n",
       "1                                            3.331071    0.364550  -0.223767   \n",
       "2                                            0.542882   -0.884923   0.081693   \n",
       "3                                           -0.452899   -0.211488  -0.834685   \n",
       "4                                           -1.249524   -1.132592   0.387152   \n",
       "5                                           -0.353319   -0.075131   2.525365   \n",
       "6                                            0.642463    0.105751  -0.529226   \n",
       "7                                           -0.253742   -0.286623  -0.223767   \n",
       "8                                           -0.652057   -0.545423   0.998070   \n",
       "9                                            1.040773    0.000005   0.387152   \n",
       "10                                          -0.950790    0.726313   0.081693   \n",
       "11                                          -0.353319   -0.022258   0.692611   \n",
       "12                                          -0.253742   -0.178094   0.387152   \n",
       "13                                          -0.950790   -0.083479  -0.223767   \n",
       "14                                           1.040773    0.133579   0.692611   \n",
       "15                                          -0.851210    0.556563   0.081693   \n",
       "16                                          -1.249524    1.196605  -0.529226   \n",
       "17                                          -0.552476    1.224433  -0.529226   \n",
       "18                                          -0.353319    0.225411  -0.223767   \n",
       "19                                          -0.552476    0.350636   0.081693   \n",
       "20                                          -1.249524   -0.653951   0.081693   \n",
       "21                                           0.542882   -0.509246  -0.529226   \n",
       "22                                          -0.253742    1.666897  -0.529226   \n",
       "23                                          -1.149948   -0.681779  -0.529226   \n",
       "24                                          -0.353319   -0.748566   1.303529   \n",
       "25                                          -0.652057   -0.589947  -0.529226   \n",
       "26                                           0.443306    0.236542  -0.223767   \n",
       "27                                          -0.054585   -1.032411   0.387152   \n",
       "28                                          -0.154166   -1.138157  -1.140144   \n",
       "29                                           0.742040    1.152081  -0.834685   \n",
       "..                                                ...         ...        ...   \n",
       "698                                          0.941197   -0.573250  -0.223767   \n",
       "699                                         -0.253742   -1.071370   0.387152   \n",
       "700                                          0.044991   -0.843181   0.081693   \n",
       "701                                         -1.448681   -0.968407  -0.529226   \n",
       "702                                          0.841616   -0.834833  -0.529226   \n",
       "703                                          0.244149   -0.820919  -1.140144   \n",
       "704                                          0.941197   -0.573250  -0.223767   \n",
       "705                                          0.941197   -0.573250  -0.223767   \n",
       "706                                          0.244149   -0.820919  -1.140144   \n",
       "707                                         -1.149948   -0.909968  -0.529226   \n",
       "708                                          1.936978    0.038964  -0.529226   \n",
       "709                                         -0.452899    0.901629  -0.529226   \n",
       "710                                          0.343725   -0.606644  -0.223767   \n",
       "711                                         -1.448681   -0.968407  -0.529226   \n",
       "712                                         -0.652057   -0.898837   0.081693   \n",
       "713                                          1.936978   -0.473070  -0.529226   \n",
       "714                                          1.239930   -1.085284  -1.140144   \n",
       "715                                         -0.552476   -1.335736  -0.223767   \n",
       "716                                          0.343725   -0.745784   0.081693   \n",
       "717                                         -0.452899   -0.420197   1.303529   \n",
       "718                                         -0.253742   -1.071370   0.387152   \n",
       "719                                          0.244149   -0.773612  -0.529226   \n",
       "720                                          0.841616   -0.859878   0.081693   \n",
       "721                                          0.742040   -0.417414  -0.223767   \n",
       "722                                          1.538664   -1.332953  -0.223767   \n",
       "723                                          0.841616   -1.218858  -0.223767   \n",
       "724                                          0.244149   -1.171551  -0.223767   \n",
       "725                                          1.538664   -1.332953  -0.223767   \n",
       "726                                         -0.652057   -1.472092  -1.140144   \n",
       "727                                         -1.149948   -0.909968  -0.529226   \n",
       "\n",
       "     ...      Urea  C-reactive protein mg/dL  Creatinine  Potassium    Sodium  \\\n",
       "0    ...  1.198059                 -0.147895    2.089928  -0.305787  0.862512   \n",
       "1    ... -0.067309                 -0.286986   -1.838623   0.930020  0.503132   \n",
       "2    ... -0.811643                  0.046557   -0.908177   0.435697 -0.215628   \n",
       "3    ... -0.037446                 -0.487674    0.039630  -0.058104 -0.082581   \n",
       "4    ... -1.332677                  0.046557   -0.908177  -0.552949 -0.575008   \n",
       "5    ... -0.737209                 -0.434025   -0.701411  -0.058104 -0.082581   \n",
       "6    ... -0.141742                 -0.529401    0.332418  -0.058104 -0.082581   \n",
       "7    ... -0.439476                  0.545572    1.021638   0.435697 -1.653147   \n",
       "8    ... -0.513909                  0.046557   -0.391262   0.930020  0.143752   \n",
       "9    ... -0.037446                 -0.360505    0.039630  -0.058104 -0.082581   \n",
       "10   ... -0.037446                 -0.519466    0.039630  -0.058104 -0.082581   \n",
       "11   ...  0.453725                 -0.414154   -0.563567  -0.058104 -0.082581   \n",
       "12   ... -0.037446                 -0.354544    0.039630  -0.058104 -0.082581   \n",
       "13   ...  0.825892                 -0.461843    2.124389  -0.800110  0.862512   \n",
       "14   ... -0.439476                  0.011066    1.297326   0.188535  0.143752   \n",
       "15   ... -0.737209                  0.611144   -0.494645  -1.541595  0.862512   \n",
       "16   ... -0.037446                 -0.451908    0.039630  -0.058104 -0.082581   \n",
       "17   ... -0.365042                  2.256389    0.470262  -0.058626 -0.215628   \n",
       "18   ... -0.141742                 -0.495622    0.022270  -0.305787  1.581271   \n",
       "19   ... -0.141742                 -0.475752   -0.529106  -0.800110  1.581271   \n",
       "20   ... -0.037446                 -0.316791    0.194574   2.412989  0.862512   \n",
       "21   ... -0.037446                 -0.521453    0.039630  -0.058104 -0.082581   \n",
       "22   ... -0.037446                  1.727844    0.039630  -0.058104 -0.082581   \n",
       "23   ... -0.037446                 -0.519466    0.039630  -0.058104 -0.082581   \n",
       "24   ...  1.198059                 -0.283012   -0.873716   0.930020  0.503132   \n",
       "25   ... -0.365042                 -0.404219    0.573645  -1.047272 -0.215628   \n",
       "26   ... -1.034943                 -0.243272   -0.977099  -0.058104 -0.082581   \n",
       "27   ...  0.155991                 -0.461843    0.573645  -0.058626  0.143752   \n",
       "28   ... -0.960510                 -0.489661   -0.632489  -0.058104 -0.082581   \n",
       "29   ... -0.290609                  0.650884    0.539184   1.177181 -1.293767   \n",
       "..   ...       ...                       ...         ...        ...       ...   \n",
       "698  ... -0.588343                 -0.340635    0.435801  -0.800110 -0.575008   \n",
       "699  ...  0.304858                 -0.485687   -0.425723   0.435697  0.143752   \n",
       "700  ... -0.811643                  0.046557    0.056730  -0.552949 -0.215628   \n",
       "701  ...  0.304858                 -0.479726   -0.046652   0.682859  1.940651   \n",
       "702  ... -0.662776                 -0.302882    0.608106   0.188535 -0.575008   \n",
       "703  ...  0.974759                 -0.247246    0.160114  -1.047272  0.862512   \n",
       "704  ... -0.588343                 -0.340635    0.435801  -0.800110 -0.575008   \n",
       "705  ... -0.588343                 -0.340635    0.435801  -0.800110 -0.575008   \n",
       "706  ...  0.974759                 -0.247246    0.160114  -1.047272  0.862512   \n",
       "707  ... -0.037446                  0.046557    0.039630  -0.058104 -0.082581   \n",
       "708  ... -0.365042                  3.086960   -0.356801  -0.552949 -1.293767   \n",
       "709  ...  0.900325                  0.046557    0.883794   1.177181  0.143752   \n",
       "710  ... -0.037446                 -0.511518    0.039630  -0.058104 -0.082581   \n",
       "711  ...  0.304858                 -0.479726   -0.046652   0.682859  1.940651   \n",
       "712  ... -0.141742                  0.217715    0.849333   0.930020 -0.934388   \n",
       "713  ...  0.453725                  0.120352   -0.081113  -1.294433 -0.215628   \n",
       "714  ... -0.216176                  0.372702    1.952085  -0.552949 -1.293767   \n",
       "715  ... -0.886076                 -0.521453   -0.460184  -0.305787  0.143752   \n",
       "716  ... -0.037446                 -0.467804    0.194574  -0.058104 -0.082581   \n",
       "717  ... -0.513909                  0.046557   -0.322340  -0.058626  0.143752   \n",
       "718  ...  0.304858                 -0.485687   -0.425723   0.435697  0.143752   \n",
       "719  ... -1.407110                  0.841637   -1.666318  -0.800110  0.503132   \n",
       "720  ... -0.513909                  0.114391    0.091192  -0.800110 -0.934388   \n",
       "721  ... -0.037446                  0.046557    0.039630  -0.058104 -0.082581   \n",
       "722  ... -0.513909                  1.207247    0.194574  -1.541595 -1.653147   \n",
       "723  ... -0.960510                  0.046557   -0.322340   0.682859  0.143752   \n",
       "724  ...  0.453725                  1.549013    1.090560   0.435697 -2.371907   \n",
       "725  ... -0.513909                  1.207247    0.194574  -1.541595 -1.653147   \n",
       "726  ... -0.588343                  0.235598    0.125653  -0.058626 -1.293767   \n",
       "727  ... -0.037446                  0.046557    0.039630  -0.058104 -0.082581   \n",
       "\n",
       "     Alanine transaminase  Aspartate transaminase  Total Bilirubin  \\\n",
       "0                0.089108                0.119143        -0.062836   \n",
       "1               -0.586821               -0.162200        -0.062836   \n",
       "2               -0.559257               -0.549287        -0.062836   \n",
       "3                0.089108                0.119143        -0.062836   \n",
       "4                0.089108                0.119143        -0.062836   \n",
       "5                0.089108                0.119143        -0.062836   \n",
       "6                0.089108                0.119143        -0.062836   \n",
       "7                0.089108                0.119143        -0.062836   \n",
       "8                0.089108                0.119143        -0.062836   \n",
       "9                0.089108                0.119143        -0.062836   \n",
       "10               0.089108                0.119143        -0.062836   \n",
       "11               0.089108                0.119143        -0.062836   \n",
       "12              -0.476563               -0.471870        -0.062836   \n",
       "13              -0.366304               -0.510579         0.131181   \n",
       "14              -0.283610               -0.200909         1.049447   \n",
       "15              -0.448998               -0.278326        -0.174908   \n",
       "16               0.089108                0.119143        -0.062836   \n",
       "17               0.089108                0.119143        -0.062836   \n",
       "18               0.089108                0.119143        -0.062836   \n",
       "19              -0.559257               -0.471870        -1.093174   \n",
       "20               0.089108                0.119143        -0.062836   \n",
       "21               0.089108                0.119143        -0.062836   \n",
       "22               0.089108                0.119143        -0.062836   \n",
       "23               0.089108                0.119143        -0.062836   \n",
       "24              -0.531692               -0.510579        -0.062836   \n",
       "25               1.149753               -0.239617         1.355535   \n",
       "26               0.089108                0.119143        -0.062836   \n",
       "27               0.089108                0.119143        -0.062836   \n",
       "28               0.089108                0.119143        -0.062836   \n",
       "29               0.212554               -0.355744        -0.062836   \n",
       "..                    ...                     ...              ...   \n",
       "698              0.598460                0.147470        -0.787085   \n",
       "699             -0.559257               -0.355744        -0.062836   \n",
       "700             -0.311175               -0.162200        -0.787085   \n",
       "701             -0.504127               -0.394452        -0.787085   \n",
       "702              0.433072                0.418431        -0.174908   \n",
       "703              0.089108                0.119143        -0.062836   \n",
       "704              0.598460                0.147470        -0.787085   \n",
       "705              0.598460                0.147470        -0.787085   \n",
       "706              0.089108                0.119143        -0.062836   \n",
       "707              0.089108                0.119143        -0.062836   \n",
       "708              0.322813               -0.046074         0.131181   \n",
       "709             -0.007963                0.302305        -0.174908   \n",
       "710              0.089108                0.119143        -0.062836   \n",
       "711             -0.504127               -0.394452        -0.787085   \n",
       "712             -0.504127               -0.239617         0.131181   \n",
       "713              0.089108                0.119143        -0.062836   \n",
       "714              0.089108                0.119143        -0.062836   \n",
       "715              0.089108                0.119143        -0.062836   \n",
       "716              0.089108                0.119143        -0.062836   \n",
       "717             -0.504127               -0.317035         1.355535   \n",
       "718             -0.559257               -0.355744        -0.062836   \n",
       "719              6.442170                6.224744        -0.787085   \n",
       "720              0.129860               -0.162200        -0.480996   \n",
       "721              0.089108                0.119143        -0.062836   \n",
       "722              0.089108                0.119143        -0.787085   \n",
       "723             -0.421433               -0.239617        -0.062836   \n",
       "724              0.129860                0.224888        -0.062836   \n",
       "725              0.089108                0.119143        -0.787085   \n",
       "726              0.089108                0.119143        -0.062836   \n",
       "727              0.089108                0.119143        -0.062836   \n",
       "\n",
       "     Direct Bilirubin  Indirect Bilirubin  \n",
       "0           -0.035353           -0.071235  \n",
       "1           -0.035353           -0.071235  \n",
       "2           -0.035353           -0.071235  \n",
       "3           -0.035353           -0.071235  \n",
       "4           -0.035353           -0.071235  \n",
       "5           -0.035353           -0.071235  \n",
       "6           -0.035353           -0.071235  \n",
       "7           -0.035353           -0.071235  \n",
       "8           -0.035353           -0.071235  \n",
       "9           -0.035353           -0.071235  \n",
       "10          -0.035353           -0.071235  \n",
       "11          -0.035353           -0.071235  \n",
       "12          -0.035353           -0.071235  \n",
       "13           0.580054           -0.278654  \n",
       "14          -0.003205            1.690864  \n",
       "15          -0.003205           -0.278654  \n",
       "16          -0.035353           -0.071235  \n",
       "17          -0.035353           -0.071235  \n",
       "18          -0.035353           -0.071235  \n",
       "19          -1.169722           -0.771034  \n",
       "20          -0.035353           -0.071235  \n",
       "21          -0.035353           -0.071235  \n",
       "22          -0.035353           -0.071235  \n",
       "23          -0.035353           -0.071235  \n",
       "24          -0.035353           -0.071235  \n",
       "25           0.580054            1.690864  \n",
       "26          -0.035353           -0.071235  \n",
       "27          -0.035353           -0.071235  \n",
       "28          -0.035353           -0.071235  \n",
       "29          -0.035353           -0.071235  \n",
       "..                ...                 ...  \n",
       "698         -0.586463           -0.771034  \n",
       "699         -0.035353           -0.071235  \n",
       "700         -0.586463           -0.771034  \n",
       "701         -0.586463           -0.771034  \n",
       "702         -0.003205           -0.278654  \n",
       "703         -0.035353           -0.071235  \n",
       "704         -0.586463           -0.771034  \n",
       "705         -0.586463           -0.771034  \n",
       "706         -0.035353           -0.071235  \n",
       "707         -0.035353           -0.071235  \n",
       "708         -0.003205            0.213725  \n",
       "709         -0.003205           -0.278654  \n",
       "710         -0.035353           -0.071235  \n",
       "711         -0.586463           -0.771034  \n",
       "712         -0.003205            0.213725  \n",
       "713         -0.035353           -0.071235  \n",
       "714         -0.035353           -0.071235  \n",
       "715         -0.035353           -0.071235  \n",
       "716         -0.035353           -0.071235  \n",
       "717          1.163312            1.198484  \n",
       "718         -0.035353           -0.071235  \n",
       "719         -0.586463           -0.771034  \n",
       "720         -0.586463           -0.278654  \n",
       "721         -0.035353           -0.071235  \n",
       "722         -0.586463           -0.771034  \n",
       "723         -0.035353           -0.071235  \n",
       "724         -0.035353           -0.071235  \n",
       "725         -0.586463           -0.771034  \n",
       "726         -0.035353           -0.071235  \n",
       "727         -0.035353           -0.071235  \n",
       "\n",
       "[728 rows x 27 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- START EPOCH 0 ---\n",
      "* Parameter=C Value=0.18396975452910314 *\n",
      "* Parameter=tol Value=1.7382526766676483 *\n",
      "* Parameter=intercept_scaling Value=0.8953615999445083 *\n",
      "* Parameter=solver Value=sag *\n",
      "* Particle 0 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.6428571428571428 *\n",
      "* Parameter=C Value=1.2066142091485794 *\n",
      "* Parameter=tol Value=0.22429065510927776 *\n",
      "* Parameter=intercept_scaling Value=0.10245159567092944 *\n",
      "* Parameter=solver Value=sag *\n",
      "* Particle 1 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.6370370370370371 *\n",
      "* Parameter=C Value=1.0236071241837184 *\n",
      "* Parameter=tol Value=0.43893454007444516 *\n",
      "* Parameter=intercept_scaling Value=0.03881821535676816 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 2 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7346938775510204 *\n",
      "* Parameter=C Value=2.3023509081526674 *\n",
      "* Parameter=tol Value=0.5798743526153126 *\n",
      "* Parameter=intercept_scaling Value=0.5959082521208039 *\n",
      "* Parameter=solver Value=sag *\n",
      "* Particle 3 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.6582278481012658 *\n",
      "* Parameter=C Value=0.6964182642810155 *\n",
      "* Parameter=tol Value=0.60961781862508 *\n",
      "* Parameter=intercept_scaling Value=0.3189723589027618 *\n",
      "* Parameter=solver Value=lbfgs *\n",
      "* Particle 4 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7346938775510204 *\n",
      "* Parameter=C Value=1.8870311662209376 *\n",
      "* Parameter=tol Value=1.1803311275996105 *\n",
      "* Parameter=intercept_scaling Value=0.5778914630667819 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 5 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=2.531797621735333 *\n",
      "* Parameter=tol Value=0.4742094712887376 *\n",
      "* Parameter=intercept_scaling Value=0.6037589227413289 *\n",
      "* Parameter=solver Value=liblinear *\n",
      "* Particle 6 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7189542483660131 *\n",
      "* Parameter=C Value=2.9575481143728926 *\n",
      "* Parameter=tol Value=1.8066473500835567 *\n",
      "* Parameter=intercept_scaling Value=0.7167838104323273 *\n",
      "* Parameter=solver Value=sag *\n",
      "* Particle 7 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.47540983606557385 *\n",
      "* Parameter=C Value=2.8738581300905675 *\n",
      "* Parameter=tol Value=0.6927674632818527 *\n",
      "* Parameter=intercept_scaling Value=0.5375249566663517 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 8 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=0.13751613040554408 *\n",
      "* Parameter=tol Value=0.591787177539217 *\n",
      "* Parameter=intercept_scaling Value=0.6371781386429877 *\n",
      "* Parameter=solver Value=liblinear *\n",
      "* Particle 9 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.6832298136645962 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=53 *\n",
      "* Parameter=algorithm Value=brute *\n",
      "* Particle 10 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=4 *\n",
      "* Parameter=n_neighbors Value=32 *\n",
      "* Parameter=leaf_size Value=34 *\n",
      "* Parameter=algorithm Value=brute *\n",
      "* Particle 11 Algorithm Type KNN: personal best metric=0.5576923076923077 *\n",
      "* Parameter=p Value=5 *\n",
      "* Parameter=n_neighbors Value=48 *\n",
      "* Parameter=leaf_size Value=21 *\n",
      "* Parameter=algorithm Value=brute *\n",
      "* Particle 12 Algorithm Type KNN: personal best metric=0.4086021505376343 *\n",
      "* Parameter=p Value=4 *\n",
      "* Parameter=n_neighbors Value=57 *\n",
      "* Parameter=leaf_size Value=73 *\n",
      "* Parameter=algorithm Value=kd_tree *\n",
      "* Particle 13 Algorithm Type KNN: personal best metric=0.46153846153846156 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=53 *\n",
      "* Parameter=leaf_size Value=43 *\n",
      "* Parameter=algorithm Value=kd_tree *\n",
      "* Particle 14 Algorithm Type KNN: personal best metric=0.44943820224719105 *\n",
      "* Parameter=p Value=4 *\n",
      "* Parameter=n_neighbors Value=68 *\n",
      "* Parameter=leaf_size Value=82 *\n",
      "* Parameter=algorithm Value=brute *\n",
      "* Particle 15 Algorithm Type KNN: personal best metric=0.3764705882352941 *\n",
      "* Parameter=p Value=3 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=14 *\n",
      "* Parameter=algorithm Value=brute *\n",
      "* Particle 16 Algorithm Type KNN: personal best metric=0.7102803738317757 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=59 *\n",
      "* Parameter=leaf_size Value=79 *\n",
      "* Parameter=algorithm Value=ball_tree *\n",
      "* Particle 17 Algorithm Type KNN: personal best metric=0.45454545454545453 *\n",
      "* Parameter=p Value=5 *\n",
      "* Parameter=n_neighbors Value=66 *\n",
      "* Parameter=leaf_size Value=63 *\n",
      "* Parameter=algorithm Value=ball_tree *\n",
      "* Particle 18 Algorithm Type KNN: personal best metric=0.3953488372093023 *\n",
      "* Parameter=p Value=4 *\n",
      "* Parameter=n_neighbors Value=32 *\n",
      "* Parameter=leaf_size Value=15 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 19 Algorithm Type KNN: personal best metric=0.5576923076923077 *\n",
      "* Parameter=max_depth Value=13 *\n",
      "* Parameter=min_samples_split Value=18 *\n",
      "* Parameter=n_estimators Value=196 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 20 Algorithm Type RANDOM FOREST: personal best metric=0.903225806451613 *\n",
      "* Parameter=max_depth Value=45 *\n",
      "* Parameter=min_samples_split Value=40 *\n",
      "* Parameter=n_estimators Value=213 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "* Particle 21 Algorithm Type RANDOM FOREST: personal best metric=0.8270676691729323 *\n",
      "* Parameter=max_depth Value=83 *\n",
      "* Parameter=min_samples_split Value=43 *\n",
      "* Parameter=n_estimators Value=273 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 22 Algorithm Type RANDOM FOREST: personal best metric=0.8661417322834646 *\n",
      "* Parameter=max_depth Value=55 *\n",
      "* Parameter=min_samples_split Value=71 *\n",
      "* Parameter=n_estimators Value=261 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "* Particle 23 Algorithm Type RANDOM FOREST: personal best metric=0.8029197080291971 *\n",
      "* Parameter=max_depth Value=60 *\n",
      "* Parameter=min_samples_split Value=50 *\n",
      "* Parameter=n_estimators Value=287 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 24 Algorithm Type RANDOM FOREST: personal best metric=0.8527131782945736 *\n",
      "* Parameter=max_depth Value=42 *\n",
      "* Parameter=min_samples_split Value=46 *\n",
      "* Parameter=n_estimators Value=120 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "* Particle 25 Algorithm Type RANDOM FOREST: personal best metric=0.8270676691729323 *\n",
      "* Parameter=max_depth Value=74 *\n",
      "* Parameter=min_samples_split Value=13 *\n",
      "* Parameter=n_estimators Value=104 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "* Particle 26 Algorithm Type RANDOM FOREST: personal best metric=0.8818897637795277 *\n",
      "* Parameter=max_depth Value=20 *\n",
      "* Parameter=min_samples_split Value=36 *\n",
      "* Parameter=n_estimators Value=219 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "* Particle 27 Algorithm Type RANDOM FOREST: personal best metric=0.8396946564885496 *\n",
      "* Parameter=max_depth Value=62 *\n",
      "* Parameter=min_samples_split Value=15 *\n",
      "* Parameter=n_estimators Value=288 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 28 Algorithm Type RANDOM FOREST: personal best metric=0.903225806451613 *\n",
      "* Parameter=max_depth Value=76 *\n",
      "* Parameter=min_samples_split Value=48 *\n",
      "* Parameter=n_estimators Value=16 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 29 Algorithm Type RANDOM FOREST: personal best metric=0.8346456692913385 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.38437580035141083 *\n",
      "* Parameter=min_samples_split Value=104 *\n",
      "* Parameter=min_samples_leaf Value=96 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 30 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.26064605679515407 *\n",
      "* Parameter=min_samples_split Value=147 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=random *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 31 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.4503639459969029 *\n",
      "* Parameter=min_samples_split Value=125 *\n",
      "* Parameter=min_samples_leaf Value=64 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=entropy *\n",
      "* Particle 32 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.46927733076642664 *\n",
      "* Parameter=min_samples_split Value=96 *\n",
      "* Parameter=min_samples_leaf Value=160 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 33 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.06270643736387438 *\n",
      "* Parameter=min_samples_split Value=153 *\n",
      "* Parameter=min_samples_leaf Value=48 *\n",
      "* Parameter=splitter Value=random *\n",
      "* Parameter=criterion Value=entropy *\n",
      "* Particle 34 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.1584948816621755 *\n",
      "* Parameter=min_samples_split Value=55 *\n",
      "* Parameter=min_samples_leaf Value=28 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 35 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.5970149253731344 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.487455755435778 *\n",
      "* Parameter=min_samples_split Value=117 *\n",
      "* Parameter=min_samples_leaf Value=68 *\n",
      "* Parameter=splitter Value=random *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 36 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.20455141166722512 *\n",
      "* Parameter=min_samples_split Value=30 *\n",
      "* Parameter=min_samples_leaf Value=52 *\n",
      "* Parameter=splitter Value=random *\n",
      "* Parameter=criterion Value=entropy *\n",
      "* Particle 37 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.36595210816606816 *\n",
      "* Parameter=min_samples_split Value=73 *\n",
      "* Parameter=min_samples_leaf Value=159 *\n",
      "* Parameter=splitter Value=random *\n",
      "* Parameter=criterion Value=entropy *\n",
      "* Particle 38 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0418433036993584 *\n",
      "* Parameter=min_samples_split Value=169 *\n",
      "* Parameter=min_samples_leaf Value=50 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=entropy *\n",
      "* Particle 39 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.55 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.31595396225553113 *\n",
      "* Parameter=min_samples_split Value=44 *\n",
      "* Parameter=min_samples_leaf Value=148 *\n",
      "* Parameter=splitter Value=random *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 40 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.31859432270690524 *\n",
      "* Parameter=min_samples_split Value=86 *\n",
      "* Parameter=min_samples_leaf Value=106 *\n",
      "* Parameter=splitter Value=random *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 41 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.21105765783893254 *\n",
      "* Parameter=min_samples_split Value=109 *\n",
      "* Parameter=min_samples_leaf Value=9 *\n",
      "* Parameter=splitter Value=random *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 42 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.3883821101775102 *\n",
      "* Parameter=min_samples_split Value=63 *\n",
      "* Parameter=min_samples_leaf Value=158 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=entropy *\n",
      "* Particle 43 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.5853658536585367 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.22555347717503665 *\n",
      "* Parameter=min_samples_split Value=81 *\n",
      "* Parameter=min_samples_leaf Value=187 *\n",
      "* Parameter=splitter Value=random *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 44 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.17127447767110238 *\n",
      "* Parameter=min_samples_split Value=127 *\n",
      "* Parameter=min_samples_leaf Value=114 *\n",
      "* Parameter=splitter Value=random *\n",
      "* Parameter=criterion Value=entropy *\n",
      "* Particle 45 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.31374515866295416 *\n",
      "* Parameter=min_samples_split Value=24 *\n",
      "* Parameter=min_samples_leaf Value=9 *\n",
      "* Parameter=splitter Value=random *\n",
      "* Parameter=criterion Value=entropy *\n",
      "* Particle 46 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.28771101759142936 *\n",
      "* Parameter=min_samples_split Value=31 *\n",
      "* Parameter=min_samples_leaf Value=36 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 47 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.5853658536585367 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.20889811182225881 *\n",
      "* Parameter=min_samples_split Value=66 *\n",
      "* Parameter=min_samples_leaf Value=80 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=entropy *\n",
      "* Particle 48 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.6206896551724138 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.2421982870650391 *\n",
      "* Parameter=min_samples_split Value=64 *\n",
      "* Parameter=min_samples_leaf Value=114 *\n",
      "* Parameter=splitter Value=random *\n",
      "* Parameter=criterion Value=entropy *\n",
      "* Particle 49 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.4220183486238532 *\n",
      "* Parameter=alpha Value=82.57907490182255 *\n",
      "* Parameter=tol Value=55.48507425015517 *\n",
      "* Parameter=normalize Value=False *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=lsqr *\n",
      "* Particle 50 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.4578313253012048 *\n",
      "* Parameter=alpha Value=79.4933810439695 *\n",
      "* Parameter=tol Value=37.69147689313977 *\n",
      "* Parameter=normalize Value=False *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=svd *\n",
      "* Particle 51 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7114093959731544 *\n",
      "* Parameter=alpha Value=71.07459899925608 *\n",
      "* Parameter=tol Value=31.804705017305302 *\n",
      "* Parameter=normalize Value=False *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=lsqr *\n",
      "* Particle 52 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.4578313253012048 *\n",
      "* Parameter=alpha Value=76.5341193618104 *\n",
      "* Parameter=tol Value=23.502600375467154 *\n",
      "* Parameter=normalize Value=False *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=svd *\n",
      "* Particle 53 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7114093959731544 *\n",
      "* Parameter=alpha Value=34.51496309945007 *\n",
      "* Parameter=tol Value=59.78878300707219 *\n",
      "* Parameter=normalize Value=False *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=lsqr *\n",
      "* Particle 54 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.4578313253012048 *\n",
      "* Parameter=alpha Value=2.58521131143875 *\n",
      "* Parameter=tol Value=87.87832879878718 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=svd *\n",
      "* Particle 55 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7123287671232876 *\n",
      "* Parameter=alpha Value=5.411338223108509 *\n",
      "* Parameter=tol Value=17.52278997821334 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Particle 56 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7092198581560283 *\n",
      "* Parameter=alpha Value=44.93595085499107 *\n",
      "* Parameter=tol Value=56.670324070795026 *\n",
      "* Parameter=normalize Value=False *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=sparse_cg *\n",
      "* Particle 57 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=alpha Value=5.974351948484479 *\n",
      "* Parameter=tol Value=7.969556359436703 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 58 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7042253521126761 *\n",
      "* Parameter=alpha Value=65.6721952168723 *\n",
      "* Parameter=tol Value=69.27121409603859 *\n",
      "* Parameter=normalize Value=False *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=sag *\n",
      "* Particle 59 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.6447368421052632 *\n",
      "* Parameter=C Value=86.5187435650813 *\n",
      "* Parameter=fit_intercept Value=False *\n",
      "* Particle 60 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.6341463414634146 *\n",
      "* Parameter=C Value=27.09283649746852 *\n",
      "* Parameter=fit_intercept Value=False *\n",
      "* Particle 61 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.5 *\n",
      "* Parameter=C Value=64.29496868978501 *\n",
      "* Parameter=fit_intercept Value=False *\n",
      "* Particle 62 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.5196850393700787 *\n",
      "* Parameter=C Value=83.2893953457757 *\n",
      "* Parameter=fit_intercept Value=False *\n",
      "* Particle 63 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.5609756097560976 *\n",
      "* Parameter=C Value=4.232539463018734 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 64 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.03278688524590164 *\n",
      "* Parameter=C Value=30.64496484260448 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 65 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.6842105263157895 *\n",
      "* Parameter=C Value=40.85520681182494 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 66 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.20289855072463767 *\n",
      "* Parameter=C Value=48.71313964388439 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 67 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.681159420289855 *\n",
      "* Parameter=C Value=33.559916801765496 *\n",
      "* Parameter=fit_intercept Value=False *\n",
      "* Particle 68 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.5285714285714286 *\n",
      "* Parameter=C Value=42.69503371739628 *\n",
      "* Parameter=fit_intercept Value=False *\n",
      "* Particle 69 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.5045045045045046 *\n",
      "* Parameter=alpha Value=9.03502321351905 *\n",
      "* Parameter=l1_ratio Value=0.3660277518915279 *\n",
      "* Parameter=epsilon Value=3.177653130280603 *\n",
      "* Parameter=eta0 Value=6.361457170306137 *\n",
      "* Parameter=power_t Value=7.4407165275422456 *\n",
      "* Parameter=loss Value=perceptron *\n",
      "* Parameter=penalty Value=elasticnet *\n",
      "* Parameter=learning_rate Value=optimal *\n",
      "* Particle 70 Algorithm Type SGD CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=alpha Value=10.005212785722405 *\n",
      "* Parameter=l1_ratio Value=0.28077160875366414 *\n",
      "* Parameter=epsilon Value=0.8961702354277673 *\n",
      "* Parameter=eta0 Value=2.118032254925928 *\n",
      "* Parameter=power_t Value=0.20988810460054094 *\n",
      "* Parameter=loss Value=hinge *\n",
      "* Parameter=penalty Value=l1 *\n",
      "* Parameter=learning_rate Value=constant *\n",
      "* Particle 71 Algorithm Type SGD CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=alpha Value=10.128941935768216 *\n",
      "* Parameter=l1_ratio Value=0.853446943140178 *\n",
      "* Parameter=epsilon Value=10.470601130636346 *\n",
      "* Parameter=eta0 Value=4.310658863453266 *\n",
      "* Parameter=power_t Value=7.2842438821457325 *\n",
      "* Parameter=loss Value=squared_hinge *\n",
      "* Parameter=penalty Value=elasticnet *\n",
      "* Parameter=learning_rate Value=optimal *\n",
      "* Particle 72 Algorithm Type SGD CLASSIFIER: personal best metric=0.608695652173913 *\n",
      "* Parameter=alpha Value=4.588345551977099 *\n",
      "* Parameter=l1_ratio Value=0.2060336957516843 *\n",
      "* Parameter=epsilon Value=8.831484165398711 *\n",
      "* Parameter=eta0 Value=7.861856014870045 *\n",
      "* Parameter=power_t Value=10.870793558190675 *\n",
      "* Parameter=loss Value=squared_hinge *\n",
      "* Parameter=penalty Value=elasticnet *\n",
      "* Parameter=learning_rate Value=optimal *\n",
      "* Particle 73 Algorithm Type SGD CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=alpha Value=0.7307873064976448 *\n",
      "* Parameter=l1_ratio Value=0.9105360591269963 *\n",
      "* Parameter=epsilon Value=4.576378663071411 *\n",
      "* Parameter=eta0 Value=5.882299523743761 *\n",
      "* Parameter=power_t Value=3.8868437399949802 *\n",
      "* Parameter=loss Value=log *\n",
      "* Parameter=penalty Value=elasticnet *\n",
      "* Parameter=learning_rate Value=constant *\n",
      "* Particle 74 Algorithm Type SGD CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=alpha Value=3.4517074435682065 *\n",
      "* Parameter=l1_ratio Value=0.4220492900002115 *\n",
      "* Parameter=epsilon Value=3.5191516379399395 *\n",
      "* Parameter=eta0 Value=10.85360318058274 *\n",
      "* Parameter=power_t Value=2.37112092035465 *\n",
      "* Parameter=loss Value=modified_huber *\n",
      "* Parameter=penalty Value=none *\n",
      "* Parameter=learning_rate Value=constant *\n",
      "* Particle 75 Algorithm Type SGD CLASSIFIER: personal best metric=0.20512820512820512 *\n",
      "* Parameter=alpha Value=6.542807667387264 *\n",
      "* Parameter=l1_ratio Value=0.034794935735950716 *\n",
      "* Parameter=epsilon Value=4.952438283086176 *\n",
      "* Parameter=eta0 Value=5.633118452968028 *\n",
      "* Parameter=power_t Value=6.704182461038606 *\n",
      "* Parameter=loss Value=log *\n",
      "* Parameter=penalty Value=none *\n",
      "* Parameter=learning_rate Value=optimal *\n",
      "* Particle 76 Algorithm Type SGD CLASSIFIER: personal best metric=0.3305785123966942 *\n",
      "* Parameter=alpha Value=0.6470692181490766 *\n",
      "* Parameter=l1_ratio Value=0.2319887870515216 *\n",
      "* Parameter=epsilon Value=3.342943707343249 *\n",
      "* Parameter=eta0 Value=3.2690187667236192 *\n",
      "* Parameter=power_t Value=6.44724968476125 *\n",
      "* Parameter=loss Value=hinge *\n",
      "* Parameter=penalty Value=l2 *\n",
      "* Parameter=learning_rate Value=constant *\n",
      "* Particle 77 Algorithm Type SGD CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=alpha Value=10.152917716008387 *\n",
      "* Parameter=l1_ratio Value=0.4389034708752785 *\n",
      "* Parameter=epsilon Value=0.7116908557733478 *\n",
      "* Parameter=eta0 Value=10.560612088312855 *\n",
      "* Parameter=power_t Value=9.383653079910697 *\n",
      "* Parameter=loss Value=perceptron *\n",
      "* Parameter=penalty Value=none *\n",
      "* Parameter=learning_rate Value=optimal *\n",
      "* Particle 78 Algorithm Type SGD CLASSIFIER: personal best metric=0.43866171003717475 *\n",
      "* Parameter=alpha Value=9.959803230648935 *\n",
      "* Parameter=l1_ratio Value=0.23635152524913028 *\n",
      "* Parameter=epsilon Value=10.372302353762148 *\n",
      "* Parameter=eta0 Value=10.91201711155727 *\n",
      "* Parameter=power_t Value=1.6771454453080898 *\n",
      "* Parameter=loss Value=perceptron *\n",
      "* Parameter=penalty Value=none *\n",
      "* Parameter=learning_rate Value=invscaling *\n",
      "* Particle 79 Algorithm Type SGD CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.2082845177154643 *\n",
      "* Parameter=min_samples_split Value=51 *\n",
      "* Parameter=min_samples_leaf Value=184 *\n",
      "* Parameter=n_estimators Value=135 *\n",
      "* Parameter=criterion Value=gini *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Particle 80 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.26655188900396803 *\n",
      "* Parameter=min_samples_split Value=45 *\n",
      "* Parameter=min_samples_leaf Value=39 *\n",
      "* Parameter=n_estimators Value=192 *\n",
      "* Parameter=criterion Value=entropy *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Particle 81 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.22904645145665758 *\n",
      "* Parameter=min_samples_split Value=134 *\n",
      "* Parameter=min_samples_leaf Value=152 *\n",
      "* Parameter=n_estimators Value=97 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "* Particle 82 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.27800825784726935 *\n",
      "* Parameter=min_samples_split Value=164 *\n",
      "* Parameter=min_samples_leaf Value=88 *\n",
      "* Parameter=n_estimators Value=261 *\n",
      "* Parameter=criterion Value=gini *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Particle 83 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.4592679011249329 *\n",
      "* Parameter=min_samples_split Value=41 *\n",
      "* Parameter=min_samples_leaf Value=107 *\n",
      "* Parameter=n_estimators Value=25 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "* Particle 84 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.484241150480801 *\n",
      "* Parameter=min_samples_split Value=73 *\n",
      "* Parameter=min_samples_leaf Value=102 *\n",
      "* Parameter=n_estimators Value=213 *\n",
      "* Parameter=criterion Value=gini *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Particle 85 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.05971081107562398 *\n",
      "* Parameter=min_samples_split Value=110 *\n",
      "* Parameter=min_samples_leaf Value=35 *\n",
      "* Parameter=n_estimators Value=171 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "* Particle 86 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.12608667381458033 *\n",
      "* Parameter=min_samples_split Value=32 *\n",
      "* Parameter=min_samples_leaf Value=89 *\n",
      "* Parameter=n_estimators Value=201 *\n",
      "* Parameter=criterion Value=gini *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Particle 87 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.08824873639188485 *\n",
      "* Parameter=min_samples_split Value=123 *\n",
      "* Parameter=min_samples_leaf Value=45 *\n",
      "* Parameter=n_estimators Value=243 *\n",
      "* Parameter=criterion Value=gini *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Particle 88 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.28619444940890804 *\n",
      "* Parameter=min_samples_split Value=56 *\n",
      "* Parameter=min_samples_leaf Value=87 *\n",
      "* Parameter=n_estimators Value=134 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 89 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.0 *\n",
      "\n",
      "* Particle 30 Removed --- Algorithm Type: EXTRA TREE CLASSIFIER With Metric 0.0 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=90 *\n",
      "* Parameter=min_samples_split Value=15 *\n",
      "* Parameter=n_estimators Value=212 *\n",
      "* Parameter=criterion Value=gini *\n",
      "\n",
      "* Particle 30 Removed --- Algorithm Type: EXTRA TREE CLASSIFIER With Metric 0.0 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=62 *\n",
      "* Parameter=min_samples_split Value=81 *\n",
      "* Parameter=n_estimators Value=12 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "\n",
      "* Particle 30 Removed --- Algorithm Type: EXTRA TREE CLASSIFIER With Metric 0.0 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=29 *\n",
      "* Parameter=min_samples_split Value=67 *\n",
      "* Parameter=n_estimators Value=295 *\n",
      "* Parameter=criterion Value=gini *\n",
      "\n",
      "* Particle 30 Removed --- Algorithm Type: EXTRA TREE CLASSIFIER With Metric 0.0 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=57 *\n",
      "* Parameter=min_samples_split Value=32 *\n",
      "* Parameter=n_estimators Value=223 *\n",
      "* Parameter=criterion Value=gini *\n",
      "\n",
      "* Particle 30 Removed --- Algorithm Type: EXTRA TREE CLASSIFIER With Metric 0.0 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=46 *\n",
      "* Parameter=min_samples_split Value=12 *\n",
      "* Parameter=n_estimators Value=222 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "--- END EPOCH 1 ---\n",
      "--- START EPOCH 1 ---\n",
      "* Parameter=C Value=3 *\n",
      "* Parameter=tol Value=0.26085738326782404 *\n",
      "* Parameter=intercept_scaling Value=0.8493612479062831 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 0 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7297297297297298 *\n",
      "* Parameter=C Value=1.805751365758701 *\n",
      "* Parameter=tol Value=2 *\n",
      "* Parameter=intercept_scaling Value=0.542716845709013 *\n",
      "* Parameter=solver Value=liblinear *\n",
      "* Particle 1 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.6370370370370371 *\n",
      "* Parameter=C Value=2.421096491801948 *\n",
      "* Parameter=tol Value=2 *\n",
      "* Parameter=intercept_scaling Value=0.7771776830899342 *\n",
      "* Parameter=solver Value=lbfgs *\n",
      "* Particle 2 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=1.5270074453856397 *\n",
      "* Parameter=tol Value=2 *\n",
      "* Parameter=intercept_scaling Value=0.34713103619449415 *\n",
      "* Parameter=solver Value=lbfgs *\n",
      "* Particle 3 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=3 *\n",
      "* Parameter=tol Value=1.1606294749955226 *\n",
      "* Parameter=intercept_scaling Value=1 *\n",
      "* Parameter=solver Value=liblinear *\n",
      "* Particle 4 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7346938775510204 *\n",
      "* Parameter=C Value=1.9029228675032535 *\n",
      "* Parameter=tol Value=1.155857474443327 *\n",
      "* Parameter=intercept_scaling Value=0.4884032326879836 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 5 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=0.614228434352605 *\n",
      "* Parameter=tol Value=1.970924713904692 *\n",
      "* Parameter=intercept_scaling Value=0.8910695511626485 *\n",
      "* Parameter=solver Value=lbfgs *\n",
      "* Particle 6 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7297297297297298 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=tol Value=1.1054871788916918 *\n",
      "* Parameter=intercept_scaling Value=1 *\n",
      "* Parameter=solver Value=lbfgs *\n",
      "* Particle 7 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.5384615384615384 *\n",
      "* Parameter=C Value=1.6297892998222514 *\n",
      "* Parameter=tol Value=1.3816628532059019 *\n",
      "* Parameter=intercept_scaling Value=0.9138038667960044 *\n",
      "* Parameter=solver Value=lbfgs *\n",
      "* Particle 8 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=3 *\n",
      "* Parameter=tol Value=0.6181095849314453 *\n",
      "* Parameter=intercept_scaling Value=0.001 *\n",
      "* Parameter=solver Value=sag *\n",
      "* Particle 9 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.6832298136645962 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=3 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 10 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=ball_tree *\n",
      "* Particle 11 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=17 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 12 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=32 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 13 Algorithm Type KNN: personal best metric=0.5742574257425742 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 14 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=9 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 15 Algorithm Type KNN: personal best metric=0.6333333333333334 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 16 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=65 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 17 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=5 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 18 Algorithm Type KNN: personal best metric=0.7079646017699114 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 19 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=max_depth Value=13 *\n",
      "* Parameter=min_samples_split Value=19 *\n",
      "* Parameter=n_estimators Value=196 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "* Particle 20 Algorithm Type RANDOM FOREST: personal best metric=0.903225806451613 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=198 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 21 Algorithm Type RANDOM FOREST: personal best metric=0.9411764705882353 *\n",
      "* Parameter=max_depth Value=50 *\n",
      "* Parameter=min_samples_split Value=25 *\n",
      "* Parameter=n_estimators Value=55 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "* Particle 22 Algorithm Type RANDOM FOREST: personal best metric=0.8661417322834646 *\n",
      "* Parameter=max_depth Value=16 *\n",
      "* Parameter=min_samples_split Value=11 *\n",
      "* Parameter=n_estimators Value=241 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "* Particle 23 Algorithm Type RANDOM FOREST: personal best metric=0.896 *\n",
      "* Parameter=max_depth Value=37 *\n",
      "* Parameter=min_samples_split Value=42 *\n",
      "* Parameter=n_estimators Value=92 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "* Particle 24 Algorithm Type RANDOM FOREST: personal best metric=0.8527131782945736 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=151 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "* Particle 25 Algorithm Type RANDOM FOREST: personal best metric=0.9268292682926829 *\n",
      "* Parameter=max_depth Value=35 *\n",
      "* Parameter=min_samples_split Value=22 *\n",
      "* Parameter=n_estimators Value=214 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 26 Algorithm Type RANDOM FOREST: personal best metric=0.8818897637795277 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=34 *\n",
      "* Parameter=n_estimators Value=165 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 27 Algorithm Type RANDOM FOREST: personal best metric=0.8800000000000001 *\n",
      "* Parameter=max_depth Value=50 *\n",
      "* Parameter=min_samples_split Value=17 *\n",
      "* Parameter=n_estimators Value=211 *\n",
      "* Parameter=criterion Value=gini *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Particle 28 Algorithm Type RANDOM FOREST: personal best metric=0.903225806451613 *\n",
      "* Parameter=max_depth Value=36 *\n",
      "* Parameter=min_samples_split Value=31 *\n",
      "* Parameter=n_estimators Value=300 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 29 Algorithm Type RANDOM FOREST: personal best metric=0.859375 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 30 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.7941176470588235 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 31 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.803030303030303 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 32 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.7317073170731708 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=28 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 33 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.5365853658536586 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=3 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=entropy *\n",
      "* Particle 34 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.8032786885245902 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=random *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 35 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.7906976744186046 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=47 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 36 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.7230769230769231 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=48 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 37 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.7230769230769231 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=128 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 38 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.5853658536585367 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=16 *\n",
      "* Parameter=min_samples_leaf Value=28 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 39 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.5106382978723405 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.030139659078881442 *\n",
      "* Parameter=min_samples_split Value=86 *\n",
      "* Parameter=min_samples_leaf Value=100 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 40 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.6206896551724138 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=5 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 41 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.7938931297709924 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=15 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 42 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.7199999999999999 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.08336239685005084 *\n",
      "* Parameter=min_samples_split Value=26 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 43 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.6206896551724138 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.40053076608048166 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=random *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 44 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.4220183486238532 *\n",
      "* Parameter=alpha Value=32.65665531336244 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 45 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.6944444444444444 *\n",
      "* Parameter=alpha Value=36.15631145896581 *\n",
      "* Parameter=tol Value=8.521454473350591 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 46 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7114093959731544 *\n",
      "* Parameter=alpha Value=48.52154595868214 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 47 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.6944444444444444 *\n",
      "* Parameter=alpha Value=71.65974110508584 *\n",
      "* Parameter=tol Value=0.14548290216925608 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 48 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7114093959731544 *\n",
      "* Parameter=alpha Value=32.242475793703626 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=False *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=cholesky *\n",
      "* Particle 49 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7248322147651007 *\n",
      "* Parameter=alpha Value=1.110595749161448 *\n",
      "* Parameter=tol Value=31.186707795490108 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 50 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7162162162162162 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=13.805130692048717 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 51 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=24.52061814730437 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 52 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.6993006993006992 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 53 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=sag *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Particle 54 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7333333333333333 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 55 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.6341463414634146 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=False *\n",
      "* Particle 56 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.5 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 57 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.7058823529411765 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 58 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.6835443037974683 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 59 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.6050420168067226 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 60 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.6842105263157895 *\n",
      "* Parameter=C Value=17.367761970696865 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 61 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.5849056603773585 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 62 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.681159420289855 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 63 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.6716417910447762 *\n",
      "* Parameter=C Value=33.38472995418017 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 64 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.5045045045045046 *\n",
      "* Parameter=alpha Value=7.674658778480578 *\n",
      "* Parameter=l1_ratio Value=0.0865903085330636 *\n",
      "* Parameter=epsilon Value=0.001 *\n",
      "* Parameter=eta0 Value=0.0001 *\n",
      "* Parameter=power_t Value=0.001 *\n",
      "* Parameter=loss Value=hinge *\n",
      "* Parameter=penalty Value=none *\n",
      "* Parameter=learning_rate Value=constant *\n",
      "* Particle 65 Algorithm Type SGD CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=alpha Value=0.1 *\n",
      "* Parameter=l1_ratio Value=0.1927045382881517 *\n",
      "* Parameter=epsilon Value=0.001 *\n",
      "* Parameter=eta0 Value=0.6077360265241178 *\n",
      "* Parameter=power_t Value=0.001 *\n",
      "* Parameter=loss Value=hinge *\n",
      "* Parameter=penalty Value=l2 *\n",
      "* Parameter=learning_rate Value=constant *\n",
      "* Particle 66 Algorithm Type SGD CLASSIFIER: personal best metric=0.458498023715415 *\n",
      "* Parameter=alpha Value=0.1 *\n",
      "* Parameter=l1_ratio Value=0.0 *\n",
      "* Parameter=epsilon Value=0.001 *\n",
      "* Parameter=eta0 Value=0.0001 *\n",
      "* Parameter=power_t Value=0.001 *\n",
      "* Parameter=loss Value=hinge *\n",
      "* Parameter=penalty Value=none *\n",
      "* Parameter=learning_rate Value=constant *\n",
      "* Particle 67 Algorithm Type SGD CLASSIFIER: personal best metric=0.608695652173913 *\n",
      "* Parameter=alpha Value=1.744758687424048 *\n",
      "* Parameter=l1_ratio Value=0.0 *\n",
      "* Parameter=epsilon Value=0.001 *\n",
      "* Parameter=eta0 Value=0.0001 *\n",
      "* Parameter=power_t Value=0.001 *\n",
      "* Parameter=loss Value=hinge *\n",
      "* Parameter=penalty Value=none *\n",
      "* Parameter=learning_rate Value=optimal *\n",
      "* Particle 68 Algorithm Type SGD CLASSIFIER: personal best metric=0.48120300751879697 *\n",
      "* Parameter=alpha Value=0.1 *\n",
      "* Parameter=l1_ratio Value=0.0 *\n",
      "* Parameter=epsilon Value=4.438043041792322 *\n",
      "* Parameter=eta0 Value=0.0001 *\n",
      "* Parameter=power_t Value=0.001 *\n",
      "* Parameter=loss Value=hinge *\n",
      "* Parameter=penalty Value=l2 *\n",
      "* Parameter=learning_rate Value=constant *\n",
      "* Particle 69 Algorithm Type SGD CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=alpha Value=0.1 *\n",
      "* Parameter=l1_ratio Value=0.025727595220966626 *\n",
      "* Parameter=epsilon Value=0.001 *\n",
      "* Parameter=eta0 Value=4.686780946274743 *\n",
      "* Parameter=power_t Value=0.001 *\n",
      "* Parameter=loss Value=hinge *\n",
      "* Parameter=penalty Value=none *\n",
      "* Parameter=learning_rate Value=constant *\n",
      "* Particle 70 Algorithm Type SGD CLASSIFIER: personal best metric=0.5576923076923076 *\n",
      "* Parameter=alpha Value=0.1 *\n",
      "* Parameter=l1_ratio Value=0.0 *\n",
      "* Parameter=epsilon Value=0.001 *\n",
      "* Parameter=eta0 Value=0.0001 *\n",
      "* Parameter=power_t Value=0.001 *\n",
      "* Parameter=loss Value=log *\n",
      "* Parameter=penalty Value=none *\n",
      "* Parameter=learning_rate Value=optimal *\n",
      "* Particle 71 Algorithm Type SGD CLASSIFIER: personal best metric=0.6129032258064516 *\n",
      "* Parameter=alpha Value=0.1 *\n",
      "* Parameter=l1_ratio Value=0.2981689646567729 *\n",
      "* Parameter=epsilon Value=0.4348242014672312 *\n",
      "* Parameter=eta0 Value=0.0001 *\n",
      "* Parameter=power_t Value=0.001 *\n",
      "* Parameter=loss Value=hinge *\n",
      "* Parameter=penalty Value=none *\n",
      "* Parameter=learning_rate Value=constant *\n",
      "* Particle 72 Algorithm Type SGD CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=alpha Value=0.1 *\n",
      "* Parameter=l1_ratio Value=0.0 *\n",
      "* Parameter=epsilon Value=0.001 *\n",
      "* Parameter=eta0 Value=5.426225140311066 *\n",
      "* Parameter=power_t Value=0.001 *\n",
      "* Parameter=loss Value=hinge *\n",
      "* Parameter=penalty Value=none *\n",
      "* Parameter=learning_rate Value=constant *\n",
      "* Particle 73 Algorithm Type SGD CLASSIFIER: personal best metric=0.6547619047619047 *\n",
      "* Parameter=alpha Value=0.1 *\n",
      "* Parameter=l1_ratio Value=0.11643108548411818 *\n",
      "* Parameter=epsilon Value=0.001 *\n",
      "* Parameter=eta0 Value=3.457596391100247 *\n",
      "* Parameter=power_t Value=0.001 *\n",
      "* Parameter=loss Value=hinge *\n",
      "* Parameter=penalty Value=none *\n",
      "* Parameter=learning_rate Value=constant *\n",
      "* Particle 74 Algorithm Type SGD CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 75 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8275862068965518 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=84 *\n",
      "* Parameter=criterion Value=gini *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Particle 76 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8947368421052632 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.2854350555554516 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=84 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 77 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=84 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 78 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.9122807017543859 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 79 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8245614035087718 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.5 *\n",
      "* Parameter=min_samples_split Value=17 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 80 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=62 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 81 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.4631578947368421 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.42823450790056333 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 82 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.2899231522520226 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=9 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 83 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.1347069547456074 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=61 *\n",
      "* Parameter=criterion Value=gini *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Particle 84 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=24 *\n",
      "* Parameter=n_estimators Value=177 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "* Particle 85 Algorithm Type RANDOM FOREST: personal best metric=0.903225806451613 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=300 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 86 Algorithm Type RANDOM FOREST: personal best metric=0.9105691056910569 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=11 *\n",
      "* Parameter=n_estimators Value=42 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "* Particle 87 Algorithm Type RANDOM FOREST: personal best metric=0.888888888888889 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=218 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 88 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=12 *\n",
      "* Parameter=n_estimators Value=182 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 89 Algorithm Type RANDOM FOREST: personal best metric=0.9016393442622951 *\n",
      "\n",
      "* Particle 65 Removed --- Algorithm Type: SGD CLASSIFIER With Metric 0.0 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=19 *\n",
      "* Parameter=min_samples_split Value=41 *\n",
      "* Parameter=n_estimators Value=165 *\n",
      "* Parameter=criterion Value=gini *\n",
      "\n",
      "* Particle 68 Removed --- Algorithm Type: SGD CLASSIFIER With Metric 0.0 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=74 *\n",
      "* Parameter=min_samples_split Value=10 *\n",
      "* Parameter=n_estimators Value=28 *\n",
      "* Parameter=criterion Value=gini *\n",
      "\n",
      "* Particle 70 Removed --- Algorithm Type: SGD CLASSIFIER With Metric 0.0 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=30 *\n",
      "* Parameter=min_samples_split Value=6 *\n",
      "* Parameter=n_estimators Value=237 *\n",
      "* Parameter=criterion Value=gini *\n",
      "\n",
      "* Particle 71 Removed --- Algorithm Type: SGD CLASSIFIER With Metric 0.0 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=74 *\n",
      "* Parameter=min_samples_split Value=84 *\n",
      "* Parameter=n_estimators Value=112 *\n",
      "* Parameter=criterion Value=gini *\n",
      "\n",
      "* Particle 73 Removed --- Algorithm Type: EXTRA TREES CLASSIFIER With Metric 0.0 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=13 *\n",
      "* Parameter=min_samples_split Value=62 *\n",
      "* Parameter=n_estimators Value=89 *\n",
      "* Parameter=criterion Value=gini *\n",
      "--- END EPOCH 2 ---\n",
      "--- START EPOCH 2 ---\n",
      "* Parameter=C Value=3 *\n",
      "* Parameter=tol Value=0.831488937670786 *\n",
      "* Parameter=intercept_scaling Value=0.195569661670413 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 0 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=2.2738047436461004 *\n",
      "* Parameter=tol Value=0.7256153445610283 *\n",
      "* Parameter=intercept_scaling Value=0.8135555830374529 *\n",
      "* Parameter=solver Value=liblinear *\n",
      "* Particle 1 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.696774193548387 *\n",
      "* Parameter=C Value=1.9854040445978631 *\n",
      "* Parameter=tol Value=0.6242942657681578 *\n",
      "* Parameter=intercept_scaling Value=0.9574039185760411 *\n",
      "* Parameter=solver Value=lbfgs *\n",
      "* Particle 2 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=1.8158579517229523 *\n",
      "* Parameter=tol Value=0.9928399149732567 *\n",
      "* Parameter=intercept_scaling Value=0.3190442146501035 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 3 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=2.494527390454504 *\n",
      "* Parameter=tol Value=1.4661709581978657 *\n",
      "* Parameter=intercept_scaling Value=0.45524445122819157 *\n",
      "* Parameter=solver Value=sag *\n",
      "* Particle 4 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7346938775510204 *\n",
      "* Parameter=C Value=1.8757175842567186 *\n",
      "* Parameter=tol Value=1.1642408976845708 *\n",
      "* Parameter=intercept_scaling Value=0.6308571708311148 *\n",
      "* Parameter=solver Value=lbfgs *\n",
      "* Particle 5 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=3 *\n",
      "* Parameter=tol Value=0.7548178577574614 *\n",
      "* Parameter=intercept_scaling Value=0.7324198071698386 *\n",
      "* Parameter=solver Value=sag *\n",
      "* Particle 6 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7297297297297298 *\n",
      "* Parameter=C Value=0.4958639088725253 *\n",
      "* Parameter=tol Value=0.9264469116208547 *\n",
      "* Parameter=intercept_scaling Value=0.5033059335925447 *\n",
      "* Parameter=solver Value=lbfgs *\n",
      "* Particle 7 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7346938775510204 *\n",
      "* Parameter=C Value=1.053390012905357 *\n",
      "* Parameter=tol Value=1.6496994282991468 *\n",
      "* Parameter=intercept_scaling Value=0.24598339958203563 *\n",
      "* Parameter=solver Value=lbfgs *\n",
      "* Particle 8 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=3 *\n",
      "* Parameter=tol Value=0.6405193548785679 *\n",
      "* Parameter=intercept_scaling Value=0.4806804618304442 *\n",
      "* Parameter=solver Value=sag *\n",
      "* Particle 9 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.6832298136645962 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 10 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 11 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 12 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=6 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 13 Algorithm Type KNN: personal best metric=0.6095238095238096 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 14 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 15 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 16 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=34 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 17 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 18 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 19 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=max_depth Value=12 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=197 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 20 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=190 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 21 Algorithm Type RANDOM FOREST: personal best metric=0.9411764705882353 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=300 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 22 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=205 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 23 Algorithm Type RANDOM FOREST: personal best metric=0.9059829059829059 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=285 *\n",
      "* Parameter=criterion Value=gini *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Particle 24 Algorithm Type RANDOM FOREST: personal best metric=0.9075630252100839 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=186 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 25 Algorithm Type RANDOM FOREST: personal best metric=0.9268292682926829 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=25 *\n",
      "* Parameter=n_estimators Value=235 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 26 Algorithm Type RANDOM FOREST: personal best metric=0.8818897637795277 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=143 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 27 Algorithm Type RANDOM FOREST: personal best metric=0.8800000000000001 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=155 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 28 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=300 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 29 Algorithm Type RANDOM FOREST: personal best metric=0.9059829059829059 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 30 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.7941176470588235 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 31 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.803030303030303 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 32 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.75 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 33 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.8062015503875969 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=entropy *\n",
      "* Particle 34 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.8032786885245902 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 35 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8225806451612904 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=7 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 36 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.796875 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 37 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8062015503875969 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 38 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.7846153846153846 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 39 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.7846153846153846 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=51 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 40 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.6206896551724138 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 41 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.7938931297709924 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 42 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.7874015748031497 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 43 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.796875 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 44 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8031496062992127 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 45 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 46 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 47 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 48 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 49 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 50 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 51 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 52 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 53 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=sparse_cg *\n",
      "* Particle 54 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 55 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.676470588235294 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 56 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.689655172413793 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 57 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.7058823529411765 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 58 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.6835443037974683 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 59 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.6666666666666666 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 60 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.6842105263157895 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 61 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.5849056603773585 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 62 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.681159420289855 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 63 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.6857142857142857 *\n",
      "* Parameter=C Value=13.46781202846649 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 64 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.5935483870967743 *\n",
      "* Parameter=alpha Value=0.1 *\n",
      "* Parameter=l1_ratio Value=0.0 *\n",
      "* Parameter=epsilon Value=0.001 *\n",
      "* Parameter=eta0 Value=0.0001 *\n",
      "* Parameter=power_t Value=0.001 *\n",
      "* Parameter=loss Value=hinge *\n",
      "* Parameter=penalty Value=none *\n",
      "* Parameter=learning_rate Value=constant *\n",
      "* Particle 65 Algorithm Type SGD CLASSIFIER: personal best metric=0.458498023715415 *\n",
      "* Parameter=alpha Value=0.1 *\n",
      "* Parameter=l1_ratio Value=0.0 *\n",
      "* Parameter=epsilon Value=0.001 *\n",
      "* Parameter=eta0 Value=0.0001 *\n",
      "* Parameter=power_t Value=0.001 *\n",
      "* Parameter=loss Value=hinge *\n",
      "* Parameter=penalty Value=none *\n",
      "* Parameter=learning_rate Value=constant *\n",
      "* Particle 66 Algorithm Type SGD CLASSIFIER: personal best metric=0.608695652173913 *\n",
      "* Parameter=alpha Value=0.1 *\n",
      "* Parameter=l1_ratio Value=0.0 *\n",
      "* Parameter=epsilon Value=0.001 *\n",
      "* Parameter=eta0 Value=0.0001 *\n",
      "* Parameter=power_t Value=0.001 *\n",
      "* Parameter=loss Value=hinge *\n",
      "* Parameter=penalty Value=none *\n",
      "* Parameter=learning_rate Value=constant *\n",
      "* Particle 67 Algorithm Type SGD CLASSIFIER: personal best metric=0.48120300751879697 *\n",
      "* Parameter=alpha Value=0.1 *\n",
      "* Parameter=l1_ratio Value=0.0 *\n",
      "* Parameter=epsilon Value=0.001 *\n",
      "* Parameter=eta0 Value=0.0001 *\n",
      "* Parameter=power_t Value=0.001 *\n",
      "* Parameter=loss Value=hinge *\n",
      "* Parameter=penalty Value=none *\n",
      "* Parameter=learning_rate Value=constant *\n",
      "* Particle 68 Algorithm Type SGD CLASSIFIER: personal best metric=0.5576923076923076 *\n",
      "* Parameter=alpha Value=0.1 *\n",
      "* Parameter=l1_ratio Value=0.0 *\n",
      "* Parameter=epsilon Value=0.001 *\n",
      "* Parameter=eta0 Value=0.0001 *\n",
      "* Parameter=power_t Value=0.001 *\n",
      "* Parameter=loss Value=hinge *\n",
      "* Parameter=penalty Value=none *\n",
      "* Parameter=learning_rate Value=constant *\n",
      "* Particle 69 Algorithm Type SGD CLASSIFIER: personal best metric=0.6129032258064516 *\n",
      "* Parameter=alpha Value=0.1 *\n",
      "* Parameter=l1_ratio Value=0.0 *\n",
      "* Parameter=epsilon Value=0.001 *\n",
      "* Parameter=eta0 Value=0.0001 *\n",
      "* Parameter=power_t Value=0.001 *\n",
      "* Parameter=loss Value=hinge *\n",
      "* Parameter=penalty Value=none *\n",
      "* Parameter=learning_rate Value=constant *\n",
      "* Particle 70 Algorithm Type SGD CLASSIFIER: personal best metric=0.6547619047619047 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 71 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8495575221238938 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 72 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8947368421052632 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 73 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.9122807017543859 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 74 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8245614035087718 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.43238564714130645 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 75 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.0 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=10 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 76 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8135593220338985 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 77 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.7580645161290323 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 78 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.7652173913043477 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 79 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.7818181818181819 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=9 *\n",
      "* Parameter=n_estimators Value=213 *\n",
      "* Parameter=criterion Value=entropy *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Particle 80 Algorithm Type RANDOM FOREST: personal best metric=0.903225806451613 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=300 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 81 Algorithm Type RANDOM FOREST: personal best metric=0.9180327868852458 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=86 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 82 Algorithm Type RANDOM FOREST: personal best metric=0.888888888888889 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=182 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 83 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=196 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 84 Algorithm Type RANDOM FOREST: personal best metric=0.9016393442622951 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=225 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 85 Algorithm Type RANDOM FOREST: personal best metric=0.9180327868852458 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=300 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 86 Algorithm Type RANDOM FOREST: personal best metric=0.8907563025210085 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=122 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 87 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=66 *\n",
      "* Parameter=n_estimators Value=300 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 88 Algorithm Type RANDOM FOREST: personal best metric=0.8333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=4 *\n",
      "* Parameter=n_estimators Value=300 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 89 Algorithm Type RANDOM FOREST: personal best metric=0.9059829059829059 *\n",
      "\n",
      "* Particle 75 Removed --- Algorithm Type: EXTRA TREES CLASSIFIER With Metric 0.0 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=53 *\n",
      "* Parameter=min_samples_split Value=55 *\n",
      "* Parameter=n_estimators Value=293 *\n",
      "* Parameter=criterion Value=gini *\n",
      "\n",
      "* Particle 65 Removed --- Algorithm Type: SGD CLASSIFIER With Metric 0.458498023715415 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=39 *\n",
      "* Parameter=min_samples_split Value=41 *\n",
      "* Parameter=n_estimators Value=246 *\n",
      "* Parameter=criterion Value=gini *\n",
      "\n",
      "* Particle 66 Removed --- Algorithm Type: SGD CLASSIFIER With Metric 0.48120300751879697 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=71 *\n",
      "* Parameter=min_samples_split Value=28 *\n",
      "* Parameter=n_estimators Value=224 *\n",
      "* Parameter=criterion Value=gini *\n",
      "\n",
      "* Particle 66 Removed --- Algorithm Type: SGD CLASSIFIER With Metric 0.5576923076923076 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=30 *\n",
      "* Parameter=min_samples_split Value=36 *\n",
      "* Parameter=n_estimators Value=289 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "\n",
      "* Particle 61 Removed --- Algorithm Type: PASSIVE AGRESSIVE CLASSIFIER With Metric 0.5849056603773585 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=15 *\n",
      "* Parameter=min_samples_split Value=45 *\n",
      "* Parameter=n_estimators Value=271 *\n",
      "* Parameter=criterion Value=gini *\n",
      "--- END EPOCH 3 ---\n",
      "--- START EPOCH 3 ---\n",
      "* Parameter=C Value=0.8685303145686505 *\n",
      "* Parameter=tol Value=1.8717071824749398 *\n",
      "* Parameter=intercept_scaling Value=0.6876521734725787 *\n",
      "* Parameter=solver Value=lbfgs *\n",
      "* Particle 0 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=1.8066195090701789 *\n",
      "* Parameter=tol Value=0.20765800217976338 *\n",
      "* Parameter=intercept_scaling Value=0.5141616075099911 *\n",
      "* Parameter=solver Value=sag *\n",
      "* Particle 1 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.696774193548387 *\n",
      "* Parameter=C Value=1.5874851829403487 *\n",
      "* Parameter=tol Value=1.126126173591814 *\n",
      "* Parameter=intercept_scaling Value=0.22226804816597379 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 2 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=2.1015140057747277 *\n",
      "* Parameter=tol Value=0.5422650940642496 *\n",
      "* Parameter=intercept_scaling Value=0.9456828061400089 *\n",
      "* Parameter=solver Value=liblinear *\n",
      "* Particle 3 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=2.0115372193718377 *\n",
      "* Parameter=tol Value=1.2233516770202408 *\n",
      "* Parameter=intercept_scaling Value=0.3432436653742164 *\n",
      "* Parameter=solver Value=liblinear *\n",
      "* Particle 4 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7346938775510204 *\n",
      "* Parameter=C Value=1.8689755384766098 *\n",
      "* Parameter=tol Value=1.168671066890689 *\n",
      "* Parameter=intercept_scaling Value=0.6530237263194372 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 5 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=3 *\n",
      "* Parameter=tol Value=1.0409540673363913 *\n",
      "* Parameter=intercept_scaling Value=0.22131628155414373 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 6 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=3 *\n",
      "* Parameter=tol Value=0.9857707209924627 *\n",
      "* Parameter=intercept_scaling Value=0.3168504053885839 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 7 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=1.116310006438861 *\n",
      "* Parameter=tol Value=1.1775440593596924 *\n",
      "* Parameter=intercept_scaling Value=0.8536965376125439 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 8 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=1.2513098475243394 *\n",
      "* Parameter=tol Value=2 *\n",
      "* Parameter=intercept_scaling Value=0.9848560752101864 *\n",
      "* Parameter=solver Value=sag *\n",
      "* Particle 9 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.6832298136645962 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 10 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 11 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 12 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 13 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 14 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 15 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 16 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 17 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 18 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 19 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=198 *\n",
      "* Parameter=criterion Value=gini *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Particle 20 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=206 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 21 Algorithm Type RANDOM FOREST: personal best metric=0.9411764705882353 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=207 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 22 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=181 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 23 Algorithm Type RANDOM FOREST: personal best metric=0.9193548387096773 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=179 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 24 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=206 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 25 Algorithm Type RANDOM FOREST: personal best metric=0.9268292682926829 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=191 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 26 Algorithm Type RANDOM FOREST: personal best metric=0.9180327868852458 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=267 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 27 Algorithm Type RANDOM FOREST: personal best metric=0.9268292682926829 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=227 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 28 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=54 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 29 Algorithm Type RANDOM FOREST: personal best metric=0.9059829059829059 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 30 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.7941176470588235 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 31 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.803030303030303 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 32 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.7899159663865546 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 33 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.8062015503875969 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 34 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.8032786885245902 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 35 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8225806451612904 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 36 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.796875 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 37 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8062015503875969 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 38 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8225806451612904 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 39 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8031496062992127 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 40 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.796875 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 41 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8064516129032259 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 42 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8062015503875969 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 43 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.796875 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 44 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8062015503875969 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 45 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 46 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 47 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 48 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 49 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 50 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 51 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 52 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 53 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 54 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 55 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.676470588235294 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 56 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.689655172413793 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 57 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.7058823529411765 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 58 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.6835443037974683 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 59 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.7105263157894736 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 60 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.6842105263157895 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 61 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.681159420289855 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 62 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.6857142857142857 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 63 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.5935483870967743 *\n",
      "* Parameter=alpha Value=0.1 *\n",
      "* Parameter=l1_ratio Value=0.0 *\n",
      "* Parameter=epsilon Value=0.001 *\n",
      "* Parameter=eta0 Value=0.0001 *\n",
      "* Parameter=power_t Value=0.001 *\n",
      "* Parameter=loss Value=hinge *\n",
      "* Parameter=penalty Value=none *\n",
      "* Parameter=learning_rate Value=constant *\n",
      "* Particle 64 Algorithm Type SGD CLASSIFIER: personal best metric=0.608695652173913 *\n",
      "* Parameter=alpha Value=0.1 *\n",
      "* Parameter=l1_ratio Value=0.0 *\n",
      "* Parameter=epsilon Value=0.001 *\n",
      "* Parameter=eta0 Value=0.0001 *\n",
      "* Parameter=power_t Value=0.001 *\n",
      "* Parameter=loss Value=hinge *\n",
      "* Parameter=penalty Value=none *\n",
      "* Parameter=learning_rate Value=constant *\n",
      "* Particle 65 Algorithm Type SGD CLASSIFIER: personal best metric=0.6129032258064516 *\n",
      "* Parameter=alpha Value=0.1 *\n",
      "* Parameter=l1_ratio Value=0.0 *\n",
      "* Parameter=epsilon Value=0.001 *\n",
      "* Parameter=eta0 Value=0.0001 *\n",
      "* Parameter=power_t Value=0.001 *\n",
      "* Parameter=loss Value=hinge *\n",
      "* Parameter=penalty Value=none *\n",
      "* Parameter=learning_rate Value=constant *\n",
      "* Particle 66 Algorithm Type SGD CLASSIFIER: personal best metric=0.6547619047619047 *"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 67 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8495575221238938 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 68 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8947368421052632 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 69 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.9122807017543859 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 70 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.890909090909091 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 71 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8275862068965518 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 72 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8166666666666667 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 73 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.7964601769911505 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 74 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.7818181818181819 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=204 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 75 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=300 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 76 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=153 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 77 Algorithm Type RANDOM FOREST: personal best metric=0.9105691056910569 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=173 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 78 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=206 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 79 Algorithm Type RANDOM FOREST: personal best metric=0.9016393442622951 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=251 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 80 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=249 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 81 Algorithm Type RANDOM FOREST: personal best metric=0.8907563025210085 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=218 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 82 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=163 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 83 Algorithm Type RANDOM FOREST: personal best metric=0.8833333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=177 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 84 Algorithm Type RANDOM FOREST: personal best metric=0.9105691056910569 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=9 *\n",
      "* Parameter=n_estimators Value=193 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 85 Algorithm Type RANDOM FOREST: personal best metric=0.8739495798319329 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=29 *\n",
      "* Parameter=n_estimators Value=177 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 86 Algorithm Type RANDOM FOREST: personal best metric=0.8661417322834646 *\n",
      "* Parameter=max_depth Value=34 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=205 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 87 Algorithm Type RANDOM FOREST: personal best metric=0.9137931034482759 *\n",
      "* Parameter=max_depth Value=18 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=109 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 88 Algorithm Type RANDOM FOREST: personal best metric=0.8983050847457628 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=265 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 89 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "\n",
      "* Particle 63 Removed --- Algorithm Type: PASSIVE AGRESSIVE CLASSIFIER With Metric 0.5935483870967743 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=21 *\n",
      "* Parameter=min_samples_split Value=12 *\n",
      "* Parameter=n_estimators Value=52 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "\n",
      "* Particle 63 Removed --- Algorithm Type: SGD CLASSIFIER With Metric 0.608695652173913 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=45 *\n",
      "* Parameter=min_samples_split Value=28 *\n",
      "* Parameter=n_estimators Value=106 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "\n",
      "* Particle 63 Removed --- Algorithm Type: SGD CLASSIFIER With Metric 0.6129032258064516 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=73 *\n",
      "* Parameter=min_samples_split Value=64 *\n",
      "* Parameter=n_estimators Value=68 *\n",
      "* Parameter=criterion Value=gini *\n",
      "\n",
      "* Particle 63 Removed --- Algorithm Type: SGD CLASSIFIER With Metric 0.6547619047619047 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=54 *\n",
      "* Parameter=min_samples_split Value=56 *\n",
      "* Parameter=n_estimators Value=268 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "\n",
      "* Particle 55 Removed --- Algorithm Type: PASSIVE AGRESSIVE CLASSIFIER With Metric 0.676470588235294 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=29 *\n",
      "* Parameter=min_samples_split Value=90 *\n",
      "* Parameter=n_estimators Value=283 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "--- END EPOCH 4 ---\n",
      "--- START EPOCH 4 ---\n",
      "* Parameter=C Value=1.2085541215853546 *\n",
      "* Parameter=tol Value=0.9538233387434246 *\n",
      "* Parameter=intercept_scaling Value=0.6236687162454708 *\n",
      "* Parameter=solver Value=lbfgs *\n",
      "* Particle 0 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=1.7693398858042544 *\n",
      "* Parameter=tol Value=0.7650428795555809 *\n",
      "* Parameter=intercept_scaling Value=0.5076436792323692 *\n",
      "* Parameter=solver Value=sag *\n",
      "* Particle 1 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.696774193548387 *\n",
      "* Parameter=C Value=2.0934532928150738 *\n",
      "* Parameter=tol Value=1.451908408146269 *\n",
      "* Parameter=intercept_scaling Value=0.4385636066818192 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 2 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=2.061161786839288 *\n",
      "* Parameter=tol Value=1.9516728023220296 *\n",
      "* Parameter=intercept_scaling Value=0.24424606911789715 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 3 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=1.6525963981375948 *\n",
      "* Parameter=tol Value=0.9961327477755367 *\n",
      "* Parameter=intercept_scaling Value=0.7965646505695481 *\n",
      "* Parameter=solver Value=liblinear *\n",
      "* Particle 4 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7346938775510204 *\n",
      "* Parameter=C Value=1.87559782236961 *\n",
      "* Parameter=tol Value=1.196346451916495 *\n",
      "* Parameter=intercept_scaling Value=0.4566289486418423 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 5 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=2.167045969428833 *\n",
      "* Parameter=tol Value=1.3336294646533418 *\n",
      "* Parameter=intercept_scaling Value=0.5699558031814855 *\n",
      "* Parameter=solver Value=liblinear *\n",
      "* Particle 6 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=3 *\n",
      "* Parameter=tol Value=1.206627795876348 *\n",
      "* Parameter=intercept_scaling Value=0.799236287925843 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 7 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=1.5567198036562226 *\n",
      "* Parameter=tol Value=0.9454146926105338 *\n",
      "* Parameter=intercept_scaling Value=0.4879350591975756 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 8 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=2.1379787788581983 *\n",
      "* Parameter=tol Value=1.0121329956570237 *\n",
      "* Parameter=intercept_scaling Value=0.22318956514070354 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 9 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 10 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Particle 11 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 12 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 13 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 14 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 15 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 16 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 17 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 18 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 19 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=198 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 20 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=210 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 21 Algorithm Type RANDOM FOREST: personal best metric=0.9411764705882353 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=136 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 22 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=208 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 23 Algorithm Type RANDOM FOREST: personal best metric=0.9411764705882353 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=172 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 24 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=211 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 25 Algorithm Type RANDOM FOREST: personal best metric=0.9268292682926829 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=186 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 26 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=206 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 27 Algorithm Type RANDOM FOREST: personal best metric=0.9268292682926829 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=178 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 28 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 29 Algorithm Type RANDOM FOREST: personal best metric=0.9059829059829059 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 30 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.7941176470588235 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 31 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.803030303030303 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 32 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.7899159663865546 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 33 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.8062015503875969 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 34 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.8032786885245902 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 35 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8225806451612904 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 36 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.796875 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 37 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8062015503875969 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 38 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8225806451612904 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 39 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8095238095238095 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 40 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.796875 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 41 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8064516129032259 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 42 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8130081300813008 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 43 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.7999999999999999 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 44 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8062015503875969 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 45 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 46 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 47 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 48 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 49 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 50 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 51 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 52 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Particle 53 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 54 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 55 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.689655172413793 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 56 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.7058823529411765 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 57 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.6835443037974683 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 58 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.7105263157894736 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 59 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.6842105263157895 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 60 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.681159420289855 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 61 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.6857142857142857 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 62 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8495575221238938 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 63 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8947368421052632 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 64 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.9122807017543859 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 65 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.890909090909091 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 66 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8521739130434782 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 67 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8648648648648649 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 68 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.7964601769911505 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 69 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.7818181818181819 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=196 *\n",
      "* Parameter=criterion Value=gini *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Particle 70 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=116 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 71 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=199 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 72 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=220 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 73 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=202 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 74 Algorithm Type RANDOM FOREST: personal best metric=0.9180327868852458 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=228 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 75 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=114 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 76 Algorithm Type RANDOM FOREST: personal best metric=0.8907563025210085 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=265 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 77 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=121 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 78 Algorithm Type RANDOM FOREST: personal best metric=0.9180327868852458 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=145 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 79 Algorithm Type RANDOM FOREST: personal best metric=0.9105691056910569 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=145 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 80 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=15 *\n",
      "* Parameter=n_estimators Value=199 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 81 Algorithm Type RANDOM FOREST: personal best metric=0.8943089430894309 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=187 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 82 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=254 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 83 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=174 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 84 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=17 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=180 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 85 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=300 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "* Particle 86 Algorithm Type RANDOM FOREST: personal best metric=0.9059829059829059 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=237 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 87 Algorithm Type RANDOM FOREST: personal best metric=0.8907563025210085 *\n",
      "* Parameter=max_depth Value=35 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=90 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "* Particle 88 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=91 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 89 Algorithm Type RANDOM FOREST: personal best metric=0.896 *\n",
      "\n",
      "* Particle 60 Removed --- Algorithm Type: PASSIVE AGRESSIVE CLASSIFIER With Metric 0.681159420289855 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=79 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=173 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "\n",
      "* Particle 57 Removed --- Algorithm Type: PASSIVE AGRESSIVE CLASSIFIER With Metric 0.6835443037974683 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=86 *\n",
      "* Parameter=min_samples_split Value=74 *\n",
      "* Parameter=n_estimators Value=5 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "\n",
      "* Particle 58 Removed --- Algorithm Type: PASSIVE AGRESSIVE CLASSIFIER With Metric 0.6842105263157895 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=14 *\n",
      "* Parameter=min_samples_split Value=44 *\n",
      "* Parameter=n_estimators Value=112 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "\n",
      "* Particle 58 Removed --- Algorithm Type: PASSIVE AGRESSIVE CLASSIFIER With Metric 0.6857142857142857 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=87 *\n",
      "* Parameter=min_samples_split Value=37 *\n",
      "* Parameter=n_estimators Value=181 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "\n",
      "* Particle 55 Removed --- Algorithm Type: PASSIVE AGRESSIVE CLASSIFIER With Metric 0.689655172413793 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=29 *\n",
      "* Parameter=min_samples_split Value=19 *\n",
      "* Parameter=n_estimators Value=146 *\n",
      "* Parameter=criterion Value=gini *\n",
      "--- END EPOCH 5 ---\n",
      "--- START EPOCH 5 ---\n",
      "* Parameter=C Value=3 *\n",
      "* Parameter=tol Value=0.9353431696589241 *\n",
      "* Parameter=intercept_scaling Value=0.4865536612855609 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 0 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=2.0912483192220583 *\n",
      "* Parameter=tol Value=2 *\n",
      "* Parameter=intercept_scaling Value=0.6666306472679338 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 1 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=2.1234334946954903 *\n",
      "* Parameter=tol Value=0.9411684411717781 *\n",
      "* Parameter=intercept_scaling Value=0.831887796411956 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 2 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=1.7826115581959943 *\n",
      "* Parameter=tol Value=2 *\n",
      "* Parameter=intercept_scaling Value=0.001 *\n",
      "* Parameter=solver Value=sag *\n",
      "* Particle 3 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=1.5356845585129875 *\n",
      "* Parameter=tol Value=1.2727043873228374 *\n",
      "* Parameter=intercept_scaling Value=0.3909064658025158 *\n",
      "* Parameter=solver Value=sag *\n",
      "* Particle 4 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7346938775510204 *\n",
      "* Parameter=C Value=1.8994606867981634 *\n",
      "* Parameter=tol Value=1.2018701539107355 *\n",
      "* Parameter=intercept_scaling Value=0.634092475828749 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 5 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=0.9751135184519344 *\n",
      "* Parameter=tol Value=1.4492807971270014 *\n",
      "* Parameter=intercept_scaling Value=0.7531270402976489 *\n",
      "* Parameter=solver Value=lbfgs *\n",
      "* Particle 6 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=0.06739998550708748 *\n",
      "* Parameter=tol Value=1.2843347082076904 *\n",
      "* Parameter=intercept_scaling Value=0.5548276642674077 *\n",
      "* Parameter=solver Value=lbfgs *\n",
      "* Particle 7 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=2.02534654386377 *\n",
      "* Parameter=tol Value=1.09121814039834 *\n",
      "* Parameter=intercept_scaling Value=0.3684819371055621 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 8 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=2.1926280665327185 *\n",
      "* Parameter=tol Value=0.6326517543605173 *\n",
      "* Parameter=intercept_scaling Value=0.6976827430260183 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 9 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 10 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 11 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Particle 12 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 13 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 14 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 15 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 16 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 17 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 18 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 19 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=198 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 20 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=186 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 21 Algorithm Type RANDOM FOREST: personal best metric=0.9411764705882353 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=279 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 22 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=196 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 23 Algorithm Type RANDOM FOREST: personal best metric=0.9411764705882353 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=180 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 24 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=178 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 25 Algorithm Type RANDOM FOREST: personal best metric=0.9268292682926829 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=210 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 26 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=158 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 27 Algorithm Type RANDOM FOREST: personal best metric=0.9268292682926829 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=196 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 28 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=75 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 29 Algorithm Type RANDOM FOREST: personal best metric=0.9180327868852458 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 30 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.7941176470588235 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 31 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.8527131782945736 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 32 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.7899159663865546 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 33 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.8217054263565892 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 34 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.8032786885245902 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 35 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8225806451612904 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 36 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.796875 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 37 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8062015503875969 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 38 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8225806451612904 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 39 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8095238095238095 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 40 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.796875 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 41 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8064516129032259 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 42 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8130081300813008 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 43 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8031496062992127 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 44 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8095238095238095 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 45 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 46 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 47 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 48 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 49 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 50 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 51 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 52 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 53 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 54 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 55 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.7058823529411765 *\n",
      "* Parameter=C Value=0.001 *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Particle 56 Algorithm Type PASSIVE AGRESSIVE CLASSIFIER: personal best metric=0.7105263157894736 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 57 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.864406779661017 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 58 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8947368421052632 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 59 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.9122807017543859 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Particle 60 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.890909090909091 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 61 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8521739130434782 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 62 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8648648648648649 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 63 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8421052631578948 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 64 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8103448275862069 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=200 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 65 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=157 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 66 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=222 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 67 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=209 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 68 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=194 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 69 Algorithm Type RANDOM FOREST: personal best metric=0.9180327868852458 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=216 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 70 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=236 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 71 Algorithm Type RANDOM FOREST: personal best metric=0.9059829059829059 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=102 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 72 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=114 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 73 Algorithm Type RANDOM FOREST: personal best metric=0.9180327868852458 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=223 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 74 Algorithm Type RANDOM FOREST: personal best metric=0.9105691056910569 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=251 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 75 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=210 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 76 Algorithm Type RANDOM FOREST: personal best metric=0.9180327868852458 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=189 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 77 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=186 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 78 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=142 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 79 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=291 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 80 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=291 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 81 Algorithm Type RANDOM FOREST: personal best metric=0.9059829059829059 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=227 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 82 Algorithm Type RANDOM FOREST: personal best metric=0.9152542372881356 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=147 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 83 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=62 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 84 Algorithm Type RANDOM FOREST: personal best metric=0.9075630252100839 *\n",
      "* Parameter=max_depth Value=48 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=216 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 85 Algorithm Type RANDOM FOREST: personal best metric=0.9105691056910569 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=299 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 86 Algorithm Type RANDOM FOREST: personal best metric=0.9059829059829059 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=164 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 87 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=26 *\n",
      "* Parameter=n_estimators Value=206 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 88 Algorithm Type RANDOM FOREST: personal best metric=0.8682170542635659 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=271 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 89 Algorithm Type RANDOM FOREST: personal best metric=0.9180327868852458 *\n",
      "\n",
      "* Particle 55 Removed --- Algorithm Type: PASSIVE AGRESSIVE CLASSIFIER With Metric 0.7058823529411765 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=54 *\n",
      "* Parameter=min_samples_split Value=80 *\n",
      "* Parameter=n_estimators Value=171 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "\n",
      "* Particle 55 Removed --- Algorithm Type: PASSIVE AGRESSIVE CLASSIFIER With Metric 0.7105263157894736 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=76 *\n",
      "* Parameter=min_samples_split Value=43 *\n",
      "* Parameter=n_estimators Value=132 *\n",
      "* Parameter=criterion Value=gini *\n",
      "\n",
      "* Particle 10 Removed --- Algorithm Type: KNN With Metric 0.7155963302752293 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=79 *\n",
      "* Parameter=min_samples_split Value=25 *\n",
      "* Parameter=n_estimators Value=286 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "\n",
      "* Particle 10 Removed --- Algorithm Type: KNN With Metric 0.7155963302752293 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=50 *\n",
      "* Parameter=min_samples_split Value=75 *\n",
      "* Parameter=n_estimators Value=15 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "\n",
      "* Particle 10 Removed --- Algorithm Type: KNN With Metric 0.7155963302752293 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=70 *\n",
      "* Parameter=min_samples_split Value=41 *\n",
      "* Parameter=n_estimators Value=44 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "--- END EPOCH 6 ---\n",
      "--- START EPOCH 6 ---\n",
      "* Parameter=C Value=1.115451971334977 *\n",
      "* Parameter=tol Value=0.9904999986679456 *\n",
      "* Parameter=intercept_scaling Value=0.4840737956017846 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 0 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=1.800120793153074 *\n",
      "* Parameter=tol Value=1.0629418127024894 *\n",
      "* Parameter=intercept_scaling Value=0.6512893555781304 *\n",
      "* Parameter=solver Value=liblinear *\n",
      "* Particle 1 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=1.7349183547720541 *\n",
      "* Parameter=tol Value=0.9111025916436988 *\n",
      "* Parameter=intercept_scaling Value=0.8599577183076214 *\n",
      "* Parameter=solver Value=lbfgs *\n",
      "* Particle 2 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=1.8137117849295252 *\n",
      "* Parameter=tol Value=1.5968089361319135 *\n",
      "* Parameter=intercept_scaling Value=0.4029792938088238 *\n",
      "* Parameter=solver Value=lbfgs *\n",
      "* Particle 3 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=1.679293437698289 *\n",
      "* Parameter=tol Value=1.2729773977679382 *\n",
      "* Parameter=intercept_scaling Value=0.32228564352274114 *\n",
      "* Parameter=solver Value=sag *\n",
      "* Particle 4 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7346938775510204 *\n",
      "* Parameter=C Value=1.890581611114512 *\n",
      "* Parameter=tol Value=1.1480927842285553 *\n",
      "* Parameter=intercept_scaling Value=0.5543174280514378 *\n",
      "* Parameter=solver Value=lbfgs *\n",
      "* Particle 5 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=1.3123626979636678 *\n",
      "* Parameter=tol Value=1.1174711198874356 *\n",
      "* Parameter=intercept_scaling Value=0.7067061963238723 *\n",
      "* Parameter=solver Value=newton-cg *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Particle 6 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=2.9502268944546177 *\n",
      "* Parameter=tol Value=1.0411290377763578 *\n",
      "* Parameter=intercept_scaling Value=0.4978765706399866 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 7 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=1.8710157782380903 *\n",
      "* Parameter=tol Value=1.423227774318422 *\n",
      "* Parameter=intercept_scaling Value=0.7523120570274344 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 8 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=1.7232064208845381 *\n",
      "* Parameter=tol Value=1.841937281159122 *\n",
      "* Parameter=intercept_scaling Value=0.7501791168303984 *\n",
      "* Parameter=solver Value=lbfgs *\n",
      "* Particle 9 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 10 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 11 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 12 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 13 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 14 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 15 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 16 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=200 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 17 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=186 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 18 Algorithm Type RANDOM FOREST: personal best metric=0.9411764705882353 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=268 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 19 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=195 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 20 Algorithm Type RANDOM FOREST: personal best metric=0.9411764705882353 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=218 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 21 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=204 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 22 Algorithm Type RANDOM FOREST: personal best metric=0.9268292682926829 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=201 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 23 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=218 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 24 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=204 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 25 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=300 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 26 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 27 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.8031496062992127 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 28 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.8527131782945736 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 29 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.7899159663865546 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 30 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.8217054263565892 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 31 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.8032786885245902 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 32 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8225806451612904 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 33 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8062015503875969 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 34 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8064516129032259 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 35 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8225806451612904 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 36 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8225806451612904 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 37 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.796875 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 38 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8095238095238095 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 39 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8130081300813008 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 40 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8031496062992127 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 41 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8095238095238095 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 42 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 43 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 44 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 45 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 46 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 47 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 48 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 49 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 50 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 51 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 52 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.864406779661017 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 53 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8947368421052632 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 54 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.9122807017543859 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 55 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.890909090909091 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 56 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8521739130434782 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 57 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8648648648648649 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 58 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8421052631578948 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 59 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8103448275862069 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=201 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 60 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=229 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 61 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=192 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 62 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=180 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 63 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=196 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 64 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=182 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 65 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=250 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 66 Algorithm Type RANDOM FOREST: personal best metric=0.9180327868852458 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=108 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 67 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=188 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 68 Algorithm Type RANDOM FOREST: personal best metric=0.9180327868852458 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=260 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 69 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=158 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 70 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=184 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 71 Algorithm Type RANDOM FOREST: personal best metric=0.9180327868852458 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=214 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 72 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=158 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 73 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=130 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 74 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=179 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 75 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=38 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 76 Algorithm Type RANDOM FOREST: personal best metric=0.9059829059829059 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=206 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 77 Algorithm Type RANDOM FOREST: personal best metric=0.9180327868852458 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=270 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 78 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=229 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 79 Algorithm Type RANDOM FOREST: personal best metric=0.9105691056910569 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=228 *\n",
      "* Parameter=criterion Value=gini *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Particle 80 Algorithm Type RANDOM FOREST: personal best metric=0.9105691056910569 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=184 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 81 Algorithm Type RANDOM FOREST: personal best metric=0.9075630252100839 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=211 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 82 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=208 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 83 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=191 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 84 Algorithm Type RANDOM FOREST: personal best metric=0.9180327868852458 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=67 *\n",
      "* Parameter=n_estimators Value=186 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 85 Algorithm Type RANDOM FOREST: personal best metric=0.8396946564885496 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=277 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 86 Algorithm Type RANDOM FOREST: personal best metric=0.9193548387096773 *\n",
      "* Parameter=max_depth Value=45 *\n",
      "* Parameter=min_samples_split Value=11 *\n",
      "* Parameter=n_estimators Value=199 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 87 Algorithm Type RANDOM FOREST: personal best metric=0.8943089430894309 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=300 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 88 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=288 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 89 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "\n",
      "* Particle 10 Removed --- Algorithm Type: KNN With Metric 0.7155963302752293 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=41 *\n",
      "* Parameter=min_samples_split Value=70 *\n",
      "* Parameter=n_estimators Value=160 *\n",
      "* Parameter=criterion Value=gini *\n",
      "\n",
      "* Particle 10 Removed --- Algorithm Type: KNN With Metric 0.7155963302752293 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=31 *\n",
      "* Parameter=min_samples_split Value=69 *\n",
      "* Parameter=n_estimators Value=80 *\n",
      "* Parameter=criterion Value=gini *\n",
      "\n",
      "* Particle 10 Removed --- Algorithm Type: KNN With Metric 0.7155963302752293 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=74 *\n",
      "* Parameter=min_samples_split Value=29 *\n",
      "* Parameter=n_estimators Value=172 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "\n",
      "* Particle 10 Removed --- Algorithm Type: KNN With Metric 0.7155963302752293 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=21 *\n",
      "* Parameter=min_samples_split Value=38 *\n",
      "* Parameter=n_estimators Value=91 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "\n",
      "* Particle 10 Removed --- Algorithm Type: KNN With Metric 0.7155963302752293 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=70 *\n",
      "* Parameter=min_samples_split Value=64 *\n",
      "* Parameter=n_estimators Value=126 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "--- END EPOCH 7 ---\n",
      "--- START EPOCH 7 ---\n",
      "* Parameter=C Value=2.3463241207612393 *\n",
      "* Parameter=tol Value=1.0832633216245195 *\n",
      "* Parameter=intercept_scaling Value=0.6227888000476864 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 0 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=1.8661406164696253 *\n",
      "* Parameter=tol Value=0.6957224325403102 *\n",
      "* Parameter=intercept_scaling Value=0.5708906233221722 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 1 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=1.9621515665197902 *\n",
      "* Parameter=tol Value=1.2533605269785957 *\n",
      "* Parameter=intercept_scaling Value=0.8188798441328513 *\n",
      "* Parameter=solver Value=lbfgs *\n",
      "* Particle 2 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=1.9309205154812168 *\n",
      "* Parameter=tol Value=1.1321466034329275 *\n",
      "* Parameter=intercept_scaling Value=1 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 3 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=2.0972424502339035 *\n",
      "* Parameter=tol Value=1.0590511170203396 *\n",
      "* Parameter=intercept_scaling Value=0.7796236312013887 *\n",
      "* Parameter=solver Value=liblinear *\n",
      "* Particle 4 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7346938775510204 *\n",
      "* Parameter=C Value=1.8761856107213022 *\n",
      "* Parameter=tol Value=1.1235016714109636 *\n",
      "* Parameter=intercept_scaling Value=0.5675628593219444 *\n",
      "* Parameter=solver Value=lbfgs *\n",
      "* Particle 5 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=2.1336167985196024 *\n",
      "* Parameter=tol Value=0.9706310925824233 *\n",
      "* Parameter=intercept_scaling Value=0.51675865612271 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 6 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=2.759526655540185 *\n",
      "* Parameter=tol Value=1.0150763159802385 *\n",
      "* Parameter=intercept_scaling Value=0.5455003759035442 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 7 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=1.835981898485504 *\n",
      "* Parameter=tol Value=0.9063652196589104 *\n",
      "* Parameter=intercept_scaling Value=0.5330299614112507 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 8 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=1.6944402874796713 *\n",
      "* Parameter=tol Value=0.7346668812088 *\n",
      "* Parameter=intercept_scaling Value=0.5044146218356333 *\n",
      "* Parameter=solver Value=lbfgs *\n",
      "* Particle 9 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 10 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=p Value=2 *\n",
      "* Parameter=n_neighbors Value=2 *\n",
      "* Parameter=leaf_size Value=2 *\n",
      "* Parameter=algorithm Value=auto *\n",
      "* Particle 11 Algorithm Type KNN: personal best metric=0.7155963302752293 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=200 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 12 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=219 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 13 Algorithm Type RANDOM FOREST: personal best metric=0.9411764705882353 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=121 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 14 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=200 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 15 Algorithm Type RANDOM FOREST: personal best metric=0.9411764705882353 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=223 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 16 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=209 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 17 Algorithm Type RANDOM FOREST: personal best metric=0.9268292682926829 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=196 *\n",
      "* Parameter=criterion Value=gini *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Particle 18 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=196 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 19 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=198 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 20 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=300 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 21 Algorithm Type RANDOM FOREST: personal best metric=0.9411764705882353 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 22 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.8031496062992127 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 23 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.8527131782945736 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 24 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.7999999999999999 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 25 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.8217054263565892 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 26 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.8032786885245902 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 27 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8225806451612904 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 28 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8062015503875969 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 29 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8064516129032259 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 30 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8225806451612904 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 31 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8225806451612904 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 32 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.796875 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 33 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8225806451612904 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 34 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8130081300813008 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 35 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8159999999999998 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 36 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8253968253968255 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 37 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 38 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 39 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 40 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 41 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 42 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 43 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 44 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 45 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 46 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 47 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.864406779661017 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 48 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8947368421052632 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 49 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.9122807017543859 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 50 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.890909090909091 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 51 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8521739130434782 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 52 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8648648648648649 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 53 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8545454545454545 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 54 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8103448275862069 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=200 *\n",
      "* Parameter=criterion Value=gini *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Particle 55 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=243 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 56 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=178 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 57 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=213 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 58 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=204 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 59 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=189 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 60 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=142 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 61 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=250 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 62 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=237 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 63 Algorithm Type RANDOM FOREST: personal best metric=0.9180327868852458 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=233 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 64 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=230 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 65 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=215 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 66 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=196 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 67 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=241 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 68 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=140 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 69 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=174 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 70 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 71 Algorithm Type RANDOM FOREST: personal best metric=0.9059829059829059 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=187 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 72 Algorithm Type RANDOM FOREST: personal best metric=0.9180327868852458 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=244 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 73 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=300 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 74 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=194 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 75 Algorithm Type RANDOM FOREST: personal best metric=0.9105691056910569 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=162 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 76 Algorithm Type RANDOM FOREST: personal best metric=0.9180327868852458 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=206 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 77 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=189 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 78 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=161 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 79 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=221 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 80 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=222 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 81 Algorithm Type RANDOM FOREST: personal best metric=0.9193548387096773 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=156 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 82 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=269 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 83 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=156 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 84 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=257 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 85 Algorithm Type RANDOM FOREST: personal best metric=0.9411764705882353 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=262 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 86 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=203 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 87 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=300 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "* Particle 88 Algorithm Type RANDOM FOREST: personal best metric=0.8925619834710744 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=297 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 89 Algorithm Type RANDOM FOREST: personal best metric=0.8907563025210085 *\n",
      "\n",
      "* Particle 10 Removed --- Algorithm Type: KNN With Metric 0.7155963302752293 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=63 *\n",
      "* Parameter=min_samples_split Value=42 *\n",
      "* Parameter=n_estimators Value=98 *\n",
      "* Parameter=criterion Value=entropy *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Particle 10 Removed --- Algorithm Type: KNN With Metric 0.7155963302752293 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=67 *\n",
      "* Parameter=min_samples_split Value=50 *\n",
      "* Parameter=n_estimators Value=88 *\n",
      "* Parameter=criterion Value=gini *\n",
      "\n",
      "* Particle 4 Removed --- Algorithm Type: LOGISTIC_REGRESSION With Metric 0.7346938775510204 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=35 *\n",
      "* Parameter=min_samples_split Value=38 *\n",
      "* Parameter=n_estimators Value=223 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "\n",
      "* Particle 0 Removed --- Algorithm Type: LOGISTIC_REGRESSION With Metric 0.7397260273972602 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=34 *\n",
      "* Parameter=min_samples_split Value=3 *\n",
      "* Parameter=n_estimators Value=121 *\n",
      "* Parameter=criterion Value=gini *\n",
      "\n",
      "* Particle 0 Removed --- Algorithm Type: LOGISTIC_REGRESSION With Metric 0.7397260273972602 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=27 *\n",
      "* Parameter=min_samples_split Value=59 *\n",
      "* Parameter=n_estimators Value=60 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "--- END EPOCH 8 ---\n",
      "--- START EPOCH 8 ---\n",
      "* Parameter=C Value=2.0164753941307763 *\n",
      "* Parameter=tol Value=1.3808059245859128 *\n",
      "* Parameter=intercept_scaling Value=0.35160017355199774 *\n",
      "* Parameter=solver Value=liblinear *\n",
      "* Particle 0 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=1.9106801468353476 *\n",
      "* Parameter=tol Value=0.9858652051347122 *\n",
      "* Parameter=intercept_scaling Value=1 *\n",
      "* Parameter=solver Value=lbfgs *\n",
      "* Particle 1 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=1.8714481059439183 *\n",
      "* Parameter=tol Value=1.2435403989203353 *\n",
      "* Parameter=intercept_scaling Value=0.5948131829203516 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 2 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=2.2720190391530117 *\n",
      "* Parameter=tol Value=1.106888295606768 *\n",
      "* Parameter=intercept_scaling Value=0.4888710033586058 *\n",
      "* Parameter=solver Value=lbfgs *\n",
      "* Particle 3 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=1.5754874616595265 *\n",
      "* Parameter=tol Value=1.2984848857895788 *\n",
      "* Parameter=intercept_scaling Value=0.6088533148700687 *\n",
      "* Parameter=solver Value=lbfgs *\n",
      "* Particle 4 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=1.8636816170720252 *\n",
      "* Parameter=tol Value=0.7111817183057016 *\n",
      "* Parameter=intercept_scaling Value=0.48624220363874354 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 5 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=2.0643012857756387 *\n",
      "* Parameter=tol Value=0.43109361488487924 *\n",
      "* Parameter=intercept_scaling Value=0.5777330081369262 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 6 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=198 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 7 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=198 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 8 Algorithm Type RANDOM FOREST: personal best metric=0.9411764705882353 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=86 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 9 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=200 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 10 Algorithm Type RANDOM FOREST: personal best metric=0.9411764705882353 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=208 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 11 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=185 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 12 Algorithm Type RANDOM FOREST: personal best metric=0.9268292682926829 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=198 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 13 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=187 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 14 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=196 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 15 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=126 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 16 Algorithm Type RANDOM FOREST: personal best metric=0.9411764705882353 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 17 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.8031496062992127 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 18 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.8527131782945736 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 19 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.864406779661017 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 20 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.8429752066115702 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 21 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.8032786885245902 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 22 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8225806451612904 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 23 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8062015503875969 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 24 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8064516129032259 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 25 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8225806451612904 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 26 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8225806451612904 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 27 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.796875 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 28 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8225806451612904 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 29 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8130081300813008 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 30 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8159999999999998 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 31 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8253968253968255 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 32 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 33 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 34 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 35 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 36 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 37 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 38 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 39 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 40 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Particle 41 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 42 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.864406779661017 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 43 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8947368421052632 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 44 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.9122807017543859 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 45 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.890909090909091 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 46 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8521739130434782 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 47 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8648648648648649 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 48 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8545454545454545 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 49 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8448275862068966 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=198 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 50 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=174 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 51 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=183 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 52 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=208 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 53 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=195 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 54 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=218 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 55 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=248 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 56 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=230 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 57 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=235 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 58 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=125 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 59 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=252 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 60 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=227 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 61 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=194 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 62 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=166 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 63 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=290 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 64 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=226 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 65 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=293 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 66 Algorithm Type RANDOM FOREST: personal best metric=0.9193548387096773 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=187 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 67 Algorithm Type RANDOM FOREST: personal best metric=0.9180327868852458 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=167 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 68 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=67 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 69 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=189 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 70 Algorithm Type RANDOM FOREST: personal best metric=0.9152542372881356 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=217 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 71 Algorithm Type RANDOM FOREST: personal best metric=0.9180327868852458 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=194 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 72 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=197 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 73 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=170 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 74 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=220 *\n",
      "* Parameter=criterion Value=gini *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Particle 75 Algorithm Type RANDOM FOREST: personal best metric=0.95 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=169 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 76 Algorithm Type RANDOM FOREST: personal best metric=0.923076923076923 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=261 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 77 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=117 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 78 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=137 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 79 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=155 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 80 Algorithm Type RANDOM FOREST: personal best metric=0.9411764705882353 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=230 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 81 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=212 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 82 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=224 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 83 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=300 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 84 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=63 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=300 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 85 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=43 *\n",
      "* Parameter=n_estimators Value=300 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 86 Algorithm Type RANDOM FOREST: personal best metric=0.8527131782945736 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=22 *\n",
      "* Parameter=n_estimators Value=188 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 87 Algorithm Type RANDOM FOREST: personal best metric=0.873015873015873 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=300 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 88 Algorithm Type RANDOM FOREST: personal best metric=0.9137931034482759 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=300 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 89 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "\n",
      "* Particle 0 Removed --- Algorithm Type: LOGISTIC_REGRESSION With Metric 0.7397260273972602 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=39 *\n",
      "* Parameter=min_samples_split Value=51 *\n",
      "* Parameter=n_estimators Value=294 *\n",
      "* Parameter=criterion Value=gini *\n",
      "\n",
      "* Particle 0 Removed --- Algorithm Type: LOGISTIC_REGRESSION With Metric 0.7397260273972602 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=47 *\n",
      "* Parameter=min_samples_split Value=82 *\n",
      "* Parameter=n_estimators Value=236 *\n",
      "* Parameter=criterion Value=gini *\n",
      "\n",
      "* Particle 0 Removed --- Algorithm Type: LOGISTIC_REGRESSION With Metric 0.7397260273972602 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=30 *\n",
      "* Parameter=min_samples_split Value=41 *\n",
      "* Parameter=n_estimators Value=114 *\n",
      "* Parameter=criterion Value=gini *\n",
      "\n",
      "* Particle 0 Removed --- Algorithm Type: LOGISTIC_REGRESSION With Metric 0.7397260273972602 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=69 *\n",
      "* Parameter=min_samples_split Value=90 *\n",
      "* Parameter=n_estimators Value=34 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "\n",
      "* Particle 0 Removed --- Algorithm Type: LOGISTIC_REGRESSION With Metric 0.7397260273972602 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=90 *\n",
      "* Parameter=min_samples_split Value=80 *\n",
      "* Parameter=n_estimators Value=139 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "--- END EPOCH 9 ---\n",
      "--- START EPOCH 9 ---\n",
      "* Parameter=C Value=1.8983046656188385 *\n",
      "* Parameter=tol Value=0.7661605202392215 *\n",
      "* Parameter=intercept_scaling Value=0.7070061357338002 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 0 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=C Value=2.131049438584332 *\n",
      "* Parameter=tol Value=0.9750956248376179 *\n",
      "* Parameter=intercept_scaling Value=0.6147887178592527 *\n",
      "* Parameter=solver Value=newton-cg *\n",
      "* Particle 1 Algorithm Type LOGISTIC_REGRESSION: personal best metric=0.7397260273972602 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=239 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 2 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=228 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 3 Algorithm Type RANDOM FOREST: personal best metric=0.9411764705882353 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=300 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 4 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=248 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 5 Algorithm Type RANDOM FOREST: personal best metric=0.9411764705882353 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=231 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 6 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=253 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 7 Algorithm Type RANDOM FOREST: personal best metric=0.9268292682926829 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=216 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 8 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=279 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 9 Algorithm Type RANDOM FOREST: personal best metric=0.95 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=226 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 10 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=214 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 11 Algorithm Type RANDOM FOREST: personal best metric=0.9411764705882353 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 12 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.8064516129032259 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 13 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.8527131782945736 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 14 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.864406779661017 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 15 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.8429752066115702 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 16 Algorithm Type EXTRA TREE CLASSIFIER: personal best metric=0.8032786885245902 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 17 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8225806451612904 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 18 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8062015503875969 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 19 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8064516129032259 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 20 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8225806451612904 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 21 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8225806451612904 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 22 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8130081300813008 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 23 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8225806451612904 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 24 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8130081300813008 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 25 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8159999999999998 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=splitter Value=best *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 26 Algorithm Type DECISION TREE CLASSIFIER: personal best metric=0.8253968253968255 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 27 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 28 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Parameter=solver Value=auto *\n",
      "* Particle 29 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 30 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 31 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 32 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 33 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 34 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 35 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=alpha Value=0.001 *\n",
      "* Parameter=tol Value=0.001 *\n",
      "* Parameter=normalize Value=True *\n",
      "* Parameter=fit_intercept Value=True *\n",
      "* Parameter=solver Value=auto *\n",
      "* Particle 36 Algorithm Type RIDGE CLASSIFIER: personal best metric=0.7417218543046357 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 37 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.864406779661017 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 38 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8947368421052632 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 39 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.9122807017543859 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 40 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.890909090909091 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 41 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8521739130434782 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 42 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8672566371681415 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 43 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8545454545454545 *\n",
      "* Parameter=min_weight_fraction_leaf Value=0.0 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=min_samples_leaf Value=2 *\n",
      "* Parameter=n_estimators Value=2 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 44 Algorithm Type EXTRA TREES CLASSIFIER: personal best metric=0.8448275862068966 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=209 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 45 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=272 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 46 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=197 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 47 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=242 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 48 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=216 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 49 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=239 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 50 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=240 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 51 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=218 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 52 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=203 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 53 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=292 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 54 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=194 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 55 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=221 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 56 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=195 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 57 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=146 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 58 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=238 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 59 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=244 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 60 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=300 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 61 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=216 *\n",
      "* Parameter=criterion Value=gini *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Particle 62 Algorithm Type RANDOM FOREST: personal best metric=0.9180327868852458 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=188 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 63 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=104 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 64 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=202 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 65 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=250 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 66 Algorithm Type RANDOM FOREST: personal best metric=0.9180327868852458 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=258 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 67 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=251 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 68 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=292 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 69 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=220 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 70 Algorithm Type RANDOM FOREST: personal best metric=0.95 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=143 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 71 Algorithm Type RANDOM FOREST: personal best metric=0.923076923076923 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=264 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 72 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=178 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 73 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=146 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 74 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=185 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 75 Algorithm Type RANDOM FOREST: personal best metric=0.9411764705882353 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=204 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 76 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=217 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 77 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=177 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 78 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=248 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 79 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=233 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 80 Algorithm Type RANDOM FOREST: personal best metric=0.9333333333333333 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=300 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 81 Algorithm Type RANDOM FOREST: personal best metric=0.9137931034482759 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=183 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 82 Algorithm Type RANDOM FOREST: personal best metric=0.9421487603305785 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=300 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 83 Algorithm Type RANDOM FOREST: personal best metric=0.9344262295081968 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=300 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 84 Algorithm Type RANDOM FOREST: personal best metric=0.9256198347107438 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=266 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 85 Algorithm Type RANDOM FOREST: personal best metric=0.9105691056910569 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=67 *\n",
      "* Parameter=n_estimators Value=225 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 86 Algorithm Type RANDOM FOREST: personal best metric=0.8333333333333333 *\n",
      "* Parameter=max_depth Value=24 *\n",
      "* Parameter=min_samples_split Value=2 *\n",
      "* Parameter=n_estimators Value=181 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 87 Algorithm Type RANDOM FOREST: personal best metric=0.9137931034482759 *\n",
      "* Parameter=max_depth Value=57 *\n",
      "* Parameter=min_samples_split Value=76 *\n",
      "* Parameter=n_estimators Value=48 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 88 Algorithm Type RANDOM FOREST: personal best metric=0.7941176470588235 *\n",
      "* Parameter=max_depth Value=11 *\n",
      "* Parameter=min_samples_split Value=41 *\n",
      "* Parameter=n_estimators Value=174 *\n",
      "* Parameter=criterion Value=gini *\n",
      "* Particle 89 Algorithm Type RANDOM FOREST: personal best metric=0.8661417322834646 *\n",
      "\n",
      "* Particle 0 Removed --- Algorithm Type: LOGISTIC_REGRESSION With Metric 0.7397260273972602 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=79 *\n",
      "* Parameter=min_samples_split Value=12 *\n",
      "* Parameter=n_estimators Value=129 *\n",
      "* Parameter=criterion Value=gini *\n",
      "\n",
      "* Particle 0 Removed --- Algorithm Type: LOGISTIC_REGRESSION With Metric 0.7397260273972602 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=58 *\n",
      "* Parameter=min_samples_split Value=52 *\n",
      "* Parameter=n_estimators Value=184 *\n",
      "* Parameter=criterion Value=gini *\n",
      "\n",
      "* Particle 25 Removed --- Algorithm Type: RIDGE CLASSIFIER With Metric 0.7417218543046357 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=74 *\n",
      "* Parameter=min_samples_split Value=22 *\n",
      "* Parameter=n_estimators Value=22 *\n",
      "* Parameter=criterion Value=entropy *\n",
      "\n",
      "* Particle 25 Removed --- Algorithm Type: RIDGE CLASSIFIER With Metric 0.7417218543046357 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=13 *\n",
      "* Parameter=min_samples_split Value=30 *\n",
      "* Parameter=n_estimators Value=231 *\n",
      "* Parameter=criterion Value=gini *\n",
      "\n",
      "* Particle 25 Removed --- Algorithm Type: RIDGE CLASSIFIER With Metric 0.7417218543046357 *\n",
      "\n",
      "* Particle Added -- Algorithm Type RANDOM FOREST *\n",
      "* Parameter=max_depth Value=26 *\n",
      "* Parameter=min_samples_split Value=42 *\n",
      "* Parameter=n_estimators Value=52 *\n",
      "* Parameter=criterion Value=gini *\n",
      "--- END EPOCH 10 ---\n",
      "FINAL PSO:\n",
      "[[1.8870311662209376, 1.1803311275996105, 0.5778914630667819, 1.9434539794638401], [0.0, 0.0, 0.0, 0.0], [10.001, 1.001, 219.85530888903685, 0.001], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0]]\n",
      "0.95\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=11, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=220, n_jobs=None, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "num_particles=10\n",
    "num_iterations=10\n",
    "\n",
    "pso = PSO(particle_count=num_particles, distance_between_initial_particles=1.0, evaluation_metric=f1_score)\n",
    "\n",
    "best_metric, best_model = pso.fit(X_train=x_train,\n",
    "                                  X_test=x_test,\n",
    "                                  Y_train=y_train,\n",
    "                                  Y_test=y_test,\n",
    "                                  maxiter=num_iterations,\n",
    "                                  verbose=True,\n",
    "                                  max_distance=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=11, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=220, n_jobs=None, oob_score=False,\n",
       "            random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "\n",
    "df_cm = pd.DataFrame(confusion_matrix(y_test, y_pred), [\"negative\", \"positive\"], [\"negative\", \"positive\"])\n",
    "# plt.figure(figsize=(10,7))\n",
    "sn.set(font_scale=1.4) # for label size\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, cmap=\"Blues\", fmt='d') # font size\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9726027397260274"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9344262295081968"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9661016949152542"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9705508474576272"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg(x, y):\n",
    "    return f1_score(y, best_model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n",
      "C:\\Users\\Zoltan\\AppData\\Roaming\\Python\\Python37\\site-packages\\xai\\__init__.py:1127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x[c] = tmp\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imp = xai.feature_importance(x_test, y_test, get_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient age quantile</th>\n",
       "      <th>Hematocrit</th>\n",
       "      <th>Hemoglobin</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Mean platelet volume</th>\n",
       "      <th>Red blood Cells</th>\n",
       "      <th>Lymphocytes</th>\n",
       "      <th>Mean corpuscular hemoglobin concentrationÂ (MCHC)</th>\n",
       "      <th>Leukocytes</th>\n",
       "      <th>Basophils</th>\n",
       "      <th>...</th>\n",
       "      <th>Urea</th>\n",
       "      <th>C-reactive protein mg/dL</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>Potassium</th>\n",
       "      <th>Sodium</th>\n",
       "      <th>Alanine transaminase</th>\n",
       "      <th>Aspartate transaminase</th>\n",
       "      <th>Total Bilirubin</th>\n",
       "      <th>Direct Bilirubin</th>\n",
       "      <th>Indirect Bilirubin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.031428</td>\n",
       "      <td>0.01341</td>\n",
       "      <td>0.014247</td>\n",
       "      <td>0.173398</td>\n",
       "      <td>0.061863</td>\n",
       "      <td>0.011026</td>\n",
       "      <td>0.017788</td>\n",
       "      <td>0.003713</td>\n",
       "      <td>0.226213</td>\n",
       "      <td>0.02298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.030977</td>\n",
       "      <td>0.016339</td>\n",
       "      <td>0.004216</td>\n",
       "      <td>0.010211</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>0.004118</td>\n",
       "      <td>0.010265</td>\n",
       "      <td>0.00314</td>\n",
       "      <td>0.028622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient age quantile  Hematocrit  Hemoglobin  Platelets  \\\n",
       "0              0.031428     0.01341    0.014247   0.173398   \n",
       "\n",
       "   Mean platelet volume   Red blood Cells  Lymphocytes  \\\n",
       "0               0.061863         0.011026     0.017788   \n",
       "\n",
       "   Mean corpuscular hemoglobin concentrationÂ (MCHC)  Leukocytes  Basophils  \\\n",
       "0                                          0.003713    0.226213    0.02298   \n",
       "\n",
       "   ...      Urea  C-reactive protein mg/dL  Creatinine  Potassium    Sodium  \\\n",
       "0  ...  0.000785                  0.030977    0.016339   0.004216  0.010211   \n",
       "\n",
       "   Alanine transaminase  Aspartate transaminase  Total Bilirubin  \\\n",
       "0              0.002355                0.004118         0.010265   \n",
       "\n",
       "   Direct Bilirubin  Indirect Bilirubin  \n",
       "0           0.00314            0.028622  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
